{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning is parameter estimation\n",
    "首先使用了校准仪器的案例来引入一个较为简单的学习案例 calibrating instruments  \n",
    "\n",
    "文中提到，desired outputs就是ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature data\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]    # Clesius\n",
    "t_u = [35.7,55.9, 58.2, 81.9, 56.3, 48.9,33.9,21.8,48.4, 60.4, 68.4]    # unknown units\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先使用线性模型进行尝试  \n",
    "$t_c = w * t_u + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "损失函数需要确定修复错误的优先级  \n",
    "参数更新 首先要对高权重样本的输出进行调整，而不是对损失较小的其他样本  \n",
    "monotonically - 单调地  \n",
    "convex - 凸的 function  \n",
    "相对来说深度神经网络不会出现凸损失？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u +ｂ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的loss函数是差的频繁，然后求了平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones(1)\n",
    "b = torch.zeros(1)\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8846)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降\n",
    "knobs - 旋钮  \n",
    "文中将调节步幅的参数，step视为旋钮  \n",
    "或者把调节w 和 b的操作视为转动旋钮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "\n",
    "loss_rate_of_change_w = \\\n",
    "    (loss_fn(model(t_u, w+delta, b), t_c) - \n",
    "     loss_fn(model(t_u, w-delta, b), t_c)) / (2.0 * delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中，对w做一点微小调整，观察对loss的影响，如果结果是负的，那么需要增大w，如果是正的，那么需要减小w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "w = w - learning_rate * loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rate_of_change_b = \\\n",
    "    (loss_fn(model(t_u, w, b+delta), t_c) - \n",
    "     loss_fn(model(t_u, w, b-delta), t_c)) / (2.0*delta)\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的部分这是这还能对上面的loss、w、b三个函数求导数  \n",
    "就是数学上的导数，然后直接计算一遍就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    dsp_diffs = 2 * (t_p - t_c)\n",
    "    return dsp_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dw = dloss_fn(t_p, t_c) * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_fn(t_p, t_c) * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw.mean(), dloss_db.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练周期  \n",
    "tentative - 精明，试验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        \n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        print('Epoch %d, loss %f' % (epoch, float(loss)))\n",
    "        print('\\t Params:', params)\n",
    "        print('\\t Grad:  ', grad)\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 1763.884644\n",
      "\t Params: tensor([ 0.5483, -0.0083])\n",
      "\t Grad:   tensor([4517.2964,   82.6000])\n",
      "Epoch 2, loss 323.090546\n",
      "\t Params: tensor([ 0.3623, -0.0118])\n",
      "\t Grad:   tensor([1859.5493,   35.7843])\n",
      "Epoch 3, loss 78.929634\n",
      "\t Params: tensor([ 0.2858, -0.0135])\n",
      "\t Grad:   tensor([765.4666,  16.5122])\n",
      "Epoch 4, loss 37.552845\n",
      "\t Params: tensor([ 0.2543, -0.0143])\n",
      "\t Grad:   tensor([315.0790,   8.5787])\n",
      "Epoch 5, loss 30.540285\n",
      "\t Params: tensor([ 0.2413, -0.0149])\n",
      "\t Grad:   tensor([129.6733,   5.3127])\n",
      "Epoch 6, loss 29.351152\n",
      "\t Params: tensor([ 0.2360, -0.0153])\n",
      "\t Grad:   tensor([53.3496,  3.9682])\n",
      "Epoch 7, loss 29.148882\n",
      "\t Params: tensor([ 0.2338, -0.0156])\n",
      "\t Grad:   tensor([21.9304,  3.4148])\n",
      "Epoch 8, loss 29.113848\n",
      "\t Params: tensor([ 0.2329, -0.0159])\n",
      "\t Grad:   tensor([8.9964, 3.1869])\n",
      "Epoch 9, loss 29.107145\n",
      "\t Params: tensor([ 0.2325, -0.0162])\n",
      "\t Grad:   tensor([3.6721, 3.0930])\n",
      "Epoch 10, loss 29.105242\n",
      "\t Params: tensor([ 0.2324, -0.0166])\n",
      "\t Grad:   tensor([1.4803, 3.0544])\n",
      "Epoch 11, loss 29.104168\n",
      "\t Params: tensor([ 0.2323, -0.0169])\n",
      "\t Grad:   tensor([0.5780, 3.0384])\n",
      "Epoch 12, loss 29.103222\n",
      "\t Params: tensor([ 0.2323, -0.0172])\n",
      "\t Grad:   tensor([0.2066, 3.0318])\n",
      "Epoch 13, loss 29.102297\n",
      "\t Params: tensor([ 0.2323, -0.0175])\n",
      "\t Grad:   tensor([0.0537, 3.0291])\n",
      "Epoch 14, loss 29.101379\n",
      "\t Params: tensor([ 0.2323, -0.0178])\n",
      "\t Grad:   tensor([-0.0093,  3.0279])\n",
      "Epoch 15, loss 29.100470\n",
      "\t Params: tensor([ 0.2323, -0.0181])\n",
      "\t Grad:   tensor([-0.0353,  3.0274])\n",
      "Epoch 16, loss 29.099548\n",
      "\t Params: tensor([ 0.2323, -0.0184])\n",
      "\t Grad:   tensor([-0.0459,  3.0272])\n",
      "Epoch 17, loss 29.098631\n",
      "\t Params: tensor([ 0.2323, -0.0187])\n",
      "\t Grad:   tensor([-0.0502,  3.0270])\n",
      "Epoch 18, loss 29.097715\n",
      "\t Params: tensor([ 0.2323, -0.0190])\n",
      "\t Grad:   tensor([-0.0520,  3.0270])\n",
      "Epoch 19, loss 29.096796\n",
      "\t Params: tensor([ 0.2323, -0.0193])\n",
      "\t Grad:   tensor([-0.0528,  3.0269])\n",
      "Epoch 20, loss 29.095884\n",
      "\t Params: tensor([ 0.2323, -0.0196])\n",
      "\t Grad:   tensor([-0.0531,  3.0268])\n",
      "Epoch 21, loss 29.094959\n",
      "\t Params: tensor([ 0.2323, -0.0199])\n",
      "\t Grad:   tensor([-0.0533,  3.0268])\n",
      "Epoch 22, loss 29.094049\n",
      "\t Params: tensor([ 0.2323, -0.0202])\n",
      "\t Grad:   tensor([-0.0533,  3.0267])\n",
      "Epoch 23, loss 29.093134\n",
      "\t Params: tensor([ 0.2323, -0.0205])\n",
      "\t Grad:   tensor([-0.0533,  3.0267])\n",
      "Epoch 24, loss 29.092213\n",
      "\t Params: tensor([ 0.2323, -0.0208])\n",
      "\t Grad:   tensor([-0.0533,  3.0266])\n",
      "Epoch 25, loss 29.091297\n",
      "\t Params: tensor([ 0.2323, -0.0211])\n",
      "\t Grad:   tensor([-0.0533,  3.0266])\n",
      "Epoch 26, loss 29.090382\n",
      "\t Params: tensor([ 0.2323, -0.0214])\n",
      "\t Grad:   tensor([-0.0533,  3.0265])\n",
      "Epoch 27, loss 29.089460\n",
      "\t Params: tensor([ 0.2323, -0.0217])\n",
      "\t Grad:   tensor([-0.0533,  3.0265])\n",
      "Epoch 28, loss 29.088549\n",
      "\t Params: tensor([ 0.2323, -0.0220])\n",
      "\t Grad:   tensor([-0.0532,  3.0264])\n",
      "Epoch 29, loss 29.087635\n",
      "\t Params: tensor([ 0.2323, -0.0223])\n",
      "\t Grad:   tensor([-0.0533,  3.0264])\n",
      "Epoch 30, loss 29.086718\n",
      "\t Params: tensor([ 0.2323, -0.0226])\n",
      "\t Grad:   tensor([-0.0533,  3.0263])\n",
      "Epoch 31, loss 29.085808\n",
      "\t Params: tensor([ 0.2324, -0.0229])\n",
      "\t Grad:   tensor([-0.0532,  3.0262])\n",
      "Epoch 32, loss 29.084888\n",
      "\t Params: tensor([ 0.2324, -0.0232])\n",
      "\t Grad:   tensor([-0.0533,  3.0262])\n",
      "Epoch 33, loss 29.083965\n",
      "\t Params: tensor([ 0.2324, -0.0235])\n",
      "\t Grad:   tensor([-0.0533,  3.0261])\n",
      "Epoch 34, loss 29.083057\n",
      "\t Params: tensor([ 0.2324, -0.0238])\n",
      "\t Grad:   tensor([-0.0533,  3.0261])\n",
      "Epoch 35, loss 29.082142\n",
      "\t Params: tensor([ 0.2324, -0.0241])\n",
      "\t Grad:   tensor([-0.0532,  3.0260])\n",
      "Epoch 36, loss 29.081219\n",
      "\t Params: tensor([ 0.2324, -0.0244])\n",
      "\t Grad:   tensor([-0.0533,  3.0260])\n",
      "Epoch 37, loss 29.080309\n",
      "\t Params: tensor([ 0.2324, -0.0247])\n",
      "\t Grad:   tensor([-0.0533,  3.0259])\n",
      "Epoch 38, loss 29.079393\n",
      "\t Params: tensor([ 0.2324, -0.0250])\n",
      "\t Grad:   tensor([-0.0532,  3.0259])\n",
      "Epoch 39, loss 29.078474\n",
      "\t Params: tensor([ 0.2324, -0.0253])\n",
      "\t Grad:   tensor([-0.0533,  3.0258])\n",
      "Epoch 40, loss 29.077559\n",
      "\t Params: tensor([ 0.2324, -0.0256])\n",
      "\t Grad:   tensor([-0.0533,  3.0258])\n",
      "Epoch 41, loss 29.076653\n",
      "\t Params: tensor([ 0.2324, -0.0259])\n",
      "\t Grad:   tensor([-0.0533,  3.0257])\n",
      "Epoch 42, loss 29.075731\n",
      "\t Params: tensor([ 0.2324, -0.0262])\n",
      "\t Grad:   tensor([-0.0532,  3.0257])\n",
      "Epoch 43, loss 29.074812\n",
      "\t Params: tensor([ 0.2324, -0.0265])\n",
      "\t Grad:   tensor([-0.0533,  3.0256])\n",
      "Epoch 44, loss 29.073896\n",
      "\t Params: tensor([ 0.2324, -0.0268])\n",
      "\t Grad:   tensor([-0.0533,  3.0256])\n",
      "Epoch 45, loss 29.072985\n",
      "\t Params: tensor([ 0.2324, -0.0271])\n",
      "\t Grad:   tensor([-0.0533,  3.0255])\n",
      "Epoch 46, loss 29.072069\n",
      "\t Params: tensor([ 0.2324, -0.0274])\n",
      "\t Grad:   tensor([-0.0533,  3.0254])\n",
      "Epoch 47, loss 29.071148\n",
      "\t Params: tensor([ 0.2324, -0.0277])\n",
      "\t Grad:   tensor([-0.0533,  3.0254])\n",
      "Epoch 48, loss 29.070234\n",
      "\t Params: tensor([ 0.2324, -0.0281])\n",
      "\t Grad:   tensor([-0.0533,  3.0253])\n",
      "Epoch 49, loss 29.069323\n",
      "\t Params: tensor([ 0.2325, -0.0284])\n",
      "\t Grad:   tensor([-0.0533,  3.0253])\n",
      "Epoch 50, loss 29.068401\n",
      "\t Params: tensor([ 0.2325, -0.0287])\n",
      "\t Grad:   tensor([-0.0532,  3.0252])\n",
      "Epoch 51, loss 29.067486\n",
      "\t Params: tensor([ 0.2325, -0.0290])\n",
      "\t Grad:   tensor([-0.0533,  3.0252])\n",
      "Epoch 52, loss 29.066570\n",
      "\t Params: tensor([ 0.2325, -0.0293])\n",
      "\t Grad:   tensor([-0.0533,  3.0251])\n",
      "Epoch 53, loss 29.065655\n",
      "\t Params: tensor([ 0.2325, -0.0296])\n",
      "\t Grad:   tensor([-0.0533,  3.0251])\n",
      "Epoch 54, loss 29.064739\n",
      "\t Params: tensor([ 0.2325, -0.0299])\n",
      "\t Grad:   tensor([-0.0533,  3.0250])\n",
      "Epoch 55, loss 29.063829\n",
      "\t Params: tensor([ 0.2325, -0.0302])\n",
      "\t Grad:   tensor([-0.0532,  3.0250])\n",
      "Epoch 56, loss 29.062910\n",
      "\t Params: tensor([ 0.2325, -0.0305])\n",
      "\t Grad:   tensor([-0.0533,  3.0249])\n",
      "Epoch 57, loss 29.061989\n",
      "\t Params: tensor([ 0.2325, -0.0308])\n",
      "\t Grad:   tensor([-0.0532,  3.0249])\n",
      "Epoch 58, loss 29.061079\n",
      "\t Params: tensor([ 0.2325, -0.0311])\n",
      "\t Grad:   tensor([-0.0533,  3.0248])\n",
      "Epoch 59, loss 29.060169\n",
      "\t Params: tensor([ 0.2325, -0.0314])\n",
      "\t Grad:   tensor([-0.0533,  3.0248])\n",
      "Epoch 60, loss 29.059252\n",
      "\t Params: tensor([ 0.2325, -0.0317])\n",
      "\t Grad:   tensor([-0.0533,  3.0247])\n",
      "Epoch 61, loss 29.058331\n",
      "\t Params: tensor([ 0.2325, -0.0320])\n",
      "\t Grad:   tensor([-0.0532,  3.0247])\n",
      "Epoch 62, loss 29.057417\n",
      "\t Params: tensor([ 0.2325, -0.0323])\n",
      "\t Grad:   tensor([-0.0533,  3.0246])\n",
      "Epoch 63, loss 29.056507\n",
      "\t Params: tensor([ 0.2325, -0.0326])\n",
      "\t Grad:   tensor([-0.0533,  3.0245])\n",
      "Epoch 64, loss 29.055586\n",
      "\t Params: tensor([ 0.2325, -0.0329])\n",
      "\t Grad:   tensor([-0.0532,  3.0245])\n",
      "Epoch 65, loss 29.054670\n",
      "\t Params: tensor([ 0.2325, -0.0332])\n",
      "\t Grad:   tensor([-0.0533,  3.0244])\n",
      "Epoch 66, loss 29.053761\n",
      "\t Params: tensor([ 0.2325, -0.0335])\n",
      "\t Grad:   tensor([-0.0533,  3.0244])\n",
      "Epoch 67, loss 29.052843\n",
      "\t Params: tensor([ 0.2325, -0.0338])\n",
      "\t Grad:   tensor([-0.0533,  3.0243])\n",
      "Epoch 68, loss 29.051929\n",
      "\t Params: tensor([ 0.2326, -0.0341])\n",
      "\t Grad:   tensor([-0.0533,  3.0243])\n",
      "Epoch 69, loss 29.051014\n",
      "\t Params: tensor([ 0.2326, -0.0344])\n",
      "\t Grad:   tensor([-0.0533,  3.0242])\n",
      "Epoch 70, loss 29.050098\n",
      "\t Params: tensor([ 0.2326, -0.0347])\n",
      "\t Grad:   tensor([-0.0532,  3.0242])\n",
      "Epoch 71, loss 29.049183\n",
      "\t Params: tensor([ 0.2326, -0.0350])\n",
      "\t Grad:   tensor([-0.0533,  3.0241])\n",
      "Epoch 72, loss 29.048271\n",
      "\t Params: tensor([ 0.2326, -0.0353])\n",
      "\t Grad:   tensor([-0.0533,  3.0241])\n",
      "Epoch 73, loss 29.047346\n",
      "\t Params: tensor([ 0.2326, -0.0356])\n",
      "\t Grad:   tensor([-0.0532,  3.0240])\n",
      "Epoch 74, loss 29.046442\n",
      "\t Params: tensor([ 0.2326, -0.0359])\n",
      "\t Grad:   tensor([-0.0533,  3.0240])\n",
      "Epoch 75, loss 29.045530\n",
      "\t Params: tensor([ 0.2326, -0.0362])\n",
      "\t Grad:   tensor([-0.0533,  3.0239])\n",
      "Epoch 76, loss 29.044611\n",
      "\t Params: tensor([ 0.2326, -0.0365])\n",
      "\t Grad:   tensor([-0.0533,  3.0239])\n",
      "Epoch 77, loss 29.043699\n",
      "\t Params: tensor([ 0.2326, -0.0368])\n",
      "\t Grad:   tensor([-0.0533,  3.0238])\n",
      "Epoch 78, loss 29.042780\n",
      "\t Params: tensor([ 0.2326, -0.0371])\n",
      "\t Grad:   tensor([-0.0533,  3.0238])\n",
      "Epoch 79, loss 29.041870\n",
      "\t Params: tensor([ 0.2326, -0.0374])\n",
      "\t Grad:   tensor([-0.0533,  3.0237])\n",
      "Epoch 80, loss 29.040955\n",
      "\t Params: tensor([ 0.2326, -0.0377])\n",
      "\t Grad:   tensor([-0.0532,  3.0236])\n",
      "Epoch 81, loss 29.040039\n",
      "\t Params: tensor([ 0.2326, -0.0380])\n",
      "\t Grad:   tensor([-0.0534,  3.0236])\n",
      "Epoch 82, loss 29.039122\n",
      "\t Params: tensor([ 0.2326, -0.0383])\n",
      "\t Grad:   tensor([-0.0533,  3.0235])\n",
      "Epoch 83, loss 29.038214\n",
      "\t Params: tensor([ 0.2326, -0.0386])\n",
      "\t Grad:   tensor([-0.0532,  3.0235])\n",
      "Epoch 84, loss 29.037292\n",
      "\t Params: tensor([ 0.2326, -0.0389])\n",
      "\t Grad:   tensor([-0.0533,  3.0234])\n",
      "Epoch 85, loss 29.036379\n",
      "\t Params: tensor([ 0.2326, -0.0392])\n",
      "\t Grad:   tensor([-0.0532,  3.0234])\n",
      "Epoch 86, loss 29.035463\n",
      "\t Params: tensor([ 0.2326, -0.0395])\n",
      "\t Grad:   tensor([-0.0532,  3.0233])\n",
      "Epoch 87, loss 29.034557\n",
      "\t Params: tensor([ 0.2327, -0.0398])\n",
      "\t Grad:   tensor([-0.0533,  3.0233])\n",
      "Epoch 88, loss 29.033638\n",
      "\t Params: tensor([ 0.2327, -0.0401])\n",
      "\t Grad:   tensor([-0.0532,  3.0232])\n",
      "Epoch 89, loss 29.032721\n",
      "\t Params: tensor([ 0.2327, -0.0405])\n",
      "\t Grad:   tensor([-0.0533,  3.0232])\n",
      "Epoch 90, loss 29.031805\n",
      "\t Params: tensor([ 0.2327, -0.0408])\n",
      "\t Grad:   tensor([-0.0533,  3.0231])\n",
      "Epoch 91, loss 29.030895\n",
      "\t Params: tensor([ 0.2327, -0.0411])\n",
      "\t Grad:   tensor([-0.0532,  3.0231])\n",
      "Epoch 92, loss 29.029976\n",
      "\t Params: tensor([ 0.2327, -0.0414])\n",
      "\t Grad:   tensor([-0.0532,  3.0230])\n",
      "Epoch 93, loss 29.029066\n",
      "\t Params: tensor([ 0.2327, -0.0417])\n",
      "\t Grad:   tensor([-0.0533,  3.0230])\n",
      "Epoch 94, loss 29.028151\n",
      "\t Params: tensor([ 0.2327, -0.0420])\n",
      "\t Grad:   tensor([-0.0532,  3.0229])\n",
      "Epoch 95, loss 29.027235\n",
      "\t Params: tensor([ 0.2327, -0.0423])\n",
      "\t Grad:   tensor([-0.0532,  3.0229])\n",
      "Epoch 96, loss 29.026323\n",
      "\t Params: tensor([ 0.2327, -0.0426])\n",
      "\t Grad:   tensor([-0.0533,  3.0228])\n",
      "Epoch 97, loss 29.025410\n",
      "\t Params: tensor([ 0.2327, -0.0429])\n",
      "\t Grad:   tensor([-0.0533,  3.0227])\n",
      "Epoch 98, loss 29.024494\n",
      "\t Params: tensor([ 0.2327, -0.0432])\n",
      "\t Grad:   tensor([-0.0533,  3.0227])\n",
      "Epoch 99, loss 29.023582\n",
      "\t Params: tensor([ 0.2327, -0.0435])\n",
      "\t Grad:   tensor([-0.0533,  3.0226])\n",
      "Epoch 100, loss 29.022669\n",
      "\t Params: tensor([ 0.2327, -0.0438])\n",
      "\t Grad:   tensor([-0.0532,  3.0226])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2327, -0.0438])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    learning_rate = 1e-4,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_u,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的训练中，loss反而是越来越大了  \n",
    "原因自然是参数更新的步长有点大了，说明优化方法还不够好  \n",
    "而且，你会看到刚开始的时候，w 和 b 根本不在一个数量级，如果能为不同参数独立设置学习率可能会更好，但是也会更麻烦\n",
    "\n",
    "### normalization\n",
    "还有一种方法：那就是更改inputs，让这些梯度值不会差异这么大：也就是说将输入值归一化到 -1和1 之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_un = 0.1 * t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 80.364342\n",
      "\t Params: tensor([1.7761, 0.1064])\n",
      "\t Grad:   tensor([-77.6140, -10.6400])\n",
      "Epoch 2, loss 37.574917\n",
      "\t Params: tensor([2.0848, 0.1303])\n",
      "\t Grad:   tensor([-30.8623,  -2.3864])\n",
      "Epoch 3, loss 30.871077\n",
      "\t Params: tensor([2.2094, 0.1217])\n",
      "\t Grad:   tensor([-12.4631,   0.8587])\n",
      "Epoch 4, loss 29.756193\n",
      "\t Params: tensor([2.2616, 0.1004])\n",
      "\t Grad:   tensor([-5.2218,  2.1327])\n",
      "Epoch 5, loss 29.507149\n",
      "\t Params: tensor([2.2853, 0.0740])\n",
      "\t Grad:   tensor([-2.3715,  2.6310])\n",
      "Epoch 6, loss 29.392458\n",
      "\t Params: tensor([2.2978, 0.0458])\n",
      "\t Grad:   tensor([-1.2492,  2.8241])\n",
      "Epoch 7, loss 29.298828\n",
      "\t Params: tensor([2.3059, 0.0168])\n",
      "\t Grad:   tensor([-0.8071,  2.8970])\n",
      "Epoch 8, loss 29.208717\n",
      "\t Params: tensor([ 2.3122, -0.0124])\n",
      "\t Grad:   tensor([-0.6325,  2.9227])\n",
      "Epoch 9, loss 29.119417\n",
      "\t Params: tensor([ 2.3178, -0.0417])\n",
      "\t Grad:   tensor([-0.5633,  2.9298])\n",
      "Epoch 10, loss 29.030487\n",
      "\t Params: tensor([ 2.3232, -0.0710])\n",
      "\t Grad:   tensor([-0.5355,  2.9295])\n",
      "Epoch 11, loss 28.941875\n",
      "\t Params: tensor([ 2.3284, -0.1003])\n",
      "\t Grad:   tensor([-0.5240,  2.9264])\n",
      "Epoch 12, loss 28.853565\n",
      "\t Params: tensor([ 2.3336, -0.1295])\n",
      "\t Grad:   tensor([-0.5190,  2.9222])\n",
      "Epoch 13, loss 28.765556\n",
      "\t Params: tensor([ 2.3388, -0.1587])\n",
      "\t Grad:   tensor([-0.5165,  2.9175])\n",
      "Epoch 14, loss 28.677851\n",
      "\t Params: tensor([ 2.3439, -0.1878])\n",
      "\t Grad:   tensor([-0.5150,  2.9126])\n",
      "Epoch 15, loss 28.590431\n",
      "\t Params: tensor([ 2.3491, -0.2169])\n",
      "\t Grad:   tensor([-0.5138,  2.9077])\n",
      "Epoch 16, loss 28.503321\n",
      "\t Params: tensor([ 2.3542, -0.2459])\n",
      "\t Grad:   tensor([-0.5129,  2.9028])\n",
      "Epoch 17, loss 28.416496\n",
      "\t Params: tensor([ 2.3593, -0.2749])\n",
      "\t Grad:   tensor([-0.5120,  2.8979])\n",
      "Epoch 18, loss 28.329975\n",
      "\t Params: tensor([ 2.3644, -0.3038])\n",
      "\t Grad:   tensor([-0.5111,  2.8930])\n",
      "Epoch 19, loss 28.243738\n",
      "\t Params: tensor([ 2.3695, -0.3327])\n",
      "\t Grad:   tensor([-0.5102,  2.8881])\n",
      "Epoch 20, loss 28.157801\n",
      "\t Params: tensor([ 2.3746, -0.3615])\n",
      "\t Grad:   tensor([-0.5093,  2.8832])\n",
      "Epoch 21, loss 28.072151\n",
      "\t Params: tensor([ 2.3797, -0.3903])\n",
      "\t Grad:   tensor([-0.5084,  2.8783])\n",
      "Epoch 22, loss 27.986799\n",
      "\t Params: tensor([ 2.3848, -0.4190])\n",
      "\t Grad:   tensor([-0.5076,  2.8734])\n",
      "Epoch 23, loss 27.901731\n",
      "\t Params: tensor([ 2.3899, -0.4477])\n",
      "\t Grad:   tensor([-0.5067,  2.8685])\n",
      "Epoch 24, loss 27.816956\n",
      "\t Params: tensor([ 2.3949, -0.4763])\n",
      "\t Grad:   tensor([-0.5059,  2.8636])\n",
      "Epoch 25, loss 27.732466\n",
      "\t Params: tensor([ 2.4000, -0.5049])\n",
      "\t Grad:   tensor([-0.5050,  2.8588])\n",
      "Epoch 26, loss 27.648256\n",
      "\t Params: tensor([ 2.4050, -0.5335])\n",
      "\t Grad:   tensor([-0.5042,  2.8539])\n",
      "Epoch 27, loss 27.564342\n",
      "\t Params: tensor([ 2.4101, -0.5620])\n",
      "\t Grad:   tensor([-0.5033,  2.8490])\n",
      "Epoch 28, loss 27.480711\n",
      "\t Params: tensor([ 2.4151, -0.5904])\n",
      "\t Grad:   tensor([-0.5024,  2.8442])\n",
      "Epoch 29, loss 27.397358\n",
      "\t Params: tensor([ 2.4201, -0.6188])\n",
      "\t Grad:   tensor([-0.5016,  2.8394])\n",
      "Epoch 30, loss 27.314295\n",
      "\t Params: tensor([ 2.4251, -0.6471])\n",
      "\t Grad:   tensor([-0.5007,  2.8346])\n",
      "Epoch 31, loss 27.231512\n",
      "\t Params: tensor([ 2.4301, -0.6754])\n",
      "\t Grad:   tensor([-0.4999,  2.8297])\n",
      "Epoch 32, loss 27.149006\n",
      "\t Params: tensor([ 2.4351, -0.7037])\n",
      "\t Grad:   tensor([-0.4990,  2.8249])\n",
      "Epoch 33, loss 27.066790\n",
      "\t Params: tensor([ 2.4401, -0.7319])\n",
      "\t Grad:   tensor([-0.4982,  2.8201])\n",
      "Epoch 34, loss 26.984844\n",
      "\t Params: tensor([ 2.4450, -0.7600])\n",
      "\t Grad:   tensor([-0.4973,  2.8153])\n",
      "Epoch 35, loss 26.903173\n",
      "\t Params: tensor([ 2.4500, -0.7881])\n",
      "\t Grad:   tensor([-0.4965,  2.8106])\n",
      "Epoch 36, loss 26.821791\n",
      "\t Params: tensor([ 2.4550, -0.8162])\n",
      "\t Grad:   tensor([-0.4957,  2.8058])\n",
      "Epoch 37, loss 26.740675\n",
      "\t Params: tensor([ 2.4599, -0.8442])\n",
      "\t Grad:   tensor([-0.4948,  2.8010])\n",
      "Epoch 38, loss 26.659838\n",
      "\t Params: tensor([ 2.4649, -0.8722])\n",
      "\t Grad:   tensor([-0.4940,  2.7963])\n",
      "Epoch 39, loss 26.579279\n",
      "\t Params: tensor([ 2.4698, -0.9001])\n",
      "\t Grad:   tensor([-0.4931,  2.7915])\n",
      "Epoch 40, loss 26.498987\n",
      "\t Params: tensor([ 2.4747, -0.9280])\n",
      "\t Grad:   tensor([-0.4923,  2.7868])\n",
      "Epoch 41, loss 26.418974\n",
      "\t Params: tensor([ 2.4796, -0.9558])\n",
      "\t Grad:   tensor([-0.4915,  2.7820])\n",
      "Epoch 42, loss 26.339228\n",
      "\t Params: tensor([ 2.4845, -0.9836])\n",
      "\t Grad:   tensor([-0.4906,  2.7773])\n",
      "Epoch 43, loss 26.259752\n",
      "\t Params: tensor([ 2.4894, -1.0113])\n",
      "\t Grad:   tensor([-0.4898,  2.7726])\n",
      "Epoch 44, loss 26.180548\n",
      "\t Params: tensor([ 2.4943, -1.0390])\n",
      "\t Grad:   tensor([-0.4890,  2.7679])\n",
      "Epoch 45, loss 26.101616\n",
      "\t Params: tensor([ 2.4992, -1.0666])\n",
      "\t Grad:   tensor([-0.4881,  2.7632])\n",
      "Epoch 46, loss 26.022949\n",
      "\t Params: tensor([ 2.5041, -1.0942])\n",
      "\t Grad:   tensor([-0.4873,  2.7585])\n",
      "Epoch 47, loss 25.944542\n",
      "\t Params: tensor([ 2.5089, -1.1217])\n",
      "\t Grad:   tensor([-0.4865,  2.7538])\n",
      "Epoch 48, loss 25.866417\n",
      "\t Params: tensor([ 2.5138, -1.1492])\n",
      "\t Grad:   tensor([-0.4856,  2.7491])\n",
      "Epoch 49, loss 25.788546\n",
      "\t Params: tensor([ 2.5186, -1.1766])\n",
      "\t Grad:   tensor([-0.4848,  2.7444])\n",
      "Epoch 50, loss 25.710936\n",
      "\t Params: tensor([ 2.5235, -1.2040])\n",
      "\t Grad:   tensor([-0.4840,  2.7398])\n",
      "Epoch 51, loss 25.633600\n",
      "\t Params: tensor([ 2.5283, -1.2314])\n",
      "\t Grad:   tensor([-0.4832,  2.7351])\n",
      "Epoch 52, loss 25.556524\n",
      "\t Params: tensor([ 2.5331, -1.2587])\n",
      "\t Grad:   tensor([-0.4823,  2.7305])\n",
      "Epoch 53, loss 25.479700\n",
      "\t Params: tensor([ 2.5379, -1.2860])\n",
      "\t Grad:   tensor([-0.4815,  2.7258])\n",
      "Epoch 54, loss 25.403149\n",
      "\t Params: tensor([ 2.5428, -1.3132])\n",
      "\t Grad:   tensor([-0.4807,  2.7212])\n",
      "Epoch 55, loss 25.326851\n",
      "\t Params: tensor([ 2.5476, -1.3403])\n",
      "\t Grad:   tensor([-0.4799,  2.7166])\n",
      "Epoch 56, loss 25.250811\n",
      "\t Params: tensor([ 2.5523, -1.3675])\n",
      "\t Grad:   tensor([-0.4791,  2.7120])\n",
      "Epoch 57, loss 25.175035\n",
      "\t Params: tensor([ 2.5571, -1.3945])\n",
      "\t Grad:   tensor([-0.4783,  2.7074])\n",
      "Epoch 58, loss 25.099510\n",
      "\t Params: tensor([ 2.5619, -1.4216])\n",
      "\t Grad:   tensor([-0.4775,  2.7028])\n",
      "Epoch 59, loss 25.024248\n",
      "\t Params: tensor([ 2.5667, -1.4485])\n",
      "\t Grad:   tensor([-0.4766,  2.6982])\n",
      "Epoch 60, loss 24.949238\n",
      "\t Params: tensor([ 2.5714, -1.4755])\n",
      "\t Grad:   tensor([-0.4758,  2.6936])\n",
      "Epoch 61, loss 24.874483\n",
      "\t Params: tensor([ 2.5762, -1.5024])\n",
      "\t Grad:   tensor([-0.4750,  2.6890])\n",
      "Epoch 62, loss 24.799980\n",
      "\t Params: tensor([ 2.5809, -1.5292])\n",
      "\t Grad:   tensor([-0.4742,  2.6845])\n",
      "Epoch 63, loss 24.725737\n",
      "\t Params: tensor([ 2.5857, -1.5560])\n",
      "\t Grad:   tensor([-0.4734,  2.6799])\n",
      "Epoch 64, loss 24.651735\n",
      "\t Params: tensor([ 2.5904, -1.5828])\n",
      "\t Grad:   tensor([-0.4726,  2.6753])\n",
      "Epoch 65, loss 24.577986\n",
      "\t Params: tensor([ 2.5951, -1.6095])\n",
      "\t Grad:   tensor([-0.4718,  2.6708])\n",
      "Epoch 66, loss 24.504494\n",
      "\t Params: tensor([ 2.5998, -1.6361])\n",
      "\t Grad:   tensor([-0.4710,  2.6663])\n",
      "Epoch 67, loss 24.431250\n",
      "\t Params: tensor([ 2.6045, -1.6628])\n",
      "\t Grad:   tensor([-0.4702,  2.6617])\n",
      "Epoch 68, loss 24.358257\n",
      "\t Params: tensor([ 2.6092, -1.6893])\n",
      "\t Grad:   tensor([-0.4694,  2.6572])\n",
      "Epoch 69, loss 24.285505\n",
      "\t Params: tensor([ 2.6139, -1.7159])\n",
      "\t Grad:   tensor([-0.4686,  2.6527])\n",
      "Epoch 70, loss 24.212996\n",
      "\t Params: tensor([ 2.6186, -1.7423])\n",
      "\t Grad:   tensor([-0.4678,  2.6482])\n",
      "Epoch 71, loss 24.140741\n",
      "\t Params: tensor([ 2.6232, -1.7688])\n",
      "\t Grad:   tensor([-0.4670,  2.6437])\n",
      "Epoch 72, loss 24.068733\n",
      "\t Params: tensor([ 2.6279, -1.7952])\n",
      "\t Grad:   tensor([-0.4662,  2.6392])\n",
      "Epoch 73, loss 23.996967\n",
      "\t Params: tensor([ 2.6326, -1.8215])\n",
      "\t Grad:   tensor([-0.4654,  2.6347])\n",
      "Epoch 74, loss 23.925446\n",
      "\t Params: tensor([ 2.6372, -1.8478])\n",
      "\t Grad:   tensor([-0.4646,  2.6302])\n",
      "Epoch 75, loss 23.854168\n",
      "\t Params: tensor([ 2.6418, -1.8741])\n",
      "\t Grad:   tensor([-0.4638,  2.6258])\n",
      "Epoch 76, loss 23.783125\n",
      "\t Params: tensor([ 2.6465, -1.9003])\n",
      "\t Grad:   tensor([-0.4631,  2.6213])\n",
      "Epoch 77, loss 23.712328\n",
      "\t Params: tensor([ 2.6511, -1.9265])\n",
      "\t Grad:   tensor([-0.4623,  2.6169])\n",
      "Epoch 78, loss 23.641771\n",
      "\t Params: tensor([ 2.6557, -1.9526])\n",
      "\t Grad:   tensor([-0.4615,  2.6124])\n",
      "Epoch 79, loss 23.571455\n",
      "\t Params: tensor([ 2.6603, -1.9787])\n",
      "\t Grad:   tensor([-0.4607,  2.6080])\n",
      "Epoch 80, loss 23.501379\n",
      "\t Params: tensor([ 2.6649, -2.0047])\n",
      "\t Grad:   tensor([-0.4599,  2.6035])\n",
      "Epoch 81, loss 23.431538\n",
      "\t Params: tensor([ 2.6695, -2.0307])\n",
      "\t Grad:   tensor([-0.4591,  2.5991])\n",
      "Epoch 82, loss 23.361938\n",
      "\t Params: tensor([ 2.6741, -2.0566])\n",
      "\t Grad:   tensor([-0.4584,  2.5947])\n",
      "Epoch 83, loss 23.292570\n",
      "\t Params: tensor([ 2.6787, -2.0825])\n",
      "\t Grad:   tensor([-0.4576,  2.5903])\n",
      "Epoch 84, loss 23.223436\n",
      "\t Params: tensor([ 2.6832, -2.1084])\n",
      "\t Grad:   tensor([-0.4568,  2.5859])\n",
      "Epoch 85, loss 23.154539\n",
      "\t Params: tensor([ 2.6878, -2.1342])\n",
      "\t Grad:   tensor([-0.4560,  2.5815])\n",
      "Epoch 86, loss 23.085882\n",
      "\t Params: tensor([ 2.6923, -2.1600])\n",
      "\t Grad:   tensor([-0.4553,  2.5771])\n",
      "Epoch 87, loss 23.017447\n",
      "\t Params: tensor([ 2.6969, -2.1857])\n",
      "\t Grad:   tensor([-0.4545,  2.5727])\n",
      "Epoch 88, loss 22.949251\n",
      "\t Params: tensor([ 2.7014, -2.2114])\n",
      "\t Grad:   tensor([-0.4537,  2.5684])\n",
      "Epoch 89, loss 22.881283\n",
      "\t Params: tensor([ 2.7060, -2.2370])\n",
      "\t Grad:   tensor([-0.4529,  2.5640])\n",
      "Epoch 90, loss 22.813547\n",
      "\t Params: tensor([ 2.7105, -2.2626])\n",
      "\t Grad:   tensor([-0.4522,  2.5597])\n",
      "Epoch 91, loss 22.746044\n",
      "\t Params: tensor([ 2.7150, -2.2882])\n",
      "\t Grad:   tensor([-0.4514,  2.5553])\n",
      "Epoch 92, loss 22.678770\n",
      "\t Params: tensor([ 2.7195, -2.3137])\n",
      "\t Grad:   tensor([-0.4506,  2.5510])\n",
      "Epoch 93, loss 22.611717\n",
      "\t Params: tensor([ 2.7240, -2.3392])\n",
      "\t Grad:   tensor([-0.4499,  2.5466])\n",
      "Epoch 94, loss 22.544899\n",
      "\t Params: tensor([ 2.7285, -2.3646])\n",
      "\t Grad:   tensor([-0.4491,  2.5423])\n",
      "Epoch 95, loss 22.478304\n",
      "\t Params: tensor([ 2.7330, -2.3900])\n",
      "\t Grad:   tensor([-0.4483,  2.5380])\n",
      "Epoch 96, loss 22.411938\n",
      "\t Params: tensor([ 2.7374, -2.4153])\n",
      "\t Grad:   tensor([-0.4476,  2.5337])\n",
      "Epoch 97, loss 22.345795\n",
      "\t Params: tensor([ 2.7419, -2.4406])\n",
      "\t Grad:   tensor([-0.4468,  2.5294])\n",
      "Epoch 98, loss 22.279875\n",
      "\t Params: tensor([ 2.7464, -2.4658])\n",
      "\t Grad:   tensor([-0.4461,  2.5251])\n",
      "Epoch 99, loss 22.214186\n",
      "\t Params: tensor([ 2.7508, -2.4910])\n",
      "\t Grad:   tensor([-0.4453,  2.5208])\n",
      "Epoch 100, loss 22.148710\n",
      "\t Params: tensor([ 2.7553, -2.5162])\n",
      "\t Grad:   tensor([-0.4445,  2.5165])\n",
      "Epoch 101, loss 22.083464\n",
      "\t Params: tensor([ 2.7597, -2.5413])\n",
      "\t Grad:   tensor([-0.4438,  2.5122])\n",
      "Epoch 102, loss 22.018436\n",
      "\t Params: tensor([ 2.7641, -2.5664])\n",
      "\t Grad:   tensor([-0.4430,  2.5080])\n",
      "Epoch 103, loss 21.953630\n",
      "\t Params: tensor([ 2.7686, -2.5914])\n",
      "\t Grad:   tensor([-0.4423,  2.5037])\n",
      "Epoch 104, loss 21.889046\n",
      "\t Params: tensor([ 2.7730, -2.6164])\n",
      "\t Grad:   tensor([-0.4415,  2.4994])\n",
      "Epoch 105, loss 21.824677\n",
      "\t Params: tensor([ 2.7774, -2.6414])\n",
      "\t Grad:   tensor([-0.4408,  2.4952])\n",
      "Epoch 106, loss 21.760530\n",
      "\t Params: tensor([ 2.7818, -2.6663])\n",
      "\t Grad:   tensor([-0.4400,  2.4910])\n",
      "Epoch 107, loss 21.696600\n",
      "\t Params: tensor([ 2.7862, -2.6912])\n",
      "\t Grad:   tensor([-0.4393,  2.4867])\n",
      "Epoch 108, loss 21.632881\n",
      "\t Params: tensor([ 2.7906, -2.7160])\n",
      "\t Grad:   tensor([-0.4385,  2.4825])\n",
      "Epoch 109, loss 21.569389\n",
      "\t Params: tensor([ 2.7949, -2.7408])\n",
      "\t Grad:   tensor([-0.4378,  2.4783])\n",
      "Epoch 110, loss 21.506104\n",
      "\t Params: tensor([ 2.7993, -2.7655])\n",
      "\t Grad:   tensor([-0.4370,  2.4741])\n",
      "Epoch 111, loss 21.443037\n",
      "\t Params: tensor([ 2.8037, -2.7902])\n",
      "\t Grad:   tensor([-0.4363,  2.4699])\n",
      "Epoch 112, loss 21.380190\n",
      "\t Params: tensor([ 2.8080, -2.8149])\n",
      "\t Grad:   tensor([-0.4356,  2.4657])\n",
      "Epoch 113, loss 21.317547\n",
      "\t Params: tensor([ 2.8124, -2.8395])\n",
      "\t Grad:   tensor([-0.4348,  2.4615])\n",
      "Epoch 114, loss 21.255119\n",
      "\t Params: tensor([ 2.8167, -2.8641])\n",
      "\t Grad:   tensor([-0.4341,  2.4573])\n",
      "Epoch 115, loss 21.192904\n",
      "\t Params: tensor([ 2.8211, -2.8886])\n",
      "\t Grad:   tensor([-0.4334,  2.4531])\n",
      "Epoch 116, loss 21.130901\n",
      "\t Params: tensor([ 2.8254, -2.9131])\n",
      "\t Grad:   tensor([-0.4326,  2.4490])\n",
      "Epoch 117, loss 21.069105\n",
      "\t Params: tensor([ 2.8297, -2.9375])\n",
      "\t Grad:   tensor([-0.4319,  2.4448])\n",
      "Epoch 118, loss 21.007528\n",
      "\t Params: tensor([ 2.8340, -2.9619])\n",
      "\t Grad:   tensor([-0.4311,  2.4407])\n",
      "Epoch 119, loss 20.946152\n",
      "\t Params: tensor([ 2.8383, -2.9863])\n",
      "\t Grad:   tensor([-0.4304,  2.4365])\n",
      "Epoch 120, loss 20.884983\n",
      "\t Params: tensor([ 2.8426, -3.0106])\n",
      "\t Grad:   tensor([-0.4297,  2.4324])\n",
      "Epoch 121, loss 20.824028\n",
      "\t Params: tensor([ 2.8469, -3.0349])\n",
      "\t Grad:   tensor([-0.4290,  2.4282])\n",
      "Epoch 122, loss 20.763273\n",
      "\t Params: tensor([ 2.8512, -3.0592])\n",
      "\t Grad:   tensor([-0.4282,  2.4241])\n",
      "Epoch 123, loss 20.702726\n",
      "\t Params: tensor([ 2.8555, -3.0834])\n",
      "\t Grad:   tensor([-0.4275,  2.4200])\n",
      "Epoch 124, loss 20.642384\n",
      "\t Params: tensor([ 2.8597, -3.1075])\n",
      "\t Grad:   tensor([-0.4268,  2.4159])\n",
      "Epoch 125, loss 20.582251\n",
      "\t Params: tensor([ 2.8640, -3.1316])\n",
      "\t Grad:   tensor([-0.4261,  2.4118])\n",
      "Epoch 126, loss 20.522322\n",
      "\t Params: tensor([ 2.8682, -3.1557])\n",
      "\t Grad:   tensor([-0.4253,  2.4077])\n",
      "Epoch 127, loss 20.462593\n",
      "\t Params: tensor([ 2.8725, -3.1797])\n",
      "\t Grad:   tensor([-0.4246,  2.4036])\n",
      "Epoch 128, loss 20.403069\n",
      "\t Params: tensor([ 2.8767, -3.2037])\n",
      "\t Grad:   tensor([-0.4239,  2.3995])\n",
      "Epoch 129, loss 20.343746\n",
      "\t Params: tensor([ 2.8810, -3.2277])\n",
      "\t Grad:   tensor([-0.4232,  2.3954])\n",
      "Epoch 130, loss 20.284622\n",
      "\t Params: tensor([ 2.8852, -3.2516])\n",
      "\t Grad:   tensor([-0.4224,  2.3914])\n",
      "Epoch 131, loss 20.225704\n",
      "\t Params: tensor([ 2.8894, -3.2755])\n",
      "\t Grad:   tensor([-0.4217,  2.3873])\n",
      "Epoch 132, loss 20.166983\n",
      "\t Params: tensor([ 2.8936, -3.2993])\n",
      "\t Grad:   tensor([-0.4210,  2.3832])\n",
      "Epoch 133, loss 20.108461\n",
      "\t Params: tensor([ 2.8978, -3.3231])\n",
      "\t Grad:   tensor([-0.4203,  2.3792])\n",
      "Epoch 134, loss 20.050135\n",
      "\t Params: tensor([ 2.9020, -3.3469])\n",
      "\t Grad:   tensor([-0.4196,  2.3752])\n",
      "Epoch 135, loss 19.992012\n",
      "\t Params: tensor([ 2.9062, -3.3706])\n",
      "\t Grad:   tensor([-0.4189,  2.3711])\n",
      "Epoch 136, loss 19.934088\n",
      "\t Params: tensor([ 2.9104, -3.3942])\n",
      "\t Grad:   tensor([-0.4182,  2.3671])\n",
      "Epoch 137, loss 19.876352\n",
      "\t Params: tensor([ 2.9146, -3.4179])\n",
      "\t Grad:   tensor([-0.4174,  2.3631])\n",
      "Epoch 138, loss 19.818825\n",
      "\t Params: tensor([ 2.9187, -3.4415])\n",
      "\t Grad:   tensor([-0.4167,  2.3591])\n",
      "Epoch 139, loss 19.761480\n",
      "\t Params: tensor([ 2.9229, -3.4650])\n",
      "\t Grad:   tensor([-0.4160,  2.3550])\n",
      "Epoch 140, loss 19.704338\n",
      "\t Params: tensor([ 2.9270, -3.4885])\n",
      "\t Grad:   tensor([-0.4153,  2.3510])\n",
      "Epoch 141, loss 19.647383\n",
      "\t Params: tensor([ 2.9312, -3.5120])\n",
      "\t Grad:   tensor([-0.4146,  2.3471])\n",
      "Epoch 142, loss 19.590630\n",
      "\t Params: tensor([ 2.9353, -3.5354])\n",
      "\t Grad:   tensor([-0.4139,  2.3431])\n",
      "Epoch 143, loss 19.534063\n",
      "\t Params: tensor([ 2.9395, -3.5588])\n",
      "\t Grad:   tensor([-0.4132,  2.3391])\n",
      "Epoch 144, loss 19.477690\n",
      "\t Params: tensor([ 2.9436, -3.5822])\n",
      "\t Grad:   tensor([-0.4125,  2.3351])\n",
      "Epoch 145, loss 19.421507\n",
      "\t Params: tensor([ 2.9477, -3.6055])\n",
      "\t Grad:   tensor([-0.4118,  2.3311])\n",
      "Epoch 146, loss 19.365517\n",
      "\t Params: tensor([ 2.9518, -3.6287])\n",
      "\t Grad:   tensor([-0.4111,  2.3272])\n",
      "Epoch 147, loss 19.309715\n",
      "\t Params: tensor([ 2.9559, -3.6520])\n",
      "\t Grad:   tensor([-0.4104,  2.3232])\n",
      "Epoch 148, loss 19.254107\n",
      "\t Params: tensor([ 2.9600, -3.6752])\n",
      "\t Grad:   tensor([-0.4097,  2.3193])\n",
      "Epoch 149, loss 19.198685\n",
      "\t Params: tensor([ 2.9641, -3.6983])\n",
      "\t Grad:   tensor([-0.4090,  2.3153])\n",
      "Epoch 150, loss 19.143446\n",
      "\t Params: tensor([ 2.9682, -3.7214])\n",
      "\t Grad:   tensor([-0.4083,  2.3114])\n",
      "Epoch 151, loss 19.088400\n",
      "\t Params: tensor([ 2.9723, -3.7445])\n",
      "\t Grad:   tensor([-0.4076,  2.3075])\n",
      "Epoch 152, loss 19.033545\n",
      "\t Params: tensor([ 2.9763, -3.7675])\n",
      "\t Grad:   tensor([-0.4069,  2.3036])\n",
      "Epoch 153, loss 18.978868\n",
      "\t Params: tensor([ 2.9804, -3.7905])\n",
      "\t Grad:   tensor([-0.4062,  2.2997])\n",
      "Epoch 154, loss 18.924377\n",
      "\t Params: tensor([ 2.9844, -3.8135])\n",
      "\t Grad:   tensor([-0.4056,  2.2957])\n",
      "Epoch 155, loss 18.870081\n",
      "\t Params: tensor([ 2.9885, -3.8364])\n",
      "\t Grad:   tensor([-0.4049,  2.2918])\n",
      "Epoch 156, loss 18.815960\n",
      "\t Params: tensor([ 2.9925, -3.8593])\n",
      "\t Grad:   tensor([-0.4042,  2.2880])\n",
      "Epoch 157, loss 18.762022\n",
      "\t Params: tensor([ 2.9966, -3.8821])\n",
      "\t Grad:   tensor([-0.4035,  2.2841])\n",
      "Epoch 158, loss 18.708269\n",
      "\t Params: tensor([ 3.0006, -3.9049])\n",
      "\t Grad:   tensor([-0.4028,  2.2802])\n",
      "Epoch 159, loss 18.654703\n",
      "\t Params: tensor([ 3.0046, -3.9277])\n",
      "\t Grad:   tensor([-0.4021,  2.2763])\n",
      "Epoch 160, loss 18.601313\n",
      "\t Params: tensor([ 3.0086, -3.9504])\n",
      "\t Grad:   tensor([-0.4014,  2.2724])\n",
      "Epoch 161, loss 18.548111\n",
      "\t Params: tensor([ 3.0126, -3.9731])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Grad:   tensor([-0.4007,  2.2686])\n",
      "Epoch 162, loss 18.495083\n",
      "\t Params: tensor([ 3.0166, -3.9958])\n",
      "\t Grad:   tensor([-0.4001,  2.2647])\n",
      "Epoch 163, loss 18.442238\n",
      "\t Params: tensor([ 3.0206, -4.0184])\n",
      "\t Grad:   tensor([-0.3994,  2.2609])\n",
      "Epoch 164, loss 18.389570\n",
      "\t Params: tensor([ 3.0246, -4.0409])\n",
      "\t Grad:   tensor([-0.3987,  2.2570])\n",
      "Epoch 165, loss 18.337080\n",
      "\t Params: tensor([ 3.0286, -4.0635])\n",
      "\t Grad:   tensor([-0.3980,  2.2532])\n",
      "Epoch 166, loss 18.284777\n",
      "\t Params: tensor([ 3.0326, -4.0860])\n",
      "\t Grad:   tensor([-0.3974,  2.2494])\n",
      "Epoch 167, loss 18.232643\n",
      "\t Params: tensor([ 3.0365, -4.1084])\n",
      "\t Grad:   tensor([-0.3967,  2.2456])\n",
      "Epoch 168, loss 18.180687\n",
      "\t Params: tensor([ 3.0405, -4.1308])\n",
      "\t Grad:   tensor([-0.3960,  2.2417])\n",
      "Epoch 169, loss 18.128904\n",
      "\t Params: tensor([ 3.0445, -4.1532])\n",
      "\t Grad:   tensor([-0.3953,  2.2379])\n",
      "Epoch 170, loss 18.077299\n",
      "\t Params: tensor([ 3.0484, -4.1756])\n",
      "\t Grad:   tensor([-0.3947,  2.2341])\n",
      "Epoch 171, loss 18.025879\n",
      "\t Params: tensor([ 3.0523, -4.1979])\n",
      "\t Grad:   tensor([-0.3940,  2.2303])\n",
      "Epoch 172, loss 17.974623\n",
      "\t Params: tensor([ 3.0563, -4.2201])\n",
      "\t Grad:   tensor([-0.3933,  2.2266])\n",
      "Epoch 173, loss 17.923546\n",
      "\t Params: tensor([ 3.0602, -4.2424])\n",
      "\t Grad:   tensor([-0.3927,  2.2228])\n",
      "Epoch 174, loss 17.872641\n",
      "\t Params: tensor([ 3.0641, -4.2646])\n",
      "\t Grad:   tensor([-0.3920,  2.2190])\n",
      "Epoch 175, loss 17.821907\n",
      "\t Params: tensor([ 3.0680, -4.2867])\n",
      "\t Grad:   tensor([-0.3913,  2.2152])\n",
      "Epoch 176, loss 17.771343\n",
      "\t Params: tensor([ 3.0719, -4.3088])\n",
      "\t Grad:   tensor([-0.3907,  2.2115])\n",
      "Epoch 177, loss 17.720955\n",
      "\t Params: tensor([ 3.0758, -4.3309])\n",
      "\t Grad:   tensor([-0.3900,  2.2077])\n",
      "Epoch 178, loss 17.670738\n",
      "\t Params: tensor([ 3.0797, -4.3529])\n",
      "\t Grad:   tensor([-0.3893,  2.2040])\n",
      "Epoch 179, loss 17.620691\n",
      "\t Params: tensor([ 3.0836, -4.3749])\n",
      "\t Grad:   tensor([-0.3887,  2.2002])\n",
      "Epoch 180, loss 17.570814\n",
      "\t Params: tensor([ 3.0875, -4.3969])\n",
      "\t Grad:   tensor([-0.3880,  2.1965])\n",
      "Epoch 181, loss 17.521105\n",
      "\t Params: tensor([ 3.0914, -4.4188])\n",
      "\t Grad:   tensor([-0.3873,  2.1927])\n",
      "Epoch 182, loss 17.471563\n",
      "\t Params: tensor([ 3.0952, -4.4407])\n",
      "\t Grad:   tensor([-0.3867,  2.1890])\n",
      "Epoch 183, loss 17.422194\n",
      "\t Params: tensor([ 3.0991, -4.4626])\n",
      "\t Grad:   tensor([-0.3860,  2.1853])\n",
      "Epoch 184, loss 17.372992\n",
      "\t Params: tensor([ 3.1030, -4.4844])\n",
      "\t Grad:   tensor([-0.3854,  2.1816])\n",
      "Epoch 185, loss 17.323954\n",
      "\t Params: tensor([ 3.1068, -4.5062])\n",
      "\t Grad:   tensor([-0.3847,  2.1779])\n",
      "Epoch 186, loss 17.275085\n",
      "\t Params: tensor([ 3.1106, -4.5279])\n",
      "\t Grad:   tensor([-0.3841,  2.1742])\n",
      "Epoch 187, loss 17.226379\n",
      "\t Params: tensor([ 3.1145, -4.5496])\n",
      "\t Grad:   tensor([-0.3834,  2.1705])\n",
      "Epoch 188, loss 17.177839\n",
      "\t Params: tensor([ 3.1183, -4.5713])\n",
      "\t Grad:   tensor([-0.3828,  2.1668])\n",
      "Epoch 189, loss 17.129467\n",
      "\t Params: tensor([ 3.1221, -4.5929])\n",
      "\t Grad:   tensor([-0.3821,  2.1631])\n",
      "Epoch 190, loss 17.081255\n",
      "\t Params: tensor([ 3.1259, -4.6145])\n",
      "\t Grad:   tensor([-0.3815,  2.1594])\n",
      "Epoch 191, loss 17.033207\n",
      "\t Params: tensor([ 3.1298, -4.6361])\n",
      "\t Grad:   tensor([-0.3808,  2.1558])\n",
      "Epoch 192, loss 16.985327\n",
      "\t Params: tensor([ 3.1336, -4.6576])\n",
      "\t Grad:   tensor([-0.3802,  2.1521])\n",
      "Epoch 193, loss 16.937605\n",
      "\t Params: tensor([ 3.1374, -4.6791])\n",
      "\t Grad:   tensor([-0.3795,  2.1485])\n",
      "Epoch 194, loss 16.890047\n",
      "\t Params: tensor([ 3.1411, -4.7005])\n",
      "\t Grad:   tensor([-0.3789,  2.1448])\n",
      "Epoch 195, loss 16.842649\n",
      "\t Params: tensor([ 3.1449, -4.7219])\n",
      "\t Grad:   tensor([-0.3782,  2.1412])\n",
      "Epoch 196, loss 16.795412\n",
      "\t Params: tensor([ 3.1487, -4.7433])\n",
      "\t Grad:   tensor([-0.3776,  2.1375])\n",
      "Epoch 197, loss 16.748339\n",
      "\t Params: tensor([ 3.1525, -4.7646])\n",
      "\t Grad:   tensor([-0.3770,  2.1339])\n",
      "Epoch 198, loss 16.701424\n",
      "\t Params: tensor([ 3.1562, -4.7859])\n",
      "\t Grad:   tensor([-0.3763,  2.1303])\n",
      "Epoch 199, loss 16.654661\n",
      "\t Params: tensor([ 3.1600, -4.8072])\n",
      "\t Grad:   tensor([-0.3757,  2.1267])\n",
      "Epoch 200, loss 16.608065\n",
      "\t Params: tensor([ 3.1637, -4.8284])\n",
      "\t Grad:   tensor([-0.3750,  2.1230])\n",
      "Epoch 201, loss 16.561625\n",
      "\t Params: tensor([ 3.1675, -4.8496])\n",
      "\t Grad:   tensor([-0.3744,  2.1194])\n",
      "Epoch 202, loss 16.515343\n",
      "\t Params: tensor([ 3.1712, -4.8708])\n",
      "\t Grad:   tensor([-0.3738,  2.1158])\n",
      "Epoch 203, loss 16.469219\n",
      "\t Params: tensor([ 3.1750, -4.8919])\n",
      "\t Grad:   tensor([-0.3731,  2.1122])\n",
      "Epoch 204, loss 16.423250\n",
      "\t Params: tensor([ 3.1787, -4.9130])\n",
      "\t Grad:   tensor([-0.3725,  2.1087])\n",
      "Epoch 205, loss 16.377434\n",
      "\t Params: tensor([ 3.1824, -4.9341])\n",
      "\t Grad:   tensor([-0.3719,  2.1051])\n",
      "Epoch 206, loss 16.331776\n",
      "\t Params: tensor([ 3.1861, -4.9551])\n",
      "\t Grad:   tensor([-0.3712,  2.1015])\n",
      "Epoch 207, loss 16.286276\n",
      "\t Params: tensor([ 3.1898, -4.9760])\n",
      "\t Grad:   tensor([-0.3706,  2.0979])\n",
      "Epoch 208, loss 16.240925\n",
      "\t Params: tensor([ 3.1935, -4.9970])\n",
      "\t Grad:   tensor([-0.3700,  2.0944])\n",
      "Epoch 209, loss 16.195734\n",
      "\t Params: tensor([ 3.1972, -5.0179])\n",
      "\t Grad:   tensor([-0.3694,  2.0908])\n",
      "Epoch 210, loss 16.150694\n",
      "\t Params: tensor([ 3.2009, -5.0388])\n",
      "\t Grad:   tensor([-0.3687,  2.0873])\n",
      "Epoch 211, loss 16.105806\n",
      "\t Params: tensor([ 3.2046, -5.0596])\n",
      "\t Grad:   tensor([-0.3681,  2.0837])\n",
      "Epoch 212, loss 16.061071\n",
      "\t Params: tensor([ 3.2082, -5.0804])\n",
      "\t Grad:   tensor([-0.3675,  2.0802])\n",
      "Epoch 213, loss 16.016487\n",
      "\t Params: tensor([ 3.2119, -5.1012])\n",
      "\t Grad:   tensor([-0.3668,  2.0766])\n",
      "Epoch 214, loss 15.972058\n",
      "\t Params: tensor([ 3.2156, -5.1219])\n",
      "\t Grad:   tensor([-0.3662,  2.0731])\n",
      "Epoch 215, loss 15.927777\n",
      "\t Params: tensor([ 3.2192, -5.1426])\n",
      "\t Grad:   tensor([-0.3656,  2.0696])\n",
      "Epoch 216, loss 15.883645\n",
      "\t Params: tensor([ 3.2229, -5.1633])\n",
      "\t Grad:   tensor([-0.3650,  2.0661])\n",
      "Epoch 217, loss 15.839664\n",
      "\t Params: tensor([ 3.2265, -5.1839])\n",
      "\t Grad:   tensor([-0.3644,  2.0626])\n",
      "Epoch 218, loss 15.795832\n",
      "\t Params: tensor([ 3.2302, -5.2045])\n",
      "\t Grad:   tensor([-0.3637,  2.0591])\n",
      "Epoch 219, loss 15.752152\n",
      "\t Params: tensor([ 3.2338, -5.2250])\n",
      "\t Grad:   tensor([-0.3631,  2.0556])\n",
      "Epoch 220, loss 15.708612\n",
      "\t Params: tensor([ 3.2374, -5.2456])\n",
      "\t Grad:   tensor([-0.3625,  2.0521])\n",
      "Epoch 221, loss 15.665228\n",
      "\t Params: tensor([ 3.2410, -5.2660])\n",
      "\t Grad:   tensor([-0.3619,  2.0486])\n",
      "Epoch 222, loss 15.621990\n",
      "\t Params: tensor([ 3.2447, -5.2865])\n",
      "\t Grad:   tensor([-0.3613,  2.0451])\n",
      "Epoch 223, loss 15.578897\n",
      "\t Params: tensor([ 3.2483, -5.3069])\n",
      "\t Grad:   tensor([-0.3607,  2.0416])\n",
      "Epoch 224, loss 15.535950\n",
      "\t Params: tensor([ 3.2519, -5.3273])\n",
      "\t Grad:   tensor([-0.3601,  2.0382])\n",
      "Epoch 225, loss 15.493152\n",
      "\t Params: tensor([ 3.2555, -5.3476])\n",
      "\t Grad:   tensor([-0.3594,  2.0347])\n",
      "Epoch 226, loss 15.450497\n",
      "\t Params: tensor([ 3.2590, -5.3680])\n",
      "\t Grad:   tensor([-0.3588,  2.0312])\n",
      "Epoch 227, loss 15.407981\n",
      "\t Params: tensor([ 3.2626, -5.3882])\n",
      "\t Grad:   tensor([-0.3582,  2.0278])\n",
      "Epoch 228, loss 15.365615\n",
      "\t Params: tensor([ 3.2662, -5.4085])\n",
      "\t Grad:   tensor([-0.3576,  2.0243])\n",
      "Epoch 229, loss 15.323395\n",
      "\t Params: tensor([ 3.2698, -5.4287])\n",
      "\t Grad:   tensor([-0.3570,  2.0209])\n",
      "Epoch 230, loss 15.281318\n",
      "\t Params: tensor([ 3.2733, -5.4489])\n",
      "\t Grad:   tensor([-0.3564,  2.0175])\n",
      "Epoch 231, loss 15.239380\n",
      "\t Params: tensor([ 3.2769, -5.4690])\n",
      "\t Grad:   tensor([-0.3558,  2.0140])\n",
      "Epoch 232, loss 15.197586\n",
      "\t Params: tensor([ 3.2804, -5.4891])\n",
      "\t Grad:   tensor([-0.3552,  2.0106])\n",
      "Epoch 233, loss 15.155931\n",
      "\t Params: tensor([ 3.2840, -5.5092])\n",
      "\t Grad:   tensor([-0.3546,  2.0072])\n",
      "Epoch 234, loss 15.114425\n",
      "\t Params: tensor([ 3.2875, -5.5292])\n",
      "\t Grad:   tensor([-0.3540,  2.0038])\n",
      "Epoch 235, loss 15.073053\n",
      "\t Params: tensor([ 3.2911, -5.5492])\n",
      "\t Grad:   tensor([-0.3534,  2.0004])\n",
      "Epoch 236, loss 15.031823\n",
      "\t Params: tensor([ 3.2946, -5.5692])\n",
      "\t Grad:   tensor([-0.3528,  1.9970])\n",
      "Epoch 237, loss 14.990737\n",
      "\t Params: tensor([ 3.2981, -5.5891])\n",
      "\t Grad:   tensor([-0.3522,  1.9936])\n",
      "Epoch 238, loss 14.949784\n",
      "\t Params: tensor([ 3.3016, -5.6090])\n",
      "\t Grad:   tensor([-0.3516,  1.9902])\n",
      "Epoch 239, loss 14.908973\n",
      "\t Params: tensor([ 3.3051, -5.6289])\n",
      "\t Grad:   tensor([-0.3510,  1.9868])\n",
      "Epoch 240, loss 14.868304\n",
      "\t Params: tensor([ 3.3086, -5.6487])\n",
      "\t Grad:   tensor([-0.3504,  1.9835])\n",
      "Epoch 241, loss 14.827767\n",
      "\t Params: tensor([ 3.3121, -5.6685])\n",
      "\t Grad:   tensor([-0.3498,  1.9801])\n",
      "Epoch 242, loss 14.787370\n",
      "\t Params: tensor([ 3.3156, -5.6883])\n",
      "\t Grad:   tensor([-0.3492,  1.9767])\n",
      "Epoch 243, loss 14.747110\n",
      "\t Params: tensor([ 3.3191, -5.7080])\n",
      "\t Grad:   tensor([-0.3486,  1.9734])\n",
      "Epoch 244, loss 14.706989\n",
      "\t Params: tensor([ 3.3226, -5.7277])\n",
      "\t Grad:   tensor([-0.3480,  1.9700])\n",
      "Epoch 245, loss 14.667002\n",
      "\t Params: tensor([ 3.3261, -5.7474])\n",
      "\t Grad:   tensor([-0.3474,  1.9667])\n",
      "Epoch 246, loss 14.627149\n",
      "\t Params: tensor([ 3.3295, -5.7670])\n",
      "\t Grad:   tensor([-0.3468,  1.9633])\n",
      "Epoch 247, loss 14.587436\n",
      "\t Params: tensor([ 3.3330, -5.7866])\n",
      "\t Grad:   tensor([-0.3462,  1.9600])\n",
      "Epoch 248, loss 14.547854\n",
      "\t Params: tensor([ 3.3365, -5.8062])\n",
      "\t Grad:   tensor([-0.3456,  1.9567])\n",
      "Epoch 249, loss 14.508408\n",
      "\t Params: tensor([ 3.3399, -5.8257])\n",
      "\t Grad:   tensor([-0.3451,  1.9533])\n",
      "Epoch 250, loss 14.469095\n",
      "\t Params: tensor([ 3.3434, -5.8452])\n",
      "\t Grad:   tensor([-0.3445,  1.9500])\n",
      "Epoch 251, loss 14.429919\n",
      "\t Params: tensor([ 3.3468, -5.8647])\n",
      "\t Grad:   tensor([-0.3439,  1.9467])\n",
      "Epoch 252, loss 14.390872\n",
      "\t Params: tensor([ 3.3502, -5.8841])\n",
      "\t Grad:   tensor([-0.3433,  1.9434])\n",
      "Epoch 253, loss 14.351956\n",
      "\t Params: tensor([ 3.3537, -5.9035])\n",
      "\t Grad:   tensor([-0.3427,  1.9401])\n",
      "Epoch 254, loss 14.313177\n",
      "\t Params: tensor([ 3.3571, -5.9229])\n",
      "\t Grad:   tensor([-0.3421,  1.9368])\n",
      "Epoch 255, loss 14.274525\n",
      "\t Params: tensor([ 3.3605, -5.9422])\n",
      "\t Grad:   tensor([-0.3416,  1.9335])\n",
      "Epoch 256, loss 14.236008\n",
      "\t Params: tensor([ 3.3639, -5.9615])\n",
      "\t Grad:   tensor([-0.3410,  1.9302])\n",
      "Epoch 257, loss 14.197620\n",
      "\t Params: tensor([ 3.3673, -5.9808])\n",
      "\t Grad:   tensor([-0.3404,  1.9269])\n",
      "Epoch 258, loss 14.159363\n",
      "\t Params: tensor([ 3.3707, -6.0000])\n",
      "\t Grad:   tensor([-0.3398,  1.9237])\n",
      "Epoch 259, loss 14.121234\n",
      "\t Params: tensor([ 3.3741, -6.0192])\n",
      "\t Grad:   tensor([-0.3392,  1.9204])\n",
      "Epoch 260, loss 14.083237\n",
      "\t Params: tensor([ 3.3775, -6.0384])\n",
      "\t Grad:   tensor([-0.3387,  1.9171])\n",
      "Epoch 261, loss 14.045368\n",
      "\t Params: tensor([ 3.3809, -6.0576])\n",
      "\t Grad:   tensor([-0.3381,  1.9139])\n",
      "Epoch 262, loss 14.007627\n",
      "\t Params: tensor([ 3.3842, -6.0767])\n",
      "\t Grad:   tensor([-0.3375,  1.9106])\n",
      "Epoch 263, loss 13.970016\n",
      "\t Params: tensor([ 3.3876, -6.0957])\n",
      "\t Grad:   tensor([-0.3369,  1.9074])\n",
      "Epoch 264, loss 13.932532\n",
      "\t Params: tensor([ 3.3910, -6.1148])\n",
      "\t Grad:   tensor([-0.3364,  1.9041])\n",
      "Epoch 265, loss 13.895172\n",
      "\t Params: tensor([ 3.3943, -6.1338])\n",
      "\t Grad:   tensor([-0.3358,  1.9009])\n",
      "Epoch 266, loss 13.857942\n",
      "\t Params: tensor([ 3.3977, -6.1528])\n",
      "\t Grad:   tensor([-0.3352,  1.8977])\n",
      "Epoch 267, loss 13.820837\n",
      "\t Params: tensor([ 3.4010, -6.1717])\n",
      "\t Grad:   tensor([-0.3347,  1.8945])\n",
      "Epoch 268, loss 13.783858\n",
      "\t Params: tensor([ 3.4044, -6.1906])\n",
      "\t Grad:   tensor([-0.3341,  1.8912])\n",
      "Epoch 269, loss 13.747006\n",
      "\t Params: tensor([ 3.4077, -6.2095])\n",
      "\t Grad:   tensor([-0.3335,  1.8880])\n",
      "Epoch 270, loss 13.710278\n",
      "\t Params: tensor([ 3.4110, -6.2284])\n",
      "\t Grad:   tensor([-0.3330,  1.8848])\n",
      "Epoch 271, loss 13.673676\n",
      "\t Params: tensor([ 3.4144, -6.2472])\n",
      "\t Grad:   tensor([-0.3324,  1.8816])\n",
      "Epoch 272, loss 13.637196\n",
      "\t Params: tensor([ 3.4177, -6.2660])\n",
      "\t Grad:   tensor([-0.3318,  1.8784])\n",
      "Epoch 273, loss 13.600842\n",
      "\t Params: tensor([ 3.4210, -6.2847])\n",
      "\t Grad:   tensor([-0.3313,  1.8752])\n",
      "Epoch 274, loss 13.564609\n",
      "\t Params: tensor([ 3.4243, -6.3034])\n",
      "\t Grad:   tensor([-0.3307,  1.8720])\n",
      "Epoch 275, loss 13.528501\n",
      "\t Params: tensor([ 3.4276, -6.3221])\n",
      "\t Grad:   tensor([-0.3301,  1.8689])\n",
      "Epoch 276, loss 13.492515\n",
      "\t Params: tensor([ 3.4309, -6.3408])\n",
      "\t Grad:   tensor([-0.3296,  1.8657])\n",
      "Epoch 277, loss 13.456651\n",
      "\t Params: tensor([ 3.4342, -6.3594])\n",
      "\t Grad:   tensor([-0.3290,  1.8625])\n",
      "Epoch 278, loss 13.420910\n",
      "\t Params: tensor([ 3.4375, -6.3780])\n",
      "\t Grad:   tensor([-0.3285,  1.8594])\n",
      "Epoch 279, loss 13.385287\n",
      "\t Params: tensor([ 3.4407, -6.3966])\n",
      "\t Grad:   tensor([-0.3279,  1.8562])\n",
      "Epoch 280, loss 13.349787\n",
      "\t Params: tensor([ 3.4440, -6.4151])\n",
      "\t Grad:   tensor([-0.3273,  1.8530])\n",
      "Epoch 281, loss 13.314410\n",
      "\t Params: tensor([ 3.4473, -6.4336])\n",
      "\t Grad:   tensor([-0.3268,  1.8499])\n",
      "Epoch 282, loss 13.279148\n",
      "\t Params: tensor([ 3.4506, -6.4520])\n",
      "\t Grad:   tensor([-0.3262,  1.8468])\n",
      "Epoch 283, loss 13.244009\n",
      "\t Params: tensor([ 3.4538, -6.4705])\n",
      "\t Grad:   tensor([-0.3257,  1.8436])\n",
      "Epoch 284, loss 13.208993\n",
      "\t Params: tensor([ 3.4571, -6.4889])\n",
      "\t Grad:   tensor([-0.3251,  1.8405])\n",
      "Epoch 285, loss 13.174088\n",
      "\t Params: tensor([ 3.4603, -6.5073])\n",
      "\t Grad:   tensor([-0.3246,  1.8374])\n",
      "Epoch 286, loss 13.139307\n",
      "\t Params: tensor([ 3.4635, -6.5256])\n",
      "\t Grad:   tensor([-0.3240,  1.8342])\n",
      "Epoch 287, loss 13.104638\n",
      "\t Params: tensor([ 3.4668, -6.5439])\n",
      "\t Grad:   tensor([-0.3235,  1.8311])\n",
      "Epoch 288, loss 13.070093\n",
      "\t Params: tensor([ 3.4700, -6.5622])\n",
      "\t Grad:   tensor([-0.3229,  1.8280])\n",
      "Epoch 289, loss 13.035663\n",
      "\t Params: tensor([ 3.4732, -6.5804])\n",
      "\t Grad:   tensor([-0.3224,  1.8249])\n",
      "Epoch 290, loss 13.001349\n",
      "\t Params: tensor([ 3.4765, -6.5987])\n",
      "\t Grad:   tensor([-0.3218,  1.8218])\n",
      "Epoch 291, loss 12.967154\n",
      "\t Params: tensor([ 3.4797, -6.6169])\n",
      "\t Grad:   tensor([-0.3213,  1.8187])\n",
      "Epoch 292, loss 12.933074\n",
      "\t Params: tensor([ 3.4829, -6.6350])\n",
      "\t Grad:   tensor([-0.3207,  1.8156])\n",
      "Epoch 293, loss 12.899109\n",
      "\t Params: tensor([ 3.4861, -6.6531])\n",
      "\t Grad:   tensor([-0.3202,  1.8125])\n",
      "Epoch 294, loss 12.865259\n",
      "\t Params: tensor([ 3.4893, -6.6712])\n",
      "\t Grad:   tensor([-0.3196,  1.8095])\n",
      "Epoch 295, loss 12.831525\n",
      "\t Params: tensor([ 3.4925, -6.6893])\n",
      "\t Grad:   tensor([-0.3191,  1.8064])\n",
      "Epoch 296, loss 12.797904\n",
      "\t Params: tensor([ 3.4956, -6.7073])\n",
      "\t Grad:   tensor([-0.3186,  1.8033])\n",
      "Epoch 297, loss 12.764399\n",
      "\t Params: tensor([ 3.4988, -6.7253])\n",
      "\t Grad:   tensor([-0.3180,  1.8003])\n",
      "Epoch 298, loss 12.731007\n",
      "\t Params: tensor([ 3.5020, -6.7433])\n",
      "\t Grad:   tensor([-0.3175,  1.7972])\n",
      "Epoch 299, loss 12.697727\n",
      "\t Params: tensor([ 3.5052, -6.7612])\n",
      "\t Grad:   tensor([-0.3169,  1.7941])\n",
      "Epoch 300, loss 12.664560\n",
      "\t Params: tensor([ 3.5083, -6.7792])\n",
      "\t Grad:   tensor([-0.3164,  1.7911])\n",
      "Epoch 301, loss 12.631507\n",
      "\t Params: tensor([ 3.5115, -6.7970])\n",
      "\t Grad:   tensor([-0.3159,  1.7881])\n",
      "Epoch 302, loss 12.598566\n",
      "\t Params: tensor([ 3.5146, -6.8149])\n",
      "\t Grad:   tensor([-0.3153,  1.7850])\n",
      "Epoch 303, loss 12.565738\n",
      "\t Params: tensor([ 3.5178, -6.8327])\n",
      "\t Grad:   tensor([-0.3148,  1.7820])\n",
      "Epoch 304, loss 12.533021\n",
      "\t Params: tensor([ 3.5209, -6.8505])\n",
      "\t Grad:   tensor([-0.3143,  1.7790])\n",
      "Epoch 305, loss 12.500415\n",
      "\t Params: tensor([ 3.5241, -6.8683])\n",
      "\t Grad:   tensor([-0.3137,  1.7759])\n",
      "Epoch 306, loss 12.467919\n",
      "\t Params: tensor([ 3.5272, -6.8860])\n",
      "\t Grad:   tensor([-0.3132,  1.7729])\n",
      "Epoch 307, loss 12.435533\n",
      "\t Params: tensor([ 3.5303, -6.9037])\n",
      "\t Grad:   tensor([-0.3127,  1.7699])\n",
      "Epoch 308, loss 12.403255\n",
      "\t Params: tensor([ 3.5335, -6.9213])\n",
      "\t Grad:   tensor([-0.3121,  1.7669])\n",
      "Epoch 309, loss 12.371088\n",
      "\t Params: tensor([ 3.5366, -6.9390])\n",
      "\t Grad:   tensor([-0.3116,  1.7639])\n",
      "Epoch 310, loss 12.339031\n",
      "\t Params: tensor([ 3.5397, -6.9566])\n",
      "\t Grad:   tensor([-0.3111,  1.7609])\n",
      "Epoch 311, loss 12.307083\n",
      "\t Params: tensor([ 3.5428, -6.9742])\n",
      "\t Grad:   tensor([-0.3105,  1.7579])\n",
      "Epoch 312, loss 12.275247\n",
      "\t Params: tensor([ 3.5459, -6.9917])\n",
      "\t Grad:   tensor([-0.3100,  1.7549])\n",
      "Epoch 313, loss 12.243509\n",
      "\t Params: tensor([ 3.5490, -7.0092])\n",
      "\t Grad:   tensor([-0.3095,  1.7519])\n",
      "Epoch 314, loss 12.211887\n",
      "\t Params: tensor([ 3.5521, -7.0267])\n",
      "\t Grad:   tensor([-0.3090,  1.7490])\n",
      "Epoch 315, loss 12.180370\n",
      "\t Params: tensor([ 3.5552, -7.0442])\n",
      "\t Grad:   tensor([-0.3084,  1.7460])\n",
      "Epoch 316, loss 12.148962\n",
      "\t Params: tensor([ 3.5582, -7.0616])\n",
      "\t Grad:   tensor([-0.3079,  1.7430])\n",
      "Epoch 317, loss 12.117655\n",
      "\t Params: tensor([ 3.5613, -7.0790])\n",
      "\t Grad:   tensor([-0.3074,  1.7401])\n",
      "Epoch 318, loss 12.086463\n",
      "\t Params: tensor([ 3.5644, -7.0964])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Grad:   tensor([-0.3069,  1.7371])\n",
      "Epoch 319, loss 12.055373\n",
      "\t Params: tensor([ 3.5674, -7.1137])\n",
      "\t Grad:   tensor([-0.3063,  1.7342])\n",
      "Epoch 320, loss 12.024384\n",
      "\t Params: tensor([ 3.5705, -7.1310])\n",
      "\t Grad:   tensor([-0.3058,  1.7312])\n",
      "Epoch 321, loss 11.993508\n",
      "\t Params: tensor([ 3.5736, -7.1483])\n",
      "\t Grad:   tensor([-0.3053,  1.7283])\n",
      "Epoch 322, loss 11.962732\n",
      "\t Params: tensor([ 3.5766, -7.1656])\n",
      "\t Grad:   tensor([-0.3048,  1.7253])\n",
      "Epoch 323, loss 11.932056\n",
      "\t Params: tensor([ 3.5796, -7.1828])\n",
      "\t Grad:   tensor([-0.3043,  1.7224])\n",
      "Epoch 324, loss 11.901492\n",
      "\t Params: tensor([ 3.5827, -7.2000])\n",
      "\t Grad:   tensor([-0.3037,  1.7195])\n",
      "Epoch 325, loss 11.871029\n",
      "\t Params: tensor([ 3.5857, -7.2172])\n",
      "\t Grad:   tensor([-0.3032,  1.7166])\n",
      "Epoch 326, loss 11.840671\n",
      "\t Params: tensor([ 3.5887, -7.2343])\n",
      "\t Grad:   tensor([-0.3027,  1.7136])\n",
      "Epoch 327, loss 11.810413\n",
      "\t Params: tensor([ 3.5918, -7.2514])\n",
      "\t Grad:   tensor([-0.3022,  1.7107])\n",
      "Epoch 328, loss 11.780257\n",
      "\t Params: tensor([ 3.5948, -7.2685])\n",
      "\t Grad:   tensor([-0.3017,  1.7078])\n",
      "Epoch 329, loss 11.750208\n",
      "\t Params: tensor([ 3.5978, -7.2855])\n",
      "\t Grad:   tensor([-0.3012,  1.7049])\n",
      "Epoch 330, loss 11.720258\n",
      "\t Params: tensor([ 3.6008, -7.3026])\n",
      "\t Grad:   tensor([-0.3007,  1.7020])\n",
      "Epoch 331, loss 11.690412\n",
      "\t Params: tensor([ 3.6038, -7.3196])\n",
      "\t Grad:   tensor([-0.3002,  1.6991])\n",
      "Epoch 332, loss 11.660664\n",
      "\t Params: tensor([ 3.6068, -7.3365])\n",
      "\t Grad:   tensor([-0.2996,  1.6963])\n",
      "Epoch 333, loss 11.631016\n",
      "\t Params: tensor([ 3.6098, -7.3535])\n",
      "\t Grad:   tensor([-0.2991,  1.6934])\n",
      "Epoch 334, loss 11.601473\n",
      "\t Params: tensor([ 3.6128, -7.3704])\n",
      "\t Grad:   tensor([-0.2986,  1.6905])\n",
      "Epoch 335, loss 11.572030\n",
      "\t Params: tensor([ 3.6158, -7.3872])\n",
      "\t Grad:   tensor([-0.2981,  1.6876])\n",
      "Epoch 336, loss 11.542686\n",
      "\t Params: tensor([ 3.6187, -7.4041])\n",
      "\t Grad:   tensor([-0.2976,  1.6848])\n",
      "Epoch 337, loss 11.513440\n",
      "\t Params: tensor([ 3.6217, -7.4209])\n",
      "\t Grad:   tensor([-0.2971,  1.6819])\n",
      "Epoch 338, loss 11.484293\n",
      "\t Params: tensor([ 3.6247, -7.4377])\n",
      "\t Grad:   tensor([-0.2966,  1.6790])\n",
      "Epoch 339, loss 11.455247\n",
      "\t Params: tensor([ 3.6276, -7.4545])\n",
      "\t Grad:   tensor([-0.2961,  1.6762])\n",
      "Epoch 340, loss 11.426300\n",
      "\t Params: tensor([ 3.6306, -7.4712])\n",
      "\t Grad:   tensor([-0.2956,  1.6733])\n",
      "Epoch 341, loss 11.397448\n",
      "\t Params: tensor([ 3.6335, -7.4879])\n",
      "\t Grad:   tensor([-0.2951,  1.6705])\n",
      "Epoch 342, loss 11.368697\n",
      "\t Params: tensor([ 3.6365, -7.5046])\n",
      "\t Grad:   tensor([-0.2946,  1.6677])\n",
      "Epoch 343, loss 11.340043\n",
      "\t Params: tensor([ 3.6394, -7.5212])\n",
      "\t Grad:   tensor([-0.2941,  1.6648])\n",
      "Epoch 344, loss 11.311487\n",
      "\t Params: tensor([ 3.6424, -7.5378])\n",
      "\t Grad:   tensor([-0.2936,  1.6620])\n",
      "Epoch 345, loss 11.283028\n",
      "\t Params: tensor([ 3.6453, -7.5544])\n",
      "\t Grad:   tensor([-0.2931,  1.6592])\n",
      "Epoch 346, loss 11.254662\n",
      "\t Params: tensor([ 3.6482, -7.5710])\n",
      "\t Grad:   tensor([-0.2926,  1.6564])\n",
      "Epoch 347, loss 11.226396\n",
      "\t Params: tensor([ 3.6511, -7.5875])\n",
      "\t Grad:   tensor([-0.2921,  1.6535])\n",
      "Epoch 348, loss 11.198221\n",
      "\t Params: tensor([ 3.6541, -7.6040])\n",
      "\t Grad:   tensor([-0.2916,  1.6507])\n",
      "Epoch 349, loss 11.170149\n",
      "\t Params: tensor([ 3.6570, -7.6205])\n",
      "\t Grad:   tensor([-0.2911,  1.6479])\n",
      "Epoch 350, loss 11.142170\n",
      "\t Params: tensor([ 3.6599, -7.6370])\n",
      "\t Grad:   tensor([-0.2906,  1.6451])\n",
      "Epoch 351, loss 11.114283\n",
      "\t Params: tensor([ 3.6628, -7.6534])\n",
      "\t Grad:   tensor([-0.2901,  1.6423])\n",
      "Epoch 352, loss 11.086493\n",
      "\t Params: tensor([ 3.6657, -7.6698])\n",
      "\t Grad:   tensor([-0.2896,  1.6395])\n",
      "Epoch 353, loss 11.058796\n",
      "\t Params: tensor([ 3.6686, -7.6861])\n",
      "\t Grad:   tensor([-0.2892,  1.6368])\n",
      "Epoch 354, loss 11.031192\n",
      "\t Params: tensor([ 3.6714, -7.7025])\n",
      "\t Grad:   tensor([-0.2886,  1.6340])\n",
      "Epoch 355, loss 11.003686\n",
      "\t Params: tensor([ 3.6743, -7.7188])\n",
      "\t Grad:   tensor([-0.2882,  1.6312])\n",
      "Epoch 356, loss 10.976271\n",
      "\t Params: tensor([ 3.6772, -7.7351])\n",
      "\t Grad:   tensor([-0.2877,  1.6284])\n",
      "Epoch 357, loss 10.948948\n",
      "\t Params: tensor([ 3.6801, -7.7513])\n",
      "\t Grad:   tensor([-0.2872,  1.6257])\n",
      "Epoch 358, loss 10.921718\n",
      "\t Params: tensor([ 3.6829, -7.7676])\n",
      "\t Grad:   tensor([-0.2867,  1.6229])\n",
      "Epoch 359, loss 10.894581\n",
      "\t Params: tensor([ 3.6858, -7.7838])\n",
      "\t Grad:   tensor([-0.2862,  1.6201])\n",
      "Epoch 360, loss 10.867537\n",
      "\t Params: tensor([ 3.6887, -7.7999])\n",
      "\t Grad:   tensor([-0.2857,  1.6174])\n",
      "Epoch 361, loss 10.840583\n",
      "\t Params: tensor([ 3.6915, -7.8161])\n",
      "\t Grad:   tensor([-0.2852,  1.6146])\n",
      "Epoch 362, loss 10.813720\n",
      "\t Params: tensor([ 3.6944, -7.8322])\n",
      "\t Grad:   tensor([-0.2847,  1.6119])\n",
      "Epoch 363, loss 10.786951\n",
      "\t Params: tensor([ 3.6972, -7.8483])\n",
      "\t Grad:   tensor([-0.2843,  1.6092])\n",
      "Epoch 364, loss 10.760270\n",
      "\t Params: tensor([ 3.7000, -7.8644])\n",
      "\t Grad:   tensor([-0.2838,  1.6064])\n",
      "Epoch 365, loss 10.733681\n",
      "\t Params: tensor([ 3.7029, -7.8804])\n",
      "\t Grad:   tensor([-0.2833,  1.6037])\n",
      "Epoch 366, loss 10.707183\n",
      "\t Params: tensor([ 3.7057, -7.8964])\n",
      "\t Grad:   tensor([-0.2828,  1.6010])\n",
      "Epoch 367, loss 10.680775\n",
      "\t Params: tensor([ 3.7085, -7.9124])\n",
      "\t Grad:   tensor([-0.2823,  1.5983])\n",
      "Epoch 368, loss 10.654453\n",
      "\t Params: tensor([ 3.7113, -7.9284])\n",
      "\t Grad:   tensor([-0.2819,  1.5955])\n",
      "Epoch 369, loss 10.628225\n",
      "\t Params: tensor([ 3.7142, -7.9443])\n",
      "\t Grad:   tensor([-0.2814,  1.5928])\n",
      "Epoch 370, loss 10.602084\n",
      "\t Params: tensor([ 3.7170, -7.9602])\n",
      "\t Grad:   tensor([-0.2809,  1.5901])\n",
      "Epoch 371, loss 10.576032\n",
      "\t Params: tensor([ 3.7198, -7.9761])\n",
      "\t Grad:   tensor([-0.2804,  1.5874])\n",
      "Epoch 372, loss 10.550071\n",
      "\t Params: tensor([ 3.7226, -7.9919])\n",
      "\t Grad:   tensor([-0.2799,  1.5847])\n",
      "Epoch 373, loss 10.524195\n",
      "\t Params: tensor([ 3.7254, -8.0077])\n",
      "\t Grad:   tensor([-0.2795,  1.5820])\n",
      "Epoch 374, loss 10.498408\n",
      "\t Params: tensor([ 3.7282, -8.0235])\n",
      "\t Grad:   tensor([-0.2790,  1.5794])\n",
      "Epoch 375, loss 10.472707\n",
      "\t Params: tensor([ 3.7309, -8.0393])\n",
      "\t Grad:   tensor([-0.2785,  1.5767])\n",
      "Epoch 376, loss 10.447094\n",
      "\t Params: tensor([ 3.7337, -8.0550])\n",
      "\t Grad:   tensor([-0.2780,  1.5740])\n",
      "Epoch 377, loss 10.421568\n",
      "\t Params: tensor([ 3.7365, -8.0707])\n",
      "\t Grad:   tensor([-0.2776,  1.5713])\n",
      "Epoch 378, loss 10.396132\n",
      "\t Params: tensor([ 3.7393, -8.0864])\n",
      "\t Grad:   tensor([-0.2771,  1.5686])\n",
      "Epoch 379, loss 10.370778\n",
      "\t Params: tensor([ 3.7420, -8.1021])\n",
      "\t Grad:   tensor([-0.2766,  1.5660])\n",
      "Epoch 380, loss 10.345510\n",
      "\t Params: tensor([ 3.7448, -8.1177])\n",
      "\t Grad:   tensor([-0.2762,  1.5633])\n",
      "Epoch 381, loss 10.320329\n",
      "\t Params: tensor([ 3.7476, -8.1333])\n",
      "\t Grad:   tensor([-0.2757,  1.5607])\n",
      "Epoch 382, loss 10.295236\n",
      "\t Params: tensor([ 3.7503, -8.1489])\n",
      "\t Grad:   tensor([-0.2752,  1.5580])\n",
      "Epoch 383, loss 10.270224\n",
      "\t Params: tensor([ 3.7531, -8.1645])\n",
      "\t Grad:   tensor([-0.2748,  1.5554])\n",
      "Epoch 384, loss 10.245296\n",
      "\t Params: tensor([ 3.7558, -8.1800])\n",
      "\t Grad:   tensor([-0.2743,  1.5527])\n",
      "Epoch 385, loss 10.220456\n",
      "\t Params: tensor([ 3.7585, -8.1955])\n",
      "\t Grad:   tensor([-0.2738,  1.5501])\n",
      "Epoch 386, loss 10.195701\n",
      "\t Params: tensor([ 3.7613, -8.2110])\n",
      "\t Grad:   tensor([-0.2734,  1.5475])\n",
      "Epoch 387, loss 10.171027\n",
      "\t Params: tensor([ 3.7640, -8.2264])\n",
      "\t Grad:   tensor([-0.2729,  1.5448])\n",
      "Epoch 388, loss 10.146436\n",
      "\t Params: tensor([ 3.7667, -8.2418])\n",
      "\t Grad:   tensor([-0.2724,  1.5422])\n",
      "Epoch 389, loss 10.121934\n",
      "\t Params: tensor([ 3.7694, -8.2572])\n",
      "\t Grad:   tensor([-0.2720,  1.5396])\n",
      "Epoch 390, loss 10.097512\n",
      "\t Params: tensor([ 3.7722, -8.2726])\n",
      "\t Grad:   tensor([-0.2715,  1.5370])\n",
      "Epoch 391, loss 10.073174\n",
      "\t Params: tensor([ 3.7749, -8.2879])\n",
      "\t Grad:   tensor([-0.2711,  1.5344])\n",
      "Epoch 392, loss 10.048919\n",
      "\t Params: tensor([ 3.7776, -8.3033])\n",
      "\t Grad:   tensor([-0.2706,  1.5317])\n",
      "Epoch 393, loss 10.024742\n",
      "\t Params: tensor([ 3.7803, -8.3185])\n",
      "\t Grad:   tensor([-0.2701,  1.5291])\n",
      "Epoch 394, loss 10.000652\n",
      "\t Params: tensor([ 3.7830, -8.3338])\n",
      "\t Grad:   tensor([-0.2697,  1.5265])\n",
      "Epoch 395, loss 9.976640\n",
      "\t Params: tensor([ 3.7857, -8.3491])\n",
      "\t Grad:   tensor([-0.2692,  1.5240])\n",
      "Epoch 396, loss 9.952712\n",
      "\t Params: tensor([ 3.7884, -8.3643])\n",
      "\t Grad:   tensor([-0.2688,  1.5214])\n",
      "Epoch 397, loss 9.928863\n",
      "\t Params: tensor([ 3.7910, -8.3795])\n",
      "\t Grad:   tensor([-0.2683,  1.5188])\n",
      "Epoch 398, loss 9.905092\n",
      "\t Params: tensor([ 3.7937, -8.3946])\n",
      "\t Grad:   tensor([-0.2678,  1.5162])\n",
      "Epoch 399, loss 9.881409\n",
      "\t Params: tensor([ 3.7964, -8.4098])\n",
      "\t Grad:   tensor([-0.2674,  1.5136])\n",
      "Epoch 400, loss 9.857802\n",
      "\t Params: tensor([ 3.7991, -8.4249])\n",
      "\t Grad:   tensor([-0.2669,  1.5111])\n",
      "Epoch 401, loss 9.834277\n",
      "\t Params: tensor([ 3.8017, -8.4399])\n",
      "\t Grad:   tensor([-0.2665,  1.5085])\n",
      "Epoch 402, loss 9.810832\n",
      "\t Params: tensor([ 3.8044, -8.4550])\n",
      "\t Grad:   tensor([-0.2660,  1.5059])\n",
      "Epoch 403, loss 9.787466\n",
      "\t Params: tensor([ 3.8070, -8.4700])\n",
      "\t Grad:   tensor([-0.2656,  1.5034])\n",
      "Epoch 404, loss 9.764176\n",
      "\t Params: tensor([ 3.8097, -8.4851])\n",
      "\t Grad:   tensor([-0.2651,  1.5008])\n",
      "Epoch 405, loss 9.740971\n",
      "\t Params: tensor([ 3.8123, -8.5000])\n",
      "\t Grad:   tensor([-0.2647,  1.4983])\n",
      "Epoch 406, loss 9.717843\n",
      "\t Params: tensor([ 3.8150, -8.5150])\n",
      "\t Grad:   tensor([-0.2642,  1.4957])\n",
      "Epoch 407, loss 9.694793\n",
      "\t Params: tensor([ 3.8176, -8.5299])\n",
      "\t Grad:   tensor([-0.2638,  1.4932])\n",
      "Epoch 408, loss 9.671823\n",
      "\t Params: tensor([ 3.8202, -8.5448])\n",
      "\t Grad:   tensor([-0.2633,  1.4906])\n",
      "Epoch 409, loss 9.648926\n",
      "\t Params: tensor([ 3.8229, -8.5597])\n",
      "\t Grad:   tensor([-0.2629,  1.4881])\n",
      "Epoch 410, loss 9.626110\n",
      "\t Params: tensor([ 3.8255, -8.5746])\n",
      "\t Grad:   tensor([-0.2624,  1.4856])\n",
      "Epoch 411, loss 9.603373\n",
      "\t Params: tensor([ 3.8281, -8.5894])\n",
      "\t Grad:   tensor([-0.2620,  1.4831])\n",
      "Epoch 412, loss 9.580710\n",
      "\t Params: tensor([ 3.8307, -8.6042])\n",
      "\t Grad:   tensor([-0.2615,  1.4805])\n",
      "Epoch 413, loss 9.558124\n",
      "\t Params: tensor([ 3.8333, -8.6190])\n",
      "\t Grad:   tensor([-0.2611,  1.4780])\n",
      "Epoch 414, loss 9.535618\n",
      "\t Params: tensor([ 3.8360, -8.6337])\n",
      "\t Grad:   tensor([-0.2606,  1.4755])\n",
      "Epoch 415, loss 9.513185\n",
      "\t Params: tensor([ 3.8386, -8.6485])\n",
      "\t Grad:   tensor([-0.2602,  1.4730])\n",
      "Epoch 416, loss 9.490829\n",
      "\t Params: tensor([ 3.8412, -8.6632])\n",
      "\t Grad:   tensor([-0.2598,  1.4705])\n",
      "Epoch 417, loss 9.468551\n",
      "\t Params: tensor([ 3.8437, -8.6779])\n",
      "\t Grad:   tensor([-0.2593,  1.4680])\n",
      "Epoch 418, loss 9.446347\n",
      "\t Params: tensor([ 3.8463, -8.6925])\n",
      "\t Grad:   tensor([-0.2589,  1.4655])\n",
      "Epoch 419, loss 9.424216\n",
      "\t Params: tensor([ 3.8489, -8.7071])\n",
      "\t Grad:   tensor([-0.2584,  1.4630])\n",
      "Epoch 420, loss 9.402163\n",
      "\t Params: tensor([ 3.8515, -8.7217])\n",
      "\t Grad:   tensor([-0.2580,  1.4605])\n",
      "Epoch 421, loss 9.380185\n",
      "\t Params: tensor([ 3.8541, -8.7363])\n",
      "\t Grad:   tensor([-0.2576,  1.4581])\n",
      "Epoch 422, loss 9.358281\n",
      "\t Params: tensor([ 3.8566, -8.7509])\n",
      "\t Grad:   tensor([-0.2571,  1.4556])\n",
      "Epoch 423, loss 9.336448\n",
      "\t Params: tensor([ 3.8592, -8.7654])\n",
      "\t Grad:   tensor([-0.2567,  1.4531])\n",
      "Epoch 424, loss 9.314696\n",
      "\t Params: tensor([ 3.8618, -8.7799])\n",
      "\t Grad:   tensor([-0.2563,  1.4506])\n",
      "Epoch 425, loss 9.293013\n",
      "\t Params: tensor([ 3.8643, -8.7944])\n",
      "\t Grad:   tensor([-0.2558,  1.4482])\n",
      "Epoch 426, loss 9.271402\n",
      "\t Params: tensor([ 3.8669, -8.8089])\n",
      "\t Grad:   tensor([-0.2554,  1.4457])\n",
      "Epoch 427, loss 9.249870\n",
      "\t Params: tensor([ 3.8694, -8.8233])\n",
      "\t Grad:   tensor([-0.2550,  1.4433])\n",
      "Epoch 428, loss 9.228409\n",
      "\t Params: tensor([ 3.8720, -8.8377])\n",
      "\t Grad:   tensor([-0.2545,  1.4408])\n",
      "Epoch 429, loss 9.207021\n",
      "\t Params: tensor([ 3.8745, -8.8521])\n",
      "\t Grad:   tensor([-0.2541,  1.4384])\n",
      "Epoch 430, loss 9.185704\n",
      "\t Params: tensor([ 3.8771, -8.8664])\n",
      "\t Grad:   tensor([-0.2537,  1.4359])\n",
      "Epoch 431, loss 9.164462\n",
      "\t Params: tensor([ 3.8796, -8.8808])\n",
      "\t Grad:   tensor([-0.2532,  1.4335])\n",
      "Epoch 432, loss 9.143288\n",
      "\t Params: tensor([ 3.8821, -8.8951])\n",
      "\t Grad:   tensor([-0.2528,  1.4310])\n",
      "Epoch 433, loss 9.122189\n",
      "\t Params: tensor([ 3.8846, -8.9094])\n",
      "\t Grad:   tensor([-0.2524,  1.4286])\n",
      "Epoch 434, loss 9.101160\n",
      "\t Params: tensor([ 3.8872, -8.9236])\n",
      "\t Grad:   tensor([-0.2519,  1.4262])\n",
      "Epoch 435, loss 9.080204\n",
      "\t Params: tensor([ 3.8897, -8.9379])\n",
      "\t Grad:   tensor([-0.2515,  1.4238])\n",
      "Epoch 436, loss 9.059317\n",
      "\t Params: tensor([ 3.8922, -8.9521])\n",
      "\t Grad:   tensor([-0.2511,  1.4213])\n",
      "Epoch 437, loss 9.038502\n",
      "\t Params: tensor([ 3.8947, -8.9663])\n",
      "\t Grad:   tensor([-0.2507,  1.4189])\n",
      "Epoch 438, loss 9.017757\n",
      "\t Params: tensor([ 3.8972, -8.9804])\n",
      "\t Grad:   tensor([-0.2502,  1.4165])\n",
      "Epoch 439, loss 8.997085\n",
      "\t Params: tensor([ 3.8997, -8.9946])\n",
      "\t Grad:   tensor([-0.2498,  1.4141])\n",
      "Epoch 440, loss 8.976479\n",
      "\t Params: tensor([ 3.9022, -9.0087])\n",
      "\t Grad:   tensor([-0.2494,  1.4117])\n",
      "Epoch 441, loss 8.955945\n",
      "\t Params: tensor([ 3.9047, -9.0228])\n",
      "\t Grad:   tensor([-0.2489,  1.4093])\n",
      "Epoch 442, loss 8.935481\n",
      "\t Params: tensor([ 3.9072, -9.0369])\n",
      "\t Grad:   tensor([-0.2485,  1.4069])\n",
      "Epoch 443, loss 8.915089\n",
      "\t Params: tensor([ 3.9096, -9.0509])\n",
      "\t Grad:   tensor([-0.2481,  1.4045])\n",
      "Epoch 444, loss 8.894763\n",
      "\t Params: tensor([ 3.9121, -9.0649])\n",
      "\t Grad:   tensor([-0.2477,  1.4021])\n",
      "Epoch 445, loss 8.874508\n",
      "\t Params: tensor([ 3.9146, -9.0789])\n",
      "\t Grad:   tensor([-0.2473,  1.3998])\n",
      "Epoch 446, loss 8.854318\n",
      "\t Params: tensor([ 3.9171, -9.0929])\n",
      "\t Grad:   tensor([-0.2468,  1.3974])\n",
      "Epoch 447, loss 8.834197\n",
      "\t Params: tensor([ 3.9195, -9.1068])\n",
      "\t Grad:   tensor([-0.2464,  1.3950])\n",
      "Epoch 448, loss 8.814149\n",
      "\t Params: tensor([ 3.9220, -9.1208])\n",
      "\t Grad:   tensor([-0.2460,  1.3926])\n",
      "Epoch 449, loss 8.794162\n",
      "\t Params: tensor([ 3.9244, -9.1347])\n",
      "\t Grad:   tensor([-0.2456,  1.3903])\n",
      "Epoch 450, loss 8.774252\n",
      "\t Params: tensor([ 3.9269, -9.1486])\n",
      "\t Grad:   tensor([-0.2452,  1.3879])\n",
      "Epoch 451, loss 8.754406\n",
      "\t Params: tensor([ 3.9293, -9.1624])\n",
      "\t Grad:   tensor([-0.2448,  1.3856])\n",
      "Epoch 452, loss 8.734625\n",
      "\t Params: tensor([ 3.9318, -9.1762])\n",
      "\t Grad:   tensor([-0.2443,  1.3832])\n",
      "Epoch 453, loss 8.714911\n",
      "\t Params: tensor([ 3.9342, -9.1901])\n",
      "\t Grad:   tensor([-0.2439,  1.3808])\n",
      "Epoch 454, loss 8.695266\n",
      "\t Params: tensor([ 3.9367, -9.2038])\n",
      "\t Grad:   tensor([-0.2435,  1.3785])\n",
      "Epoch 455, loss 8.675689\n",
      "\t Params: tensor([ 3.9391, -9.2176])\n",
      "\t Grad:   tensor([-0.2431,  1.3762])\n",
      "Epoch 456, loss 8.656174\n",
      "\t Params: tensor([ 3.9415, -9.2313])\n",
      "\t Grad:   tensor([-0.2427,  1.3738])\n",
      "Epoch 457, loss 8.636728\n",
      "\t Params: tensor([ 3.9439, -9.2451])\n",
      "\t Grad:   tensor([-0.2423,  1.3715])\n",
      "Epoch 458, loss 8.617346\n",
      "\t Params: tensor([ 3.9464, -9.2587])\n",
      "\t Grad:   tensor([-0.2419,  1.3692])\n",
      "Epoch 459, loss 8.598029\n",
      "\t Params: tensor([ 3.9488, -9.2724])\n",
      "\t Grad:   tensor([-0.2414,  1.3668])\n",
      "Epoch 460, loss 8.578781\n",
      "\t Params: tensor([ 3.9512, -9.2861])\n",
      "\t Grad:   tensor([-0.2410,  1.3645])\n",
      "Epoch 461, loss 8.559597\n",
      "\t Params: tensor([ 3.9536, -9.2997])\n",
      "\t Grad:   tensor([-0.2406,  1.3622])\n",
      "Epoch 462, loss 8.540478\n",
      "\t Params: tensor([ 3.9560, -9.3133])\n",
      "\t Grad:   tensor([-0.2402,  1.3599])\n",
      "Epoch 463, loss 8.521426\n",
      "\t Params: tensor([ 3.9584, -9.3269])\n",
      "\t Grad:   tensor([-0.2398,  1.3576])\n",
      "Epoch 464, loss 8.502438\n",
      "\t Params: tensor([ 3.9608, -9.3404])\n",
      "\t Grad:   tensor([-0.2394,  1.3553])\n",
      "Epoch 465, loss 8.483516\n",
      "\t Params: tensor([ 3.9632, -9.3539])\n",
      "\t Grad:   tensor([-0.2390,  1.3530])\n",
      "Epoch 466, loss 8.464652\n",
      "\t Params: tensor([ 3.9656, -9.3674])\n",
      "\t Grad:   tensor([-0.2386,  1.3507])\n",
      "Epoch 467, loss 8.445858\n",
      "\t Params: tensor([ 3.9679, -9.3809])\n",
      "\t Grad:   tensor([-0.2382,  1.3484])\n",
      "Epoch 468, loss 8.427128\n",
      "\t Params: tensor([ 3.9703, -9.3944])\n",
      "\t Grad:   tensor([-0.2378,  1.3461])\n",
      "Epoch 469, loss 8.408456\n",
      "\t Params: tensor([ 3.9727, -9.4078])\n",
      "\t Grad:   tensor([-0.2374,  1.3438])\n",
      "Epoch 470, loss 8.389848\n",
      "\t Params: tensor([ 3.9751, -9.4212])\n",
      "\t Grad:   tensor([-0.2370,  1.3415])\n",
      "Epoch 471, loss 8.371305\n",
      "\t Params: tensor([ 3.9774, -9.4346])\n",
      "\t Grad:   tensor([-0.2366,  1.3392])\n",
      "Epoch 472, loss 8.352828\n",
      "\t Params: tensor([ 3.9798, -9.4480])\n",
      "\t Grad:   tensor([-0.2362,  1.3370])\n",
      "Epoch 473, loss 8.334408\n",
      "\t Params: tensor([ 3.9822, -9.4614])\n",
      "\t Grad:   tensor([-0.2358,  1.3347])\n",
      "Epoch 474, loss 8.316055\n",
      "\t Params: tensor([ 3.9845, -9.4747])\n",
      "\t Grad:   tensor([-0.2354,  1.3324])\n",
      "Epoch 475, loss 8.297764\n",
      "\t Params: tensor([ 3.9869, -9.4880])\n",
      "\t Grad:   tensor([-0.2350,  1.3301])\n",
      "Epoch 476, loss 8.279534\n",
      "\t Params: tensor([ 3.9892, -9.5013])\n",
      "\t Grad:   tensor([-0.2346,  1.3279])\n",
      "Epoch 477, loss 8.261369\n",
      "\t Params: tensor([ 3.9915, -9.5145])\n",
      "\t Grad:   tensor([-0.2342,  1.3256])\n",
      "Epoch 478, loss 8.243261\n",
      "\t Params: tensor([ 3.9939, -9.5277])\n",
      "\t Grad:   tensor([-0.2338,  1.3234])\n",
      "Epoch 479, loss 8.225213\n",
      "\t Params: tensor([ 3.9962, -9.5410])\n",
      "\t Grad:   tensor([-0.2334,  1.3211])\n",
      "Epoch 480, loss 8.207232\n",
      "\t Params: tensor([ 3.9985, -9.5541])\n",
      "\t Grad:   tensor([-0.2330,  1.3189])\n",
      "Epoch 481, loss 8.189310\n",
      "\t Params: tensor([ 4.0009, -9.5673])\n",
      "\t Grad:   tensor([-0.2326,  1.3166])\n",
      "Epoch 482, loss 8.171450\n",
      "\t Params: tensor([ 4.0032, -9.5805])\n",
      "\t Grad:   tensor([-0.2322,  1.3144])\n",
      "Epoch 483, loss 8.153648\n",
      "\t Params: tensor([ 4.0055, -9.5936])\n",
      "\t Grad:   tensor([-0.2318,  1.3122])\n",
      "Epoch 484, loss 8.135907\n",
      "\t Params: tensor([ 4.0078, -9.6067])\n",
      "\t Grad:   tensor([-0.2314,  1.3100])\n",
      "Epoch 485, loss 8.118226\n",
      "\t Params: tensor([ 4.0101, -9.6198])\n",
      "\t Grad:   tensor([-0.2310,  1.3077])\n",
      "Epoch 486, loss 8.100607\n",
      "\t Params: tensor([ 4.0124, -9.6328])\n",
      "\t Grad:   tensor([-0.2306,  1.3055])\n",
      "Epoch 487, loss 8.083045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Params: tensor([ 4.0147, -9.6458])\n",
      "\t Grad:   tensor([-0.2302,  1.3033])\n",
      "Epoch 488, loss 8.065548\n",
      "\t Params: tensor([ 4.0170, -9.6589])\n",
      "\t Grad:   tensor([-0.2298,  1.3011])\n",
      "Epoch 489, loss 8.048104\n",
      "\t Params: tensor([ 4.0193, -9.6718])\n",
      "\t Grad:   tensor([-0.2295,  1.2989])\n",
      "Epoch 490, loss 8.030723\n",
      "\t Params: tensor([ 4.0216, -9.6848])\n",
      "\t Grad:   tensor([-0.2291,  1.2967])\n",
      "Epoch 491, loss 8.013400\n",
      "\t Params: tensor([ 4.0239, -9.6978])\n",
      "\t Grad:   tensor([-0.2287,  1.2945])\n",
      "Epoch 492, loss 7.996135\n",
      "\t Params: tensor([ 4.0262, -9.7107])\n",
      "\t Grad:   tensor([-0.2283,  1.2923])\n",
      "Epoch 493, loss 7.978929\n",
      "\t Params: tensor([ 4.0285, -9.7236])\n",
      "\t Grad:   tensor([-0.2279,  1.2901])\n",
      "Epoch 494, loss 7.961784\n",
      "\t Params: tensor([ 4.0308, -9.7365])\n",
      "\t Grad:   tensor([-0.2275,  1.2879])\n",
      "Epoch 495, loss 7.944690\n",
      "\t Params: tensor([ 4.0330, -9.7493])\n",
      "\t Grad:   tensor([-0.2271,  1.2857])\n",
      "Epoch 496, loss 7.927662\n",
      "\t Params: tensor([ 4.0353, -9.7621])\n",
      "\t Grad:   tensor([-0.2267,  1.2835])\n",
      "Epoch 497, loss 7.910690\n",
      "\t Params: tensor([ 4.0376, -9.7750])\n",
      "\t Grad:   tensor([-0.2263,  1.2813])\n",
      "Epoch 498, loss 7.893775\n",
      "\t Params: tensor([ 4.0398, -9.7878])\n",
      "\t Grad:   tensor([-0.2260,  1.2791])\n",
      "Epoch 499, loss 7.876915\n",
      "\t Params: tensor([ 4.0421, -9.8005])\n",
      "\t Grad:   tensor([-0.2256,  1.2770])\n",
      "Epoch 500, loss 7.860116\n",
      "\t Params: tensor([ 4.0443, -9.8133])\n",
      "\t Grad:   tensor([-0.2252,  1.2748])\n",
      "Epoch 501, loss 7.843370\n",
      "\t Params: tensor([ 4.0466, -9.8260])\n",
      "\t Grad:   tensor([-0.2248,  1.2726])\n",
      "Epoch 502, loss 7.826681\n",
      "\t Params: tensor([ 4.0488, -9.8387])\n",
      "\t Grad:   tensor([-0.2244,  1.2705])\n",
      "Epoch 503, loss 7.810053\n",
      "\t Params: tensor([ 4.0511, -9.8514])\n",
      "\t Grad:   tensor([-0.2241,  1.2683])\n",
      "Epoch 504, loss 7.793480\n",
      "\t Params: tensor([ 4.0533, -9.8640])\n",
      "\t Grad:   tensor([-0.2237,  1.2662])\n",
      "Epoch 505, loss 7.776962\n",
      "\t Params: tensor([ 4.0555, -9.8767])\n",
      "\t Grad:   tensor([-0.2233,  1.2640])\n",
      "Epoch 506, loss 7.760498\n",
      "\t Params: tensor([ 4.0578, -9.8893])\n",
      "\t Grad:   tensor([-0.2229,  1.2619])\n",
      "Epoch 507, loss 7.744092\n",
      "\t Params: tensor([ 4.0600, -9.9019])\n",
      "\t Grad:   tensor([-0.2225,  1.2597])\n",
      "Epoch 508, loss 7.727745\n",
      "\t Params: tensor([ 4.0622, -9.9145])\n",
      "\t Grad:   tensor([-0.2222,  1.2576])\n",
      "Epoch 509, loss 7.711447\n",
      "\t Params: tensor([ 4.0644, -9.9270])\n",
      "\t Grad:   tensor([-0.2218,  1.2554])\n",
      "Epoch 510, loss 7.695212\n",
      "\t Params: tensor([ 4.0666, -9.9396])\n",
      "\t Grad:   tensor([-0.2214,  1.2533])\n",
      "Epoch 511, loss 7.679024\n",
      "\t Params: tensor([ 4.0688, -9.9521])\n",
      "\t Grad:   tensor([-0.2210,  1.2512])\n",
      "Epoch 512, loss 7.662895\n",
      "\t Params: tensor([ 4.0710, -9.9646])\n",
      "\t Grad:   tensor([-0.2207,  1.2490])\n",
      "Epoch 513, loss 7.646819\n",
      "\t Params: tensor([ 4.0733, -9.9770])\n",
      "\t Grad:   tensor([-0.2203,  1.2469])\n",
      "Epoch 514, loss 7.630803\n",
      "\t Params: tensor([ 4.0754, -9.9895])\n",
      "\t Grad:   tensor([-0.2199,  1.2448])\n",
      "Epoch 515, loss 7.614836\n",
      "\t Params: tensor([  4.0776, -10.0019])\n",
      "\t Grad:   tensor([-0.2195,  1.2427])\n",
      "Epoch 516, loss 7.598925\n",
      "\t Params: tensor([  4.0798, -10.0143])\n",
      "\t Grad:   tensor([-0.2192,  1.2406])\n",
      "Epoch 517, loss 7.583069\n",
      "\t Params: tensor([  4.0820, -10.0267])\n",
      "\t Grad:   tensor([-0.2188,  1.2385])\n",
      "Epoch 518, loss 7.567266\n",
      "\t Params: tensor([  4.0842, -10.0391])\n",
      "\t Grad:   tensor([-0.2184,  1.2364])\n",
      "Epoch 519, loss 7.551516\n",
      "\t Params: tensor([  4.0864, -10.0514])\n",
      "\t Grad:   tensor([-0.2180,  1.2343])\n",
      "Epoch 520, loss 7.535819\n",
      "\t Params: tensor([  4.0886, -10.0637])\n",
      "\t Grad:   tensor([-0.2177,  1.2322])\n",
      "Epoch 521, loss 7.520176\n",
      "\t Params: tensor([  4.0907, -10.0760])\n",
      "\t Grad:   tensor([-0.2173,  1.2301])\n",
      "Epoch 522, loss 7.504588\n",
      "\t Params: tensor([  4.0929, -10.0883])\n",
      "\t Grad:   tensor([-0.2169,  1.2280])\n",
      "Epoch 523, loss 7.489048\n",
      "\t Params: tensor([  4.0951, -10.1006])\n",
      "\t Grad:   tensor([-0.2165,  1.2259])\n",
      "Epoch 524, loss 7.473566\n",
      "\t Params: tensor([  4.0972, -10.1128])\n",
      "\t Grad:   tensor([-0.2162,  1.2238])\n",
      "Epoch 525, loss 7.458135\n",
      "\t Params: tensor([  4.0994, -10.1250])\n",
      "\t Grad:   tensor([-0.2158,  1.2217])\n",
      "Epoch 526, loss 7.442751\n",
      "\t Params: tensor([  4.1015, -10.1372])\n",
      "\t Grad:   tensor([-0.2155,  1.2197])\n",
      "Epoch 527, loss 7.427426\n",
      "\t Params: tensor([  4.1037, -10.1494])\n",
      "\t Grad:   tensor([-0.2151,  1.2176])\n",
      "Epoch 528, loss 7.412152\n",
      "\t Params: tensor([  4.1058, -10.1616])\n",
      "\t Grad:   tensor([-0.2147,  1.2155])\n",
      "Epoch 529, loss 7.396928\n",
      "\t Params: tensor([  4.1080, -10.1737])\n",
      "\t Grad:   tensor([-0.2144,  1.2135])\n",
      "Epoch 530, loss 7.381756\n",
      "\t Params: tensor([  4.1101, -10.1858])\n",
      "\t Grad:   tensor([-0.2140,  1.2114])\n",
      "Epoch 531, loss 7.366636\n",
      "\t Params: tensor([  4.1123, -10.1979])\n",
      "\t Grad:   tensor([-0.2136,  1.2093])\n",
      "Epoch 532, loss 7.351566\n",
      "\t Params: tensor([  4.1144, -10.2100])\n",
      "\t Grad:   tensor([-0.2133,  1.2073])\n",
      "Epoch 533, loss 7.336550\n",
      "\t Params: tensor([  4.1165, -10.2220])\n",
      "\t Grad:   tensor([-0.2129,  1.2052])\n",
      "Epoch 534, loss 7.321585\n",
      "\t Params: tensor([  4.1187, -10.2340])\n",
      "\t Grad:   tensor([-0.2125,  1.2032])\n",
      "Epoch 535, loss 7.306670\n",
      "\t Params: tensor([  4.1208, -10.2461])\n",
      "\t Grad:   tensor([-0.2122,  1.2012])\n",
      "Epoch 536, loss 7.291803\n",
      "\t Params: tensor([  4.1229, -10.2581])\n",
      "\t Grad:   tensor([-0.2118,  1.1991])\n",
      "Epoch 537, loss 7.276989\n",
      "\t Params: tensor([  4.1250, -10.2700])\n",
      "\t Grad:   tensor([-0.2115,  1.1971])\n",
      "Epoch 538, loss 7.262227\n",
      "\t Params: tensor([  4.1271, -10.2820])\n",
      "\t Grad:   tensor([-0.2111,  1.1950])\n",
      "Epoch 539, loss 7.247512\n",
      "\t Params: tensor([  4.1292, -10.2939])\n",
      "\t Grad:   tensor([-0.2108,  1.1930])\n",
      "Epoch 540, loss 7.232846\n",
      "\t Params: tensor([  4.1313, -10.3058])\n",
      "\t Grad:   tensor([-0.2104,  1.1910])\n",
      "Epoch 541, loss 7.218231\n",
      "\t Params: tensor([  4.1334, -10.3177])\n",
      "\t Grad:   tensor([-0.2100,  1.1890])\n",
      "Epoch 542, loss 7.203666\n",
      "\t Params: tensor([  4.1355, -10.3296])\n",
      "\t Grad:   tensor([-0.2097,  1.1869])\n",
      "Epoch 543, loss 7.189151\n",
      "\t Params: tensor([  4.1376, -10.3414])\n",
      "\t Grad:   tensor([-0.2093,  1.1849])\n",
      "Epoch 544, loss 7.174683\n",
      "\t Params: tensor([  4.1397, -10.3533])\n",
      "\t Grad:   tensor([-0.2090,  1.1829])\n",
      "Epoch 545, loss 7.160267\n",
      "\t Params: tensor([  4.1418, -10.3651])\n",
      "\t Grad:   tensor([-0.2086,  1.1809])\n",
      "Epoch 546, loss 7.145897\n",
      "\t Params: tensor([  4.1439, -10.3769])\n",
      "\t Grad:   tensor([-0.2083,  1.1789])\n",
      "Epoch 547, loss 7.131578\n",
      "\t Params: tensor([  4.1460, -10.3886])\n",
      "\t Grad:   tensor([-0.2079,  1.1769])\n",
      "Epoch 548, loss 7.117305\n",
      "\t Params: tensor([  4.1480, -10.4004])\n",
      "\t Grad:   tensor([-0.2075,  1.1749])\n",
      "Epoch 549, loss 7.103083\n",
      "\t Params: tensor([  4.1501, -10.4121])\n",
      "\t Grad:   tensor([-0.2072,  1.1729])\n",
      "Epoch 550, loss 7.088911\n",
      "\t Params: tensor([  4.1522, -10.4238])\n",
      "\t Grad:   tensor([-0.2068,  1.1709])\n",
      "Epoch 551, loss 7.074785\n",
      "\t Params: tensor([  4.1542, -10.4355])\n",
      "\t Grad:   tensor([-0.2065,  1.1689])\n",
      "Epoch 552, loss 7.060707\n",
      "\t Params: tensor([  4.1563, -10.4472])\n",
      "\t Grad:   tensor([-0.2062,  1.1669])\n",
      "Epoch 553, loss 7.046677\n",
      "\t Params: tensor([  4.1584, -10.4588])\n",
      "\t Grad:   tensor([-0.2058,  1.1649])\n",
      "Epoch 554, loss 7.032695\n",
      "\t Params: tensor([  4.1604, -10.4704])\n",
      "\t Grad:   tensor([-0.2054,  1.1630])\n",
      "Epoch 555, loss 7.018756\n",
      "\t Params: tensor([  4.1625, -10.4821])\n",
      "\t Grad:   tensor([-0.2051,  1.1610])\n",
      "Epoch 556, loss 7.004869\n",
      "\t Params: tensor([  4.1645, -10.4936])\n",
      "\t Grad:   tensor([-0.2047,  1.1590])\n",
      "Epoch 557, loss 6.991029\n",
      "\t Params: tensor([  4.1666, -10.5052])\n",
      "\t Grad:   tensor([-0.2044,  1.1571])\n",
      "Epoch 558, loss 6.977232\n",
      "\t Params: tensor([  4.1686, -10.5168])\n",
      "\t Grad:   tensor([-0.2041,  1.1551])\n",
      "Epoch 559, loss 6.963488\n",
      "\t Params: tensor([  4.1706, -10.5283])\n",
      "\t Grad:   tensor([-0.2037,  1.1531])\n",
      "Epoch 560, loss 6.949786\n",
      "\t Params: tensor([  4.1727, -10.5398])\n",
      "\t Grad:   tensor([-0.2034,  1.1512])\n",
      "Epoch 561, loss 6.936135\n",
      "\t Params: tensor([  4.1747, -10.5513])\n",
      "\t Grad:   tensor([-0.2030,  1.1492])\n",
      "Epoch 562, loss 6.922528\n",
      "\t Params: tensor([  4.1767, -10.5628])\n",
      "\t Grad:   tensor([-0.2027,  1.1473])\n",
      "Epoch 563, loss 6.908967\n",
      "\t Params: tensor([  4.1787, -10.5742])\n",
      "\t Grad:   tensor([-0.2023,  1.1453])\n",
      "Epoch 564, loss 6.895452\n",
      "\t Params: tensor([  4.1808, -10.5857])\n",
      "\t Grad:   tensor([-0.2020,  1.1434])\n",
      "Epoch 565, loss 6.881980\n",
      "\t Params: tensor([  4.1828, -10.5971])\n",
      "\t Grad:   tensor([-0.2016,  1.1414])\n",
      "Epoch 566, loss 6.868558\n",
      "\t Params: tensor([  4.1848, -10.6085])\n",
      "\t Grad:   tensor([-0.2013,  1.1395])\n",
      "Epoch 567, loss 6.855180\n",
      "\t Params: tensor([  4.1868, -10.6198])\n",
      "\t Grad:   tensor([-0.2010,  1.1375])\n",
      "Epoch 568, loss 6.841848\n",
      "\t Params: tensor([  4.1888, -10.6312])\n",
      "\t Grad:   tensor([-0.2006,  1.1356])\n",
      "Epoch 569, loss 6.828561\n",
      "\t Params: tensor([  4.1908, -10.6425])\n",
      "\t Grad:   tensor([-0.2003,  1.1337])\n",
      "Epoch 570, loss 6.815319\n",
      "\t Params: tensor([  4.1928, -10.6539])\n",
      "\t Grad:   tensor([-0.1999,  1.1318])\n",
      "Epoch 571, loss 6.802118\n",
      "\t Params: tensor([  4.1948, -10.6652])\n",
      "\t Grad:   tensor([-0.1996,  1.1298])\n",
      "Epoch 572, loss 6.788968\n",
      "\t Params: tensor([  4.1968, -10.6764])\n",
      "\t Grad:   tensor([-0.1992,  1.1279])\n",
      "Epoch 573, loss 6.775864\n",
      "\t Params: tensor([  4.1988, -10.6877])\n",
      "\t Grad:   tensor([-0.1989,  1.1260])\n",
      "Epoch 574, loss 6.762798\n",
      "\t Params: tensor([  4.2008, -10.6989])\n",
      "\t Grad:   tensor([-0.1986,  1.1241])\n",
      "Epoch 575, loss 6.749779\n",
      "\t Params: tensor([  4.2028, -10.7102])\n",
      "\t Grad:   tensor([-0.1982,  1.1222])\n",
      "Epoch 576, loss 6.736803\n",
      "\t Params: tensor([  4.2047, -10.7214])\n",
      "\t Grad:   tensor([-0.1979,  1.1203])\n",
      "Epoch 577, loss 6.723875\n",
      "\t Params: tensor([  4.2067, -10.7325])\n",
      "\t Grad:   tensor([-0.1976,  1.1184])\n",
      "Epoch 578, loss 6.710986\n",
      "\t Params: tensor([  4.2087, -10.7437])\n",
      "\t Grad:   tensor([-0.1972,  1.1165])\n",
      "Epoch 579, loss 6.698142\n",
      "\t Params: tensor([  4.2107, -10.7549])\n",
      "\t Grad:   tensor([-0.1969,  1.1146])\n",
      "Epoch 580, loss 6.685344\n",
      "\t Params: tensor([  4.2126, -10.7660])\n",
      "\t Grad:   tensor([-0.1966,  1.1127])\n",
      "Epoch 581, loss 6.672589\n",
      "\t Params: tensor([  4.2146, -10.7771])\n",
      "\t Grad:   tensor([-0.1962,  1.1108])\n",
      "Epoch 582, loss 6.659874\n",
      "\t Params: tensor([  4.2165, -10.7882])\n",
      "\t Grad:   tensor([-0.1959,  1.1089])\n",
      "Epoch 583, loss 6.647207\n",
      "\t Params: tensor([  4.2185, -10.7992])\n",
      "\t Grad:   tensor([-0.1956,  1.1070])\n",
      "Epoch 584, loss 6.634577\n",
      "\t Params: tensor([  4.2204, -10.8103])\n",
      "\t Grad:   tensor([-0.1952,  1.1051])\n",
      "Epoch 585, loss 6.621995\n",
      "\t Params: tensor([  4.2224, -10.8213])\n",
      "\t Grad:   tensor([-0.1949,  1.1033])\n",
      "Epoch 586, loss 6.609454\n",
      "\t Params: tensor([  4.2243, -10.8323])\n",
      "\t Grad:   tensor([-0.1946,  1.1014])\n",
      "Epoch 587, loss 6.596954\n",
      "\t Params: tensor([  4.2263, -10.8433])\n",
      "\t Grad:   tensor([-0.1942,  1.0995])\n",
      "Epoch 588, loss 6.584500\n",
      "\t Params: tensor([  4.2282, -10.8543])\n",
      "\t Grad:   tensor([-0.1939,  1.0976])\n",
      "Epoch 589, loss 6.572087\n",
      "\t Params: tensor([  4.2302, -10.8653])\n",
      "\t Grad:   tensor([-0.1936,  1.0958])\n",
      "Epoch 590, loss 6.559712\n",
      "\t Params: tensor([  4.2321, -10.8762])\n",
      "\t Grad:   tensor([-0.1932,  1.0939])\n",
      "Epoch 591, loss 6.547384\n",
      "\t Params: tensor([  4.2340, -10.8871])\n",
      "\t Grad:   tensor([-0.1929,  1.0921])\n",
      "Epoch 592, loss 6.535097\n",
      "\t Params: tensor([  4.2359, -10.8980])\n",
      "\t Grad:   tensor([-0.1926,  1.0902])\n",
      "Epoch 593, loss 6.522851\n",
      "\t Params: tensor([  4.2379, -10.9089])\n",
      "\t Grad:   tensor([-0.1923,  1.0884])\n",
      "Epoch 594, loss 6.510646\n",
      "\t Params: tensor([  4.2398, -10.9198])\n",
      "\t Grad:   tensor([-0.1919,  1.0865])\n",
      "Epoch 595, loss 6.498481\n",
      "\t Params: tensor([  4.2417, -10.9306])\n",
      "\t Grad:   tensor([-0.1916,  1.0847])\n",
      "Epoch 596, loss 6.486362\n",
      "\t Params: tensor([  4.2436, -10.9415])\n",
      "\t Grad:   tensor([-0.1913,  1.0828])\n",
      "Epoch 597, loss 6.474282\n",
      "\t Params: tensor([  4.2455, -10.9523])\n",
      "\t Grad:   tensor([-0.1910,  1.0810])\n",
      "Epoch 598, loss 6.462242\n",
      "\t Params: tensor([  4.2474, -10.9631])\n",
      "\t Grad:   tensor([-0.1906,  1.0791])\n",
      "Epoch 599, loss 6.450243\n",
      "\t Params: tensor([  4.2493, -10.9738])\n",
      "\t Grad:   tensor([-0.1903,  1.0773])\n",
      "Epoch 600, loss 6.438284\n",
      "\t Params: tensor([  4.2512, -10.9846])\n",
      "\t Grad:   tensor([-0.1900,  1.0755])\n",
      "Epoch 601, loss 6.426367\n",
      "\t Params: tensor([  4.2531, -10.9953])\n",
      "\t Grad:   tensor([-0.1897,  1.0737])\n",
      "Epoch 602, loss 6.414490\n",
      "\t Params: tensor([  4.2550, -11.0060])\n",
      "\t Grad:   tensor([-0.1893,  1.0718])\n",
      "Epoch 603, loss 6.402655\n",
      "\t Params: tensor([  4.2569, -11.0167])\n",
      "\t Grad:   tensor([-0.1890,  1.0700])\n",
      "Epoch 604, loss 6.390859\n",
      "\t Params: tensor([  4.2588, -11.0274])\n",
      "\t Grad:   tensor([-0.1887,  1.0682])\n",
      "Epoch 605, loss 6.379102\n",
      "\t Params: tensor([  4.2607, -11.0381])\n",
      "\t Grad:   tensor([-0.1884,  1.0664])\n",
      "Epoch 606, loss 6.367384\n",
      "\t Params: tensor([  4.2626, -11.0487])\n",
      "\t Grad:   tensor([-0.1880,  1.0646])\n",
      "Epoch 607, loss 6.355706\n",
      "\t Params: tensor([  4.2644, -11.0594])\n",
      "\t Grad:   tensor([-0.1877,  1.0628])\n",
      "Epoch 608, loss 6.344071\n",
      "\t Params: tensor([  4.2663, -11.0700])\n",
      "\t Grad:   tensor([-0.1874,  1.0609])\n",
      "Epoch 609, loss 6.332472\n",
      "\t Params: tensor([  4.2682, -11.0806])\n",
      "\t Grad:   tensor([-0.1871,  1.0591])\n",
      "Epoch 610, loss 6.320912\n",
      "\t Params: tensor([  4.2701, -11.0911])\n",
      "\t Grad:   tensor([-0.1868,  1.0573])\n",
      "Epoch 611, loss 6.309395\n",
      "\t Params: tensor([  4.2719, -11.1017])\n",
      "\t Grad:   tensor([-0.1865,  1.0555])\n",
      "Epoch 612, loss 6.297915\n",
      "\t Params: tensor([  4.2738, -11.1122])\n",
      "\t Grad:   tensor([-0.1861,  1.0538])\n",
      "Epoch 613, loss 6.286473\n",
      "\t Params: tensor([  4.2756, -11.1227])\n",
      "\t Grad:   tensor([-0.1858,  1.0520])\n",
      "Epoch 614, loss 6.275074\n",
      "\t Params: tensor([  4.2775, -11.1333])\n",
      "\t Grad:   tensor([-0.1855,  1.0502])\n",
      "Epoch 615, loss 6.263707\n",
      "\t Params: tensor([  4.2794, -11.1437])\n",
      "\t Grad:   tensor([-0.1852,  1.0484])\n",
      "Epoch 616, loss 6.252382\n",
      "\t Params: tensor([  4.2812, -11.1542])\n",
      "\t Grad:   tensor([-0.1849,  1.0466])\n",
      "Epoch 617, loss 6.241098\n",
      "\t Params: tensor([  4.2830, -11.1646])\n",
      "\t Grad:   tensor([-0.1846,  1.0448])\n",
      "Epoch 618, loss 6.229849\n",
      "\t Params: tensor([  4.2849, -11.1751])\n",
      "\t Grad:   tensor([-0.1843,  1.0431])\n",
      "Epoch 619, loss 6.218639\n",
      "\t Params: tensor([  4.2867, -11.1855])\n",
      "\t Grad:   tensor([-0.1840,  1.0413])\n",
      "Epoch 620, loss 6.207471\n",
      "\t Params: tensor([  4.2886, -11.1959])\n",
      "\t Grad:   tensor([-0.1836,  1.0395])\n",
      "Epoch 621, loss 6.196334\n",
      "\t Params: tensor([  4.2904, -11.2063])\n",
      "\t Grad:   tensor([-0.1833,  1.0378])\n",
      "Epoch 622, loss 6.185240\n",
      "\t Params: tensor([  4.2922, -11.2166])\n",
      "\t Grad:   tensor([-0.1830,  1.0360])\n",
      "Epoch 623, loss 6.174181\n",
      "\t Params: tensor([  4.2941, -11.2270])\n",
      "\t Grad:   tensor([-0.1827,  1.0342])\n",
      "Epoch 624, loss 6.163159\n",
      "\t Params: tensor([  4.2959, -11.2373])\n",
      "\t Grad:   tensor([-0.1824,  1.0325])\n",
      "Epoch 625, loss 6.152177\n",
      "\t Params: tensor([  4.2977, -11.2476])\n",
      "\t Grad:   tensor([-0.1821,  1.0307])\n",
      "Epoch 626, loss 6.141229\n",
      "\t Params: tensor([  4.2995, -11.2579])\n",
      "\t Grad:   tensor([-0.1818,  1.0290])\n",
      "Epoch 627, loss 6.130321\n",
      "\t Params: tensor([  4.3013, -11.2682])\n",
      "\t Grad:   tensor([-0.1815,  1.0272])\n",
      "Epoch 628, loss 6.119448\n",
      "\t Params: tensor([  4.3031, -11.2784])\n",
      "\t Grad:   tensor([-0.1811,  1.0255])\n",
      "Epoch 629, loss 6.108614\n",
      "\t Params: tensor([  4.3050, -11.2887])\n",
      "\t Grad:   tensor([-0.1808,  1.0237])\n",
      "Epoch 630, loss 6.097815\n",
      "\t Params: tensor([  4.3068, -11.2989])\n",
      "\t Grad:   tensor([-0.1805,  1.0220])\n",
      "Epoch 631, loss 6.087054\n",
      "\t Params: tensor([  4.3086, -11.3091])\n",
      "\t Grad:   tensor([-0.1802,  1.0203])\n",
      "Epoch 632, loss 6.076329\n",
      "\t Params: tensor([  4.3104, -11.3193])\n",
      "\t Grad:   tensor([-0.1799,  1.0185])\n",
      "Epoch 633, loss 6.065643\n",
      "\t Params: tensor([  4.3122, -11.3294])\n",
      "\t Grad:   tensor([-0.1796,  1.0168])\n",
      "Epoch 634, loss 6.054988\n",
      "\t Params: tensor([  4.3139, -11.3396])\n",
      "\t Grad:   tensor([-0.1793,  1.0151])\n",
      "Epoch 635, loss 6.044372\n",
      "\t Params: tensor([  4.3157, -11.3497])\n",
      "\t Grad:   tensor([-0.1790,  1.0133])\n",
      "Epoch 636, loss 6.033794\n",
      "\t Params: tensor([  4.3175, -11.3598])\n",
      "\t Grad:   tensor([-0.1787,  1.0116])\n",
      "Epoch 637, loss 6.023247\n",
      "\t Params: tensor([  4.3193, -11.3699])\n",
      "\t Grad:   tensor([-0.1784,  1.0099])\n",
      "Epoch 638, loss 6.012738\n",
      "\t Params: tensor([  4.3211, -11.3800])\n",
      "\t Grad:   tensor([-0.1781,  1.0082])\n",
      "Epoch 639, loss 6.002264\n",
      "\t Params: tensor([  4.3229, -11.3901])\n",
      "\t Grad:   tensor([-0.1778,  1.0065])\n",
      "Epoch 640, loss 5.991829\n",
      "\t Params: tensor([  4.3246, -11.4001])\n",
      "\t Grad:   tensor([-0.1775,  1.0048])\n",
      "Epoch 641, loss 5.981426\n",
      "\t Params: tensor([  4.3264, -11.4102])\n",
      "\t Grad:   tensor([-0.1772,  1.0031])\n",
      "Epoch 642, loss 5.971057\n",
      "\t Params: tensor([  4.3282, -11.4202])\n",
      "\t Grad:   tensor([-0.1769,  1.0014])\n",
      "Epoch 643, loss 5.960727\n",
      "\t Params: tensor([  4.3300, -11.4302])\n",
      "\t Grad:   tensor([-0.1766,  0.9997])\n",
      "Epoch 644, loss 5.950432\n",
      "\t Params: tensor([  4.3317, -11.4401])\n",
      "\t Grad:   tensor([-0.1763,  0.9980])\n",
      "Epoch 645, loss 5.940171\n",
      "\t Params: tensor([  4.3335, -11.4501])\n",
      "\t Grad:   tensor([-0.1760,  0.9963])\n",
      "Epoch 646, loss 5.929944\n",
      "\t Params: tensor([  4.3352, -11.4601])\n",
      "\t Grad:   tensor([-0.1757,  0.9946])\n",
      "Epoch 647, loss 5.919752\n",
      "\t Params: tensor([  4.3370, -11.4700])\n",
      "\t Grad:   tensor([-0.1754,  0.9929])\n",
      "Epoch 648, loss 5.909597\n",
      "\t Params: tensor([  4.3387, -11.4799])\n",
      "\t Grad:   tensor([-0.1751,  0.9912])\n",
      "Epoch 649, loss 5.899473\n",
      "\t Params: tensor([  4.3405, -11.4898])\n",
      "\t Grad:   tensor([-0.1748,  0.9895])\n",
      "Epoch 650, loss 5.889384\n",
      "\t Params: tensor([  4.3422, -11.4997])\n",
      "\t Grad:   tensor([-0.1745,  0.9878])\n",
      "Epoch 651, loss 5.879326\n",
      "\t Params: tensor([  4.3440, -11.5095])\n",
      "\t Grad:   tensor([-0.1742,  0.9862])\n",
      "Epoch 652, loss 5.869310\n",
      "\t Params: tensor([  4.3457, -11.5194])\n",
      "\t Grad:   tensor([-0.1739,  0.9845])\n",
      "Epoch 653, loss 5.859322\n",
      "\t Params: tensor([  4.3474, -11.5292])\n",
      "\t Grad:   tensor([-0.1736,  0.9828])\n",
      "Epoch 654, loss 5.849374\n",
      "\t Params: tensor([  4.3492, -11.5390])\n",
      "\t Grad:   tensor([-0.1733,  0.9811])\n",
      "Epoch 655, loss 5.839453\n",
      "\t Params: tensor([  4.3509, -11.5488])\n",
      "\t Grad:   tensor([-0.1730,  0.9795])\n",
      "Epoch 656, loss 5.829570\n",
      "\t Params: tensor([  4.3526, -11.5586])\n",
      "\t Grad:   tensor([-0.1727,  0.9778])\n",
      "Epoch 657, loss 5.819718\n",
      "\t Params: tensor([  4.3544, -11.5683])\n",
      "\t Grad:   tensor([-0.1724,  0.9761])\n",
      "Epoch 658, loss 5.809900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Params: tensor([  4.3561, -11.5781])\n",
      "\t Grad:   tensor([-0.1722,  0.9745])\n",
      "Epoch 659, loss 5.800117\n",
      "\t Params: tensor([  4.3578, -11.5878])\n",
      "\t Grad:   tensor([-0.1719,  0.9728])\n",
      "Epoch 660, loss 5.790367\n",
      "\t Params: tensor([  4.3595, -11.5975])\n",
      "\t Grad:   tensor([-0.1716,  0.9712])\n",
      "Epoch 661, loss 5.780647\n",
      "\t Params: tensor([  4.3612, -11.6072])\n",
      "\t Grad:   tensor([-0.1713,  0.9695])\n",
      "Epoch 662, loss 5.770962\n",
      "\t Params: tensor([  4.3629, -11.6169])\n",
      "\t Grad:   tensor([-0.1710,  0.9679])\n",
      "Epoch 663, loss 5.761312\n",
      "\t Params: tensor([  4.3646, -11.6266])\n",
      "\t Grad:   tensor([-0.1707,  0.9662])\n",
      "Epoch 664, loss 5.751693\n",
      "\t Params: tensor([  4.3664, -11.6362])\n",
      "\t Grad:   tensor([-0.1704,  0.9646])\n",
      "Epoch 665, loss 5.742105\n",
      "\t Params: tensor([  4.3681, -11.6458])\n",
      "\t Grad:   tensor([-0.1701,  0.9630])\n",
      "Epoch 666, loss 5.732550\n",
      "\t Params: tensor([  4.3697, -11.6555])\n",
      "\t Grad:   tensor([-0.1698,  0.9613])\n",
      "Epoch 667, loss 5.723031\n",
      "\t Params: tensor([  4.3714, -11.6651])\n",
      "\t Grad:   tensor([-0.1695,  0.9597])\n",
      "Epoch 668, loss 5.713539\n",
      "\t Params: tensor([  4.3731, -11.6746])\n",
      "\t Grad:   tensor([-0.1693,  0.9581])\n",
      "Epoch 669, loss 5.704084\n",
      "\t Params: tensor([  4.3748, -11.6842])\n",
      "\t Grad:   tensor([-0.1690,  0.9564])\n",
      "Epoch 670, loss 5.694658\n",
      "\t Params: tensor([  4.3765, -11.6937])\n",
      "\t Grad:   tensor([-0.1687,  0.9548])\n",
      "Epoch 671, loss 5.685265\n",
      "\t Params: tensor([  4.3782, -11.7033])\n",
      "\t Grad:   tensor([-0.1684,  0.9532])\n",
      "Epoch 672, loss 5.675904\n",
      "\t Params: tensor([  4.3799, -11.7128])\n",
      "\t Grad:   tensor([-0.1681,  0.9516])\n",
      "Epoch 673, loss 5.666573\n",
      "\t Params: tensor([  4.3816, -11.7223])\n",
      "\t Grad:   tensor([-0.1678,  0.9499])\n",
      "Epoch 674, loss 5.657277\n",
      "\t Params: tensor([  4.3832, -11.7318])\n",
      "\t Grad:   tensor([-0.1675,  0.9483])\n",
      "Epoch 675, loss 5.648010\n",
      "\t Params: tensor([  4.3849, -11.7412])\n",
      "\t Grad:   tensor([-0.1673,  0.9467])\n",
      "Epoch 676, loss 5.638776\n",
      "\t Params: tensor([  4.3866, -11.7507])\n",
      "\t Grad:   tensor([-0.1670,  0.9451])\n",
      "Epoch 677, loss 5.629575\n",
      "\t Params: tensor([  4.3882, -11.7601])\n",
      "\t Grad:   tensor([-0.1667,  0.9435])\n",
      "Epoch 678, loss 5.620402\n",
      "\t Params: tensor([  4.3899, -11.7696])\n",
      "\t Grad:   tensor([-0.1664,  0.9419])\n",
      "Epoch 679, loss 5.611260\n",
      "\t Params: tensor([  4.3916, -11.7790])\n",
      "\t Grad:   tensor([-0.1661,  0.9403])\n",
      "Epoch 680, loss 5.602148\n",
      "\t Params: tensor([  4.3932, -11.7883])\n",
      "\t Grad:   tensor([-0.1658,  0.9387])\n",
      "Epoch 681, loss 5.593071\n",
      "\t Params: tensor([  4.3949, -11.7977])\n",
      "\t Grad:   tensor([-0.1656,  0.9371])\n",
      "Epoch 682, loss 5.584022\n",
      "\t Params: tensor([  4.3965, -11.8071])\n",
      "\t Grad:   tensor([-0.1653,  0.9355])\n",
      "Epoch 683, loss 5.575005\n",
      "\t Params: tensor([  4.3982, -11.8164])\n",
      "\t Grad:   tensor([-0.1650,  0.9339])\n",
      "Epoch 684, loss 5.566019\n",
      "\t Params: tensor([  4.3998, -11.8257])\n",
      "\t Grad:   tensor([-0.1647,  0.9323])\n",
      "Epoch 685, loss 5.557063\n",
      "\t Params: tensor([  4.4015, -11.8350])\n",
      "\t Grad:   tensor([-0.1644,  0.9308])\n",
      "Epoch 686, loss 5.548136\n",
      "\t Params: tensor([  4.4031, -11.8443])\n",
      "\t Grad:   tensor([-0.1641,  0.9292])\n",
      "Epoch 687, loss 5.539241\n",
      "\t Params: tensor([  4.4048, -11.8536])\n",
      "\t Grad:   tensor([-0.1639,  0.9276])\n",
      "Epoch 688, loss 5.530376\n",
      "\t Params: tensor([  4.4064, -11.8629])\n",
      "\t Grad:   tensor([-0.1636,  0.9260])\n",
      "Epoch 689, loss 5.521540\n",
      "\t Params: tensor([  4.4080, -11.8721])\n",
      "\t Grad:   tensor([-0.1633,  0.9245])\n",
      "Epoch 690, loss 5.512733\n",
      "\t Params: tensor([  4.4097, -11.8813])\n",
      "\t Grad:   tensor([-0.1630,  0.9229])\n",
      "Epoch 691, loss 5.503958\n",
      "\t Params: tensor([  4.4113, -11.8906])\n",
      "\t Grad:   tensor([-0.1628,  0.9213])\n",
      "Epoch 692, loss 5.495212\n",
      "\t Params: tensor([  4.4129, -11.8998])\n",
      "\t Grad:   tensor([-0.1625,  0.9197])\n",
      "Epoch 693, loss 5.486496\n",
      "\t Params: tensor([  4.4145, -11.9089])\n",
      "\t Grad:   tensor([-0.1622,  0.9182])\n",
      "Epoch 694, loss 5.477808\n",
      "\t Params: tensor([  4.4161, -11.9181])\n",
      "\t Grad:   tensor([-0.1619,  0.9166])\n",
      "Epoch 695, loss 5.469152\n",
      "\t Params: tensor([  4.4178, -11.9272])\n",
      "\t Grad:   tensor([-0.1617,  0.9151])\n",
      "Epoch 696, loss 5.460525\n",
      "\t Params: tensor([  4.4194, -11.9364])\n",
      "\t Grad:   tensor([-0.1614,  0.9135])\n",
      "Epoch 697, loss 5.451928\n",
      "\t Params: tensor([  4.4210, -11.9455])\n",
      "\t Grad:   tensor([-0.1611,  0.9120])\n",
      "Epoch 698, loss 5.443359\n",
      "\t Params: tensor([  4.4226, -11.9546])\n",
      "\t Grad:   tensor([-0.1608,  0.9104])\n",
      "Epoch 699, loss 5.434820\n",
      "\t Params: tensor([  4.4242, -11.9637])\n",
      "\t Grad:   tensor([-0.1605,  0.9089])\n",
      "Epoch 700, loss 5.426310\n",
      "\t Params: tensor([  4.4258, -11.9728])\n",
      "\t Grad:   tensor([-0.1603,  0.9073])\n",
      "Epoch 701, loss 5.417827\n",
      "\t Params: tensor([  4.4274, -11.9818])\n",
      "\t Grad:   tensor([-0.1600,  0.9058])\n",
      "Epoch 702, loss 5.409373\n",
      "\t Params: tensor([  4.4290, -11.9909])\n",
      "\t Grad:   tensor([-0.1597,  0.9042])\n",
      "Epoch 703, loss 5.400949\n",
      "\t Params: tensor([  4.4306, -11.9999])\n",
      "\t Grad:   tensor([-0.1595,  0.9027])\n",
      "Epoch 704, loss 5.392551\n",
      "\t Params: tensor([  4.4322, -12.0089])\n",
      "\t Grad:   tensor([-0.1592,  0.9012])\n",
      "Epoch 705, loss 5.384184\n",
      "\t Params: tensor([  4.4338, -12.0179])\n",
      "\t Grad:   tensor([-0.1589,  0.8996])\n",
      "Epoch 706, loss 5.375845\n",
      "\t Params: tensor([  4.4354, -12.0269])\n",
      "\t Grad:   tensor([-0.1586,  0.8981])\n",
      "Epoch 707, loss 5.367537\n",
      "\t Params: tensor([  4.4369, -12.0359])\n",
      "\t Grad:   tensor([-0.1584,  0.8966])\n",
      "Epoch 708, loss 5.359253\n",
      "\t Params: tensor([  4.4385, -12.0448])\n",
      "\t Grad:   tensor([-0.1581,  0.8951])\n",
      "Epoch 709, loss 5.350998\n",
      "\t Params: tensor([  4.4401, -12.0537])\n",
      "\t Grad:   tensor([-0.1578,  0.8935])\n",
      "Epoch 710, loss 5.342771\n",
      "\t Params: tensor([  4.4417, -12.0627])\n",
      "\t Grad:   tensor([-0.1576,  0.8920])\n",
      "Epoch 711, loss 5.334575\n",
      "\t Params: tensor([  4.4433, -12.0716])\n",
      "\t Grad:   tensor([-0.1573,  0.8905])\n",
      "Epoch 712, loss 5.326403\n",
      "\t Params: tensor([  4.4448, -12.0805])\n",
      "\t Grad:   tensor([-0.1570,  0.8890])\n",
      "Epoch 713, loss 5.318259\n",
      "\t Params: tensor([  4.4464, -12.0893])\n",
      "\t Grad:   tensor([-0.1568,  0.8875])\n",
      "Epoch 714, loss 5.310144\n",
      "\t Params: tensor([  4.4480, -12.0982])\n",
      "\t Grad:   tensor([-0.1565,  0.8860])\n",
      "Epoch 715, loss 5.302055\n",
      "\t Params: tensor([  4.4495, -12.1070])\n",
      "\t Grad:   tensor([-0.1562,  0.8845])\n",
      "Epoch 716, loss 5.293994\n",
      "\t Params: tensor([  4.4511, -12.1159])\n",
      "\t Grad:   tensor([-0.1560,  0.8830])\n",
      "Epoch 717, loss 5.285964\n",
      "\t Params: tensor([  4.4526, -12.1247])\n",
      "\t Grad:   tensor([-0.1557,  0.8815])\n",
      "Epoch 718, loss 5.277958\n",
      "\t Params: tensor([  4.4542, -12.1335])\n",
      "\t Grad:   tensor([-0.1555,  0.8800])\n",
      "Epoch 719, loss 5.269979\n",
      "\t Params: tensor([  4.4557, -12.1423])\n",
      "\t Grad:   tensor([-0.1552,  0.8785])\n",
      "Epoch 720, loss 5.262026\n",
      "\t Params: tensor([  4.4573, -12.1510])\n",
      "\t Grad:   tensor([-0.1549,  0.8770])\n",
      "Epoch 721, loss 5.254103\n",
      "\t Params: tensor([  4.4588, -12.1598])\n",
      "\t Grad:   tensor([-0.1547,  0.8755])\n",
      "Epoch 722, loss 5.246205\n",
      "\t Params: tensor([  4.4604, -12.1685])\n",
      "\t Grad:   tensor([-0.1544,  0.8740])\n",
      "Epoch 723, loss 5.238335\n",
      "\t Params: tensor([  4.4619, -12.1773])\n",
      "\t Grad:   tensor([-0.1541,  0.8725])\n",
      "Epoch 724, loss 5.230491\n",
      "\t Params: tensor([  4.4635, -12.1860])\n",
      "\t Grad:   tensor([-0.1539,  0.8710])\n",
      "Epoch 725, loss 5.222673\n",
      "\t Params: tensor([  4.4650, -12.1947])\n",
      "\t Grad:   tensor([-0.1536,  0.8696])\n",
      "Epoch 726, loss 5.214881\n",
      "\t Params: tensor([  4.4665, -12.2033])\n",
      "\t Grad:   tensor([-0.1533,  0.8681])\n",
      "Epoch 727, loss 5.207120\n",
      "\t Params: tensor([  4.4681, -12.2120])\n",
      "\t Grad:   tensor([-0.1531,  0.8666])\n",
      "Epoch 728, loss 5.199381\n",
      "\t Params: tensor([  4.4696, -12.2207])\n",
      "\t Grad:   tensor([-0.1528,  0.8651])\n",
      "Epoch 729, loss 5.191670\n",
      "\t Params: tensor([  4.4711, -12.2293])\n",
      "\t Grad:   tensor([-0.1526,  0.8637])\n",
      "Epoch 730, loss 5.183984\n",
      "\t Params: tensor([  4.4726, -12.2379])\n",
      "\t Grad:   tensor([-0.1523,  0.8622])\n",
      "Epoch 731, loss 5.176324\n",
      "\t Params: tensor([  4.4742, -12.2465])\n",
      "\t Grad:   tensor([-0.1520,  0.8607])\n",
      "Epoch 732, loss 5.168688\n",
      "\t Params: tensor([  4.4757, -12.2551])\n",
      "\t Grad:   tensor([-0.1518,  0.8593])\n",
      "Epoch 733, loss 5.161084\n",
      "\t Params: tensor([  4.4772, -12.2637])\n",
      "\t Grad:   tensor([-0.1515,  0.8578])\n",
      "Epoch 734, loss 5.153500\n",
      "\t Params: tensor([  4.4787, -12.2723])\n",
      "\t Grad:   tensor([-0.1513,  0.8564])\n",
      "Epoch 735, loss 5.145943\n",
      "\t Params: tensor([  4.4802, -12.2808])\n",
      "\t Grad:   tensor([-0.1510,  0.8549])\n",
      "Epoch 736, loss 5.138412\n",
      "\t Params: tensor([  4.4817, -12.2893])\n",
      "\t Grad:   tensor([-0.1508,  0.8535])\n",
      "Epoch 737, loss 5.130910\n",
      "\t Params: tensor([  4.4832, -12.2979])\n",
      "\t Grad:   tensor([-0.1505,  0.8520])\n",
      "Epoch 738, loss 5.123428\n",
      "\t Params: tensor([  4.4847, -12.3064])\n",
      "\t Grad:   tensor([-0.1502,  0.8506])\n",
      "Epoch 739, loss 5.115977\n",
      "\t Params: tensor([  4.4862, -12.3149])\n",
      "\t Grad:   tensor([-0.1500,  0.8491])\n",
      "Epoch 740, loss 5.108547\n",
      "\t Params: tensor([  4.4877, -12.3233])\n",
      "\t Grad:   tensor([-0.1497,  0.8477])\n",
      "Epoch 741, loss 5.101144\n",
      "\t Params: tensor([  4.4892, -12.3318])\n",
      "\t Grad:   tensor([-0.1495,  0.8462])\n",
      "Epoch 742, loss 5.093765\n",
      "\t Params: tensor([  4.4907, -12.3402])\n",
      "\t Grad:   tensor([-0.1492,  0.8448])\n",
      "Epoch 743, loss 5.086413\n",
      "\t Params: tensor([  4.4922, -12.3487])\n",
      "\t Grad:   tensor([-0.1490,  0.8434])\n",
      "Epoch 744, loss 5.079085\n",
      "\t Params: tensor([  4.4937, -12.3571])\n",
      "\t Grad:   tensor([-0.1487,  0.8419])\n",
      "Epoch 745, loss 5.071782\n",
      "\t Params: tensor([  4.4952, -12.3655])\n",
      "\t Grad:   tensor([-0.1485,  0.8405])\n",
      "Epoch 746, loss 5.064505\n",
      "\t Params: tensor([  4.4967, -12.3739])\n",
      "\t Grad:   tensor([-0.1482,  0.8391])\n",
      "Epoch 747, loss 5.057247\n",
      "\t Params: tensor([  4.4981, -12.3823])\n",
      "\t Grad:   tensor([-0.1480,  0.8376])\n",
      "Epoch 748, loss 5.050022\n",
      "\t Params: tensor([  4.4996, -12.3906])\n",
      "\t Grad:   tensor([-0.1477,  0.8362])\n",
      "Epoch 749, loss 5.042817\n",
      "\t Params: tensor([  4.5011, -12.3990])\n",
      "\t Grad:   tensor([-0.1475,  0.8348])\n",
      "Epoch 750, loss 5.035636\n",
      "\t Params: tensor([  4.5026, -12.4073])\n",
      "\t Grad:   tensor([-0.1472,  0.8334])\n",
      "Epoch 751, loss 5.028476\n",
      "\t Params: tensor([  4.5040, -12.4156])\n",
      "\t Grad:   tensor([-0.1470,  0.8320])\n",
      "Epoch 752, loss 5.021346\n",
      "\t Params: tensor([  4.5055, -12.4239])\n",
      "\t Grad:   tensor([-0.1467,  0.8305])\n",
      "Epoch 753, loss 5.014239\n",
      "\t Params: tensor([  4.5070, -12.4322])\n",
      "\t Grad:   tensor([-0.1465,  0.8291])\n",
      "Epoch 754, loss 5.007157\n",
      "\t Params: tensor([  4.5084, -12.4405])\n",
      "\t Grad:   tensor([-0.1462,  0.8277])\n",
      "Epoch 755, loss 5.000099\n",
      "\t Params: tensor([  4.5099, -12.4488])\n",
      "\t Grad:   tensor([-0.1460,  0.8263])\n",
      "Epoch 756, loss 4.993064\n",
      "\t Params: tensor([  4.5113, -12.4570])\n",
      "\t Grad:   tensor([-0.1457,  0.8249])\n",
      "Epoch 757, loss 4.986051\n",
      "\t Params: tensor([  4.5128, -12.4653])\n",
      "\t Grad:   tensor([-0.1455,  0.8235])\n",
      "Epoch 758, loss 4.979065\n",
      "\t Params: tensor([  4.5143, -12.4735])\n",
      "\t Grad:   tensor([-0.1452,  0.8221])\n",
      "Epoch 759, loss 4.972100\n",
      "\t Params: tensor([  4.5157, -12.4817])\n",
      "\t Grad:   tensor([-0.1450,  0.8207])\n",
      "Epoch 760, loss 4.965159\n",
      "\t Params: tensor([  4.5172, -12.4899])\n",
      "\t Grad:   tensor([-0.1447,  0.8193])\n",
      "Epoch 761, loss 4.958245\n",
      "\t Params: tensor([  4.5186, -12.4981])\n",
      "\t Grad:   tensor([-0.1445,  0.8179])\n",
      "Epoch 762, loss 4.951350\n",
      "\t Params: tensor([  4.5200, -12.5062])\n",
      "\t Grad:   tensor([-0.1443,  0.8165])\n",
      "Epoch 763, loss 4.944479\n",
      "\t Params: tensor([  4.5215, -12.5144])\n",
      "\t Grad:   tensor([-0.1440,  0.8152])\n",
      "Epoch 764, loss 4.937633\n",
      "\t Params: tensor([  4.5229, -12.5225])\n",
      "\t Grad:   tensor([-0.1438,  0.8138])\n",
      "Epoch 765, loss 4.930812\n",
      "\t Params: tensor([  4.5244, -12.5306])\n",
      "\t Grad:   tensor([-0.1435,  0.8124])\n",
      "Epoch 766, loss 4.924009\n",
      "\t Params: tensor([  4.5258, -12.5387])\n",
      "\t Grad:   tensor([-0.1433,  0.8110])\n",
      "Epoch 767, loss 4.917234\n",
      "\t Params: tensor([  4.5272, -12.5468])\n",
      "\t Grad:   tensor([-0.1430,  0.8096])\n",
      "Epoch 768, loss 4.910480\n",
      "\t Params: tensor([  4.5286, -12.5549])\n",
      "\t Grad:   tensor([-0.1428,  0.8083])\n",
      "Epoch 769, loss 4.903749\n",
      "\t Params: tensor([  4.5301, -12.5630])\n",
      "\t Grad:   tensor([-0.1426,  0.8069])\n",
      "Epoch 770, loss 4.897040\n",
      "\t Params: tensor([  4.5315, -12.5711])\n",
      "\t Grad:   tensor([-0.1423,  0.8055])\n",
      "Epoch 771, loss 4.890356\n",
      "\t Params: tensor([  4.5329, -12.5791])\n",
      "\t Grad:   tensor([-0.1420,  0.8042])\n",
      "Epoch 772, loss 4.883691\n",
      "\t Params: tensor([  4.5343, -12.5871])\n",
      "\t Grad:   tensor([-0.1418,  0.8028])\n",
      "Epoch 773, loss 4.877052\n",
      "\t Params: tensor([  4.5357, -12.5951])\n",
      "\t Grad:   tensor([-0.1416,  0.8014])\n",
      "Epoch 774, loss 4.870436\n",
      "\t Params: tensor([  4.5372, -12.6031])\n",
      "\t Grad:   tensor([-0.1413,  0.8001])\n",
      "Epoch 775, loss 4.863839\n",
      "\t Params: tensor([  4.5386, -12.6111])\n",
      "\t Grad:   tensor([-0.1411,  0.7987])\n",
      "Epoch 776, loss 4.857267\n",
      "\t Params: tensor([  4.5400, -12.6191])\n",
      "\t Grad:   tensor([-0.1408,  0.7973])\n",
      "Epoch 777, loss 4.850717\n",
      "\t Params: tensor([  4.5414, -12.6271])\n",
      "\t Grad:   tensor([-0.1406,  0.7960])\n",
      "Epoch 778, loss 4.844189\n",
      "\t Params: tensor([  4.5428, -12.6350])\n",
      "\t Grad:   tensor([-0.1404,  0.7946])\n",
      "Epoch 779, loss 4.837683\n",
      "\t Params: tensor([  4.5442, -12.6429])\n",
      "\t Grad:   tensor([-0.1401,  0.7933])\n",
      "Epoch 780, loss 4.831196\n",
      "\t Params: tensor([  4.5456, -12.6509])\n",
      "\t Grad:   tensor([-0.1399,  0.7919])\n",
      "Epoch 781, loss 4.824737\n",
      "\t Params: tensor([  4.5470, -12.6588])\n",
      "\t Grad:   tensor([-0.1397,  0.7906])\n",
      "Epoch 782, loss 4.818298\n",
      "\t Params: tensor([  4.5484, -12.6667])\n",
      "\t Grad:   tensor([-0.1394,  0.7892])\n",
      "Epoch 783, loss 4.811880\n",
      "\t Params: tensor([  4.5498, -12.6745])\n",
      "\t Grad:   tensor([-0.1392,  0.7879])\n",
      "Epoch 784, loss 4.805481\n",
      "\t Params: tensor([  4.5512, -12.6824])\n",
      "\t Grad:   tensor([-0.1389,  0.7866])\n",
      "Epoch 785, loss 4.799106\n",
      "\t Params: tensor([  4.5525, -12.6902])\n",
      "\t Grad:   tensor([-0.1387,  0.7852])\n",
      "Epoch 786, loss 4.792755\n",
      "\t Params: tensor([  4.5539, -12.6981])\n",
      "\t Grad:   tensor([-0.1385,  0.7839])\n",
      "Epoch 787, loss 4.786422\n",
      "\t Params: tensor([  4.5553, -12.7059])\n",
      "\t Grad:   tensor([-0.1382,  0.7826])\n",
      "Epoch 788, loss 4.780112\n",
      "\t Params: tensor([  4.5567, -12.7137])\n",
      "\t Grad:   tensor([-0.1380,  0.7812])\n",
      "Epoch 789, loss 4.773824\n",
      "\t Params: tensor([  4.5581, -12.7215])\n",
      "\t Grad:   tensor([-0.1378,  0.7799])\n",
      "Epoch 790, loss 4.767559\n",
      "\t Params: tensor([  4.5594, -12.7293])\n",
      "\t Grad:   tensor([-0.1375,  0.7786])\n",
      "Epoch 791, loss 4.761311\n",
      "\t Params: tensor([  4.5608, -12.7371])\n",
      "\t Grad:   tensor([-0.1373,  0.7773])\n",
      "Epoch 792, loss 4.755087\n",
      "\t Params: tensor([  4.5622, -12.7448])\n",
      "\t Grad:   tensor([-0.1371,  0.7759])\n",
      "Epoch 793, loss 4.748885\n",
      "\t Params: tensor([  4.5636, -12.7526])\n",
      "\t Grad:   tensor([-0.1368,  0.7746])\n",
      "Epoch 794, loss 4.742701\n",
      "\t Params: tensor([  4.5649, -12.7603])\n",
      "\t Grad:   tensor([-0.1366,  0.7733])\n",
      "Epoch 795, loss 4.736537\n",
      "\t Params: tensor([  4.5663, -12.7680])\n",
      "\t Grad:   tensor([-0.1364,  0.7720])\n",
      "Epoch 796, loss 4.730397\n",
      "\t Params: tensor([  4.5677, -12.7758])\n",
      "\t Grad:   tensor([-0.1361,  0.7707])\n",
      "Epoch 797, loss 4.724279\n",
      "\t Params: tensor([  4.5690, -12.7834])\n",
      "\t Grad:   tensor([-0.1359,  0.7694])\n",
      "Epoch 798, loss 4.718181\n",
      "\t Params: tensor([  4.5704, -12.7911])\n",
      "\t Grad:   tensor([-0.1357,  0.7681])\n",
      "Epoch 799, loss 4.712101\n",
      "\t Params: tensor([  4.5717, -12.7988])\n",
      "\t Grad:   tensor([-0.1354,  0.7668])\n",
      "Epoch 800, loss 4.706046\n",
      "\t Params: tensor([  4.5731, -12.8064])\n",
      "\t Grad:   tensor([-0.1352,  0.7655])\n",
      "Epoch 801, loss 4.700009\n",
      "\t Params: tensor([  4.5744, -12.8141])\n",
      "\t Grad:   tensor([-0.1350,  0.7642])\n",
      "Epoch 802, loss 4.693989\n",
      "\t Params: tensor([  4.5758, -12.8217])\n",
      "\t Grad:   tensor([-0.1347,  0.7629])\n",
      "Epoch 803, loss 4.687995\n",
      "\t Params: tensor([  4.5771, -12.8293])\n",
      "\t Grad:   tensor([-0.1345,  0.7616])\n",
      "Epoch 804, loss 4.682020\n",
      "\t Params: tensor([  4.5785, -12.8369])\n",
      "\t Grad:   tensor([-0.1343,  0.7603])\n",
      "Epoch 805, loss 4.676063\n",
      "\t Params: tensor([  4.5798, -12.8445])\n",
      "\t Grad:   tensor([-0.1341,  0.7590])\n",
      "Epoch 806, loss 4.670130\n",
      "\t Params: tensor([  4.5811, -12.8521])\n",
      "\t Grad:   tensor([-0.1338,  0.7577])\n",
      "Epoch 807, loss 4.664214\n",
      "\t Params: tensor([  4.5825, -12.8597])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Grad:   tensor([-0.1336,  0.7564])\n",
      "Epoch 808, loss 4.658320\n",
      "\t Params: tensor([  4.5838, -12.8672])\n",
      "\t Grad:   tensor([-0.1334,  0.7551])\n",
      "Epoch 809, loss 4.652445\n",
      "\t Params: tensor([  4.5851, -12.8748])\n",
      "\t Grad:   tensor([-0.1332,  0.7538])\n",
      "Epoch 810, loss 4.646592\n",
      "\t Params: tensor([  4.5865, -12.8823])\n",
      "\t Grad:   tensor([-0.1330,  0.7526])\n",
      "Epoch 811, loss 4.640753\n",
      "\t Params: tensor([  4.5878, -12.8898])\n",
      "\t Grad:   tensor([-0.1327,  0.7513])\n",
      "Epoch 812, loss 4.634938\n",
      "\t Params: tensor([  4.5891, -12.8973])\n",
      "\t Grad:   tensor([-0.1325,  0.7500])\n",
      "Epoch 813, loss 4.629142\n",
      "\t Params: tensor([  4.5904, -12.9048])\n",
      "\t Grad:   tensor([-0.1323,  0.7487])\n",
      "Epoch 814, loss 4.623368\n",
      "\t Params: tensor([  4.5918, -12.9123])\n",
      "\t Grad:   tensor([-0.1320,  0.7475])\n",
      "Epoch 815, loss 4.617611\n",
      "\t Params: tensor([  4.5931, -12.9197])\n",
      "\t Grad:   tensor([-0.1318,  0.7462])\n",
      "Epoch 816, loss 4.611873\n",
      "\t Params: tensor([  4.5944, -12.9272])\n",
      "\t Grad:   tensor([-0.1316,  0.7449])\n",
      "Epoch 817, loss 4.606156\n",
      "\t Params: tensor([  4.5957, -12.9346])\n",
      "\t Grad:   tensor([-0.1314,  0.7437])\n",
      "Epoch 818, loss 4.600458\n",
      "\t Params: tensor([  4.5970, -12.9420])\n",
      "\t Grad:   tensor([-0.1311,  0.7424])\n",
      "Epoch 819, loss 4.594780\n",
      "\t Params: tensor([  4.5983, -12.9494])\n",
      "\t Grad:   tensor([-0.1309,  0.7411])\n",
      "Epoch 820, loss 4.589119\n",
      "\t Params: tensor([  4.5996, -12.9568])\n",
      "\t Grad:   tensor([-0.1307,  0.7399])\n",
      "Epoch 821, loss 4.583479\n",
      "\t Params: tensor([  4.6009, -12.9642])\n",
      "\t Grad:   tensor([-0.1305,  0.7386])\n",
      "Epoch 822, loss 4.577857\n",
      "\t Params: tensor([  4.6022, -12.9716])\n",
      "\t Grad:   tensor([-0.1303,  0.7374])\n",
      "Epoch 823, loss 4.572256\n",
      "\t Params: tensor([  4.6035, -12.9790])\n",
      "\t Grad:   tensor([-0.1300,  0.7361])\n",
      "Epoch 824, loss 4.566675\n",
      "\t Params: tensor([  4.6048, -12.9863])\n",
      "\t Grad:   tensor([-0.1298,  0.7349])\n",
      "Epoch 825, loss 4.561109\n",
      "\t Params: tensor([  4.6061, -12.9936])\n",
      "\t Grad:   tensor([-0.1296,  0.7336])\n",
      "Epoch 826, loss 4.555565\n",
      "\t Params: tensor([  4.6074, -13.0010])\n",
      "\t Grad:   tensor([-0.1294,  0.7324])\n",
      "Epoch 827, loss 4.550039\n",
      "\t Params: tensor([  4.6087, -13.0083])\n",
      "\t Grad:   tensor([-0.1292,  0.7311])\n",
      "Epoch 828, loss 4.544533\n",
      "\t Params: tensor([  4.6100, -13.0156])\n",
      "\t Grad:   tensor([-0.1289,  0.7299])\n",
      "Epoch 829, loss 4.539044\n",
      "\t Params: tensor([  4.6113, -13.0229])\n",
      "\t Grad:   tensor([-0.1287,  0.7286])\n",
      "Epoch 830, loss 4.533575\n",
      "\t Params: tensor([  4.6126, -13.0301])\n",
      "\t Grad:   tensor([-0.1285,  0.7274])\n",
      "Epoch 831, loss 4.528122\n",
      "\t Params: tensor([  4.6139, -13.0374])\n",
      "\t Grad:   tensor([-0.1283,  0.7262])\n",
      "Epoch 832, loss 4.522691\n",
      "\t Params: tensor([  4.6152, -13.0446])\n",
      "\t Grad:   tensor([-0.1280,  0.7249])\n",
      "Epoch 833, loss 4.517276\n",
      "\t Params: tensor([  4.6164, -13.0519])\n",
      "\t Grad:   tensor([-0.1278,  0.7237])\n",
      "Epoch 834, loss 4.511879\n",
      "\t Params: tensor([  4.6177, -13.0591])\n",
      "\t Grad:   tensor([-0.1276,  0.7225])\n",
      "Epoch 835, loss 4.506504\n",
      "\t Params: tensor([  4.6190, -13.0663])\n",
      "\t Grad:   tensor([-0.1274,  0.7212])\n",
      "Epoch 836, loss 4.501141\n",
      "\t Params: tensor([  4.6203, -13.0735])\n",
      "\t Grad:   tensor([-0.1272,  0.7200])\n",
      "Epoch 837, loss 4.495801\n",
      "\t Params: tensor([  4.6215, -13.0807])\n",
      "\t Grad:   tensor([-0.1270,  0.7188])\n",
      "Epoch 838, loss 4.490474\n",
      "\t Params: tensor([  4.6228, -13.0879])\n",
      "\t Grad:   tensor([-0.1268,  0.7176])\n",
      "Epoch 839, loss 4.485170\n",
      "\t Params: tensor([  4.6241, -13.0950])\n",
      "\t Grad:   tensor([-0.1266,  0.7163])\n",
      "Epoch 840, loss 4.479884\n",
      "\t Params: tensor([  4.6253, -13.1022])\n",
      "\t Grad:   tensor([-0.1263,  0.7151])\n",
      "Epoch 841, loss 4.474614\n",
      "\t Params: tensor([  4.6266, -13.1093])\n",
      "\t Grad:   tensor([-0.1261,  0.7139])\n",
      "Epoch 842, loss 4.469364\n",
      "\t Params: tensor([  4.6278, -13.1165])\n",
      "\t Grad:   tensor([-0.1259,  0.7127])\n",
      "Epoch 843, loss 4.464129\n",
      "\t Params: tensor([  4.6291, -13.1236])\n",
      "\t Grad:   tensor([-0.1257,  0.7115])\n",
      "Epoch 844, loss 4.458913\n",
      "\t Params: tensor([  4.6304, -13.1307])\n",
      "\t Grad:   tensor([-0.1255,  0.7103])\n",
      "Epoch 845, loss 4.453716\n",
      "\t Params: tensor([  4.6316, -13.1378])\n",
      "\t Grad:   tensor([-0.1253,  0.7091])\n",
      "Epoch 846, loss 4.448534\n",
      "\t Params: tensor([  4.6329, -13.1449])\n",
      "\t Grad:   tensor([-0.1250,  0.7079])\n",
      "Epoch 847, loss 4.443372\n",
      "\t Params: tensor([  4.6341, -13.1519])\n",
      "\t Grad:   tensor([-0.1249,  0.7067])\n",
      "Epoch 848, loss 4.438227\n",
      "\t Params: tensor([  4.6353, -13.1590])\n",
      "\t Grad:   tensor([-0.1246,  0.7055])\n",
      "Epoch 849, loss 4.433099\n",
      "\t Params: tensor([  4.6366, -13.1660])\n",
      "\t Grad:   tensor([-0.1244,  0.7043])\n",
      "Epoch 850, loss 4.427989\n",
      "\t Params: tensor([  4.6378, -13.1730])\n",
      "\t Grad:   tensor([-0.1242,  0.7031])\n",
      "Epoch 851, loss 4.422897\n",
      "\t Params: tensor([  4.6391, -13.1801])\n",
      "\t Grad:   tensor([-0.1240,  0.7019])\n",
      "Epoch 852, loss 4.417819\n",
      "\t Params: tensor([  4.6403, -13.1871])\n",
      "\t Grad:   tensor([-0.1238,  0.7007])\n",
      "Epoch 853, loss 4.412762\n",
      "\t Params: tensor([  4.6415, -13.1941])\n",
      "\t Grad:   tensor([-0.1236,  0.6995])\n",
      "Epoch 854, loss 4.407720\n",
      "\t Params: tensor([  4.6428, -13.2010])\n",
      "\t Grad:   tensor([-0.1234,  0.6983])\n",
      "Epoch 855, loss 4.402697\n",
      "\t Params: tensor([  4.6440, -13.2080])\n",
      "\t Grad:   tensor([-0.1232,  0.6971])\n",
      "Epoch 856, loss 4.397688\n",
      "\t Params: tensor([  4.6452, -13.2150])\n",
      "\t Grad:   tensor([-0.1229,  0.6959])\n",
      "Epoch 857, loss 4.392697\n",
      "\t Params: tensor([  4.6465, -13.2219])\n",
      "\t Grad:   tensor([-0.1227,  0.6948])\n",
      "Epoch 858, loss 4.387725\n",
      "\t Params: tensor([  4.6477, -13.2289])\n",
      "\t Grad:   tensor([-0.1225,  0.6936])\n",
      "Epoch 859, loss 4.382769\n",
      "\t Params: tensor([  4.6489, -13.2358])\n",
      "\t Grad:   tensor([-0.1223,  0.6924])\n",
      "Epoch 860, loss 4.377828\n",
      "\t Params: tensor([  4.6501, -13.2427])\n",
      "\t Grad:   tensor([-0.1221,  0.6912])\n",
      "Epoch 861, loss 4.372905\n",
      "\t Params: tensor([  4.6514, -13.2496])\n",
      "\t Grad:   tensor([-0.1219,  0.6901])\n",
      "Epoch 862, loss 4.368000\n",
      "\t Params: tensor([  4.6526, -13.2565])\n",
      "\t Grad:   tensor([-0.1217,  0.6889])\n",
      "Epoch 863, loss 4.363111\n",
      "\t Params: tensor([  4.6538, -13.2634])\n",
      "\t Grad:   tensor([-0.1215,  0.6877])\n",
      "Epoch 864, loss 4.358238\n",
      "\t Params: tensor([  4.6550, -13.2702])\n",
      "\t Grad:   tensor([-0.1213,  0.6865])\n",
      "Epoch 865, loss 4.353383\n",
      "\t Params: tensor([  4.6562, -13.2771])\n",
      "\t Grad:   tensor([-0.1211,  0.6854])\n",
      "Epoch 866, loss 4.348542\n",
      "\t Params: tensor([  4.6574, -13.2839])\n",
      "\t Grad:   tensor([-0.1209,  0.6842])\n",
      "Epoch 867, loss 4.343716\n",
      "\t Params: tensor([  4.6586, -13.2908])\n",
      "\t Grad:   tensor([-0.1207,  0.6830])\n",
      "Epoch 868, loss 4.338911\n",
      "\t Params: tensor([  4.6598, -13.2976])\n",
      "\t Grad:   tensor([-0.1205,  0.6819])\n",
      "Epoch 869, loss 4.334121\n",
      "\t Params: tensor([  4.6610, -13.3044])\n",
      "\t Grad:   tensor([-0.1203,  0.6807])\n",
      "Epoch 870, loss 4.329345\n",
      "\t Params: tensor([  4.6622, -13.3112])\n",
      "\t Grad:   tensor([-0.1201,  0.6796])\n",
      "Epoch 871, loss 4.324588\n",
      "\t Params: tensor([  4.6634, -13.3180])\n",
      "\t Grad:   tensor([-0.1198,  0.6784])\n",
      "Epoch 872, loss 4.319845\n",
      "\t Params: tensor([  4.6646, -13.3247])\n",
      "\t Grad:   tensor([-0.1196,  0.6773])\n",
      "Epoch 873, loss 4.315118\n",
      "\t Params: tensor([  4.6658, -13.3315])\n",
      "\t Grad:   tensor([-0.1195,  0.6761])\n",
      "Epoch 874, loss 4.310409\n",
      "\t Params: tensor([  4.6670, -13.3382])\n",
      "\t Grad:   tensor([-0.1192,  0.6750])\n",
      "Epoch 875, loss 4.305714\n",
      "\t Params: tensor([  4.6682, -13.3450])\n",
      "\t Grad:   tensor([-0.1190,  0.6738])\n",
      "Epoch 876, loss 4.301035\n",
      "\t Params: tensor([  4.6694, -13.3517])\n",
      "\t Grad:   tensor([-0.1188,  0.6727])\n",
      "Epoch 877, loss 4.296376\n",
      "\t Params: tensor([  4.6706, -13.3584])\n",
      "\t Grad:   tensor([-0.1186,  0.6715])\n",
      "Epoch 878, loss 4.291727\n",
      "\t Params: tensor([  4.6718, -13.3651])\n",
      "\t Grad:   tensor([-0.1184,  0.6704])\n",
      "Epoch 879, loss 4.287097\n",
      "\t Params: tensor([  4.6730, -13.3718])\n",
      "\t Grad:   tensor([-0.1182,  0.6693])\n",
      "Epoch 880, loss 4.282482\n",
      "\t Params: tensor([  4.6741, -13.3785])\n",
      "\t Grad:   tensor([-0.1180,  0.6681])\n",
      "Epoch 881, loss 4.277882\n",
      "\t Params: tensor([  4.6753, -13.3852])\n",
      "\t Grad:   tensor([-0.1178,  0.6670])\n",
      "Epoch 882, loss 4.273299\n",
      "\t Params: tensor([  4.6765, -13.3918])\n",
      "\t Grad:   tensor([-0.1176,  0.6658])\n",
      "Epoch 883, loss 4.268732\n",
      "\t Params: tensor([  4.6777, -13.3985])\n",
      "\t Grad:   tensor([-0.1174,  0.6647])\n",
      "Epoch 884, loss 4.264178\n",
      "\t Params: tensor([  4.6788, -13.4051])\n",
      "\t Grad:   tensor([-0.1172,  0.6636])\n",
      "Epoch 885, loss 4.259643\n",
      "\t Params: tensor([  4.6800, -13.4117])\n",
      "\t Grad:   tensor([-0.1170,  0.6625])\n",
      "Epoch 886, loss 4.255120\n",
      "\t Params: tensor([  4.6812, -13.4184])\n",
      "\t Grad:   tensor([-0.1168,  0.6613])\n",
      "Epoch 887, loss 4.250613\n",
      "\t Params: tensor([  4.6823, -13.4250])\n",
      "\t Grad:   tensor([-0.1166,  0.6602])\n",
      "Epoch 888, loss 4.246124\n",
      "\t Params: tensor([  4.6835, -13.4316])\n",
      "\t Grad:   tensor([-0.1164,  0.6591])\n",
      "Epoch 889, loss 4.241648\n",
      "\t Params: tensor([  4.6847, -13.4381])\n",
      "\t Grad:   tensor([-0.1162,  0.6580])\n",
      "Epoch 890, loss 4.237185\n",
      "\t Params: tensor([  4.6858, -13.4447])\n",
      "\t Grad:   tensor([-0.1160,  0.6569])\n",
      "Epoch 891, loss 4.232740\n",
      "\t Params: tensor([  4.6870, -13.4513])\n",
      "\t Grad:   tensor([-0.1158,  0.6557])\n",
      "Epoch 892, loss 4.228308\n",
      "\t Params: tensor([  4.6881, -13.4578])\n",
      "\t Grad:   tensor([-0.1157,  0.6546])\n",
      "Epoch 893, loss 4.223895\n",
      "\t Params: tensor([  4.6893, -13.4643])\n",
      "\t Grad:   tensor([-0.1154,  0.6535])\n",
      "Epoch 894, loss 4.219494\n",
      "\t Params: tensor([  4.6904, -13.4709])\n",
      "\t Grad:   tensor([-0.1153,  0.6524])\n",
      "Epoch 895, loss 4.215109\n",
      "\t Params: tensor([  4.6916, -13.4774])\n",
      "\t Grad:   tensor([-0.1151,  0.6513])\n",
      "Epoch 896, loss 4.210737\n",
      "\t Params: tensor([  4.6927, -13.4839])\n",
      "\t Grad:   tensor([-0.1148,  0.6502])\n",
      "Epoch 897, loss 4.206383\n",
      "\t Params: tensor([  4.6939, -13.4904])\n",
      "\t Grad:   tensor([-0.1147,  0.6491])\n",
      "Epoch 898, loss 4.202042\n",
      "\t Params: tensor([  4.6950, -13.4968])\n",
      "\t Grad:   tensor([-0.1145,  0.6480])\n",
      "Epoch 899, loss 4.197715\n",
      "\t Params: tensor([  4.6962, -13.5033])\n",
      "\t Grad:   tensor([-0.1143,  0.6469])\n",
      "Epoch 900, loss 4.193405\n",
      "\t Params: tensor([  4.6973, -13.5098])\n",
      "\t Grad:   tensor([-0.1141,  0.6458])\n",
      "Epoch 901, loss 4.189108\n",
      "\t Params: tensor([  4.6985, -13.5162])\n",
      "\t Grad:   tensor([-0.1139,  0.6447])\n",
      "Epoch 902, loss 4.184825\n",
      "\t Params: tensor([  4.6996, -13.5227])\n",
      "\t Grad:   tensor([-0.1137,  0.6436])\n",
      "Epoch 903, loss 4.180559\n",
      "\t Params: tensor([  4.7007, -13.5291])\n",
      "\t Grad:   tensor([-0.1135,  0.6425])\n",
      "Epoch 904, loss 4.176305\n",
      "\t Params: tensor([  4.7019, -13.5355])\n",
      "\t Grad:   tensor([-0.1133,  0.6414])\n",
      "Epoch 905, loss 4.172065\n",
      "\t Params: tensor([  4.7030, -13.5419])\n",
      "\t Grad:   tensor([-0.1131,  0.6403])\n",
      "Epoch 906, loss 4.167842\n",
      "\t Params: tensor([  4.7041, -13.5483])\n",
      "\t Grad:   tensor([-0.1129,  0.6392])\n",
      "Epoch 907, loss 4.163631\n",
      "\t Params: tensor([  4.7053, -13.5547])\n",
      "\t Grad:   tensor([-0.1127,  0.6381])\n",
      "Epoch 908, loss 4.159436\n",
      "\t Params: tensor([  4.7064, -13.5610])\n",
      "\t Grad:   tensor([-0.1125,  0.6371])\n",
      "Epoch 909, loss 4.155253\n",
      "\t Params: tensor([  4.7075, -13.5674])\n",
      "\t Grad:   tensor([-0.1124,  0.6360])\n",
      "Epoch 910, loss 4.151086\n",
      "\t Params: tensor([  4.7086, -13.5738])\n",
      "\t Grad:   tensor([-0.1122,  0.6349])\n",
      "Epoch 911, loss 4.146934\n",
      "\t Params: tensor([  4.7097, -13.5801])\n",
      "\t Grad:   tensor([-0.1120,  0.6338])\n",
      "Epoch 912, loss 4.142795\n",
      "\t Params: tensor([  4.7109, -13.5864])\n",
      "\t Grad:   tensor([-0.1118,  0.6327])\n",
      "Epoch 913, loss 4.138669\n",
      "\t Params: tensor([  4.7120, -13.5927])\n",
      "\t Grad:   tensor([-0.1116,  0.6317])\n",
      "Epoch 914, loss 4.134559\n",
      "\t Params: tensor([  4.7131, -13.5990])\n",
      "\t Grad:   tensor([-0.1114,  0.6306])\n",
      "Epoch 915, loss 4.130464\n",
      "\t Params: tensor([  4.7142, -13.6053])\n",
      "\t Grad:   tensor([-0.1112,  0.6295])\n",
      "Epoch 916, loss 4.126378\n",
      "\t Params: tensor([  4.7153, -13.6116])\n",
      "\t Grad:   tensor([-0.1110,  0.6284])\n",
      "Epoch 917, loss 4.122310\n",
      "\t Params: tensor([  4.7164, -13.6179])\n",
      "\t Grad:   tensor([-0.1108,  0.6274])\n",
      "Epoch 918, loss 4.118254\n",
      "\t Params: tensor([  4.7175, -13.6242])\n",
      "\t Grad:   tensor([-0.1107,  0.6263])\n",
      "Epoch 919, loss 4.114213\n",
      "\t Params: tensor([  4.7186, -13.6304])\n",
      "\t Grad:   tensor([-0.1104,  0.6253])\n",
      "Epoch 920, loss 4.110184\n",
      "\t Params: tensor([  4.7197, -13.6367])\n",
      "\t Grad:   tensor([-0.1103,  0.6242])\n",
      "Epoch 921, loss 4.106169\n",
      "\t Params: tensor([  4.7208, -13.6429])\n",
      "\t Grad:   tensor([-0.1101,  0.6231])\n",
      "Epoch 922, loss 4.102170\n",
      "\t Params: tensor([  4.7219, -13.6491])\n",
      "\t Grad:   tensor([-0.1099,  0.6221])\n",
      "Epoch 923, loss 4.098181\n",
      "\t Params: tensor([  4.7230, -13.6553])\n",
      "\t Grad:   tensor([-0.1097,  0.6210])\n",
      "Epoch 924, loss 4.094210\n",
      "\t Params: tensor([  4.7241, -13.6615])\n",
      "\t Grad:   tensor([-0.1095,  0.6200])\n",
      "Epoch 925, loss 4.090249\n",
      "\t Params: tensor([  4.7252, -13.6677])\n",
      "\t Grad:   tensor([-0.1093,  0.6189])\n",
      "Epoch 926, loss 4.086300\n",
      "\t Params: tensor([  4.7263, -13.6739])\n",
      "\t Grad:   tensor([-0.1091,  0.6179])\n",
      "Epoch 927, loss 4.082366\n",
      "\t Params: tensor([  4.7274, -13.6800])\n",
      "\t Grad:   tensor([-0.1090,  0.6168])\n",
      "Epoch 928, loss 4.078448\n",
      "\t Params: tensor([  4.7285, -13.6862])\n",
      "\t Grad:   tensor([-0.1088,  0.6158])\n",
      "Epoch 929, loss 4.074541\n",
      "\t Params: tensor([  4.7296, -13.6924])\n",
      "\t Grad:   tensor([-0.1086,  0.6147])\n",
      "Epoch 930, loss 4.070649\n",
      "\t Params: tensor([  4.7307, -13.6985])\n",
      "\t Grad:   tensor([-0.1084,  0.6137])\n",
      "Epoch 931, loss 4.066768\n",
      "\t Params: tensor([  4.7317, -13.7046])\n",
      "\t Grad:   tensor([-0.1082,  0.6126])\n",
      "Epoch 932, loss 4.062900\n",
      "\t Params: tensor([  4.7328, -13.7107])\n",
      "\t Grad:   tensor([-0.1080,  0.6116])\n",
      "Epoch 933, loss 4.059047\n",
      "\t Params: tensor([  4.7339, -13.7168])\n",
      "\t Grad:   tensor([-0.1079,  0.6105])\n",
      "Epoch 934, loss 4.055204\n",
      "\t Params: tensor([  4.7350, -13.7229])\n",
      "\t Grad:   tensor([-0.1077,  0.6095])\n",
      "Epoch 935, loss 4.051379\n",
      "\t Params: tensor([  4.7360, -13.7290])\n",
      "\t Grad:   tensor([-0.1075,  0.6085])\n",
      "Epoch 936, loss 4.047564\n",
      "\t Params: tensor([  4.7371, -13.7351])\n",
      "\t Grad:   tensor([-0.1073,  0.6074])\n",
      "Epoch 937, loss 4.043762\n",
      "\t Params: tensor([  4.7382, -13.7412])\n",
      "\t Grad:   tensor([-0.1071,  0.6064])\n",
      "Epoch 938, loss 4.039972\n",
      "\t Params: tensor([  4.7393, -13.7472])\n",
      "\t Grad:   tensor([-0.1069,  0.6054])\n",
      "Epoch 939, loss 4.036197\n",
      "\t Params: tensor([  4.7403, -13.7533])\n",
      "\t Grad:   tensor([-0.1068,  0.6043])\n",
      "Epoch 940, loss 4.032434\n",
      "\t Params: tensor([  4.7414, -13.7593])\n",
      "\t Grad:   tensor([-0.1066,  0.6033])\n",
      "Epoch 941, loss 4.028686\n",
      "\t Params: tensor([  4.7425, -13.7653])\n",
      "\t Grad:   tensor([-0.1064,  0.6023])\n",
      "Epoch 942, loss 4.024947\n",
      "\t Params: tensor([  4.7435, -13.7713])\n",
      "\t Grad:   tensor([-0.1062,  0.6013])\n",
      "Epoch 943, loss 4.021224\n",
      "\t Params: tensor([  4.7446, -13.7773])\n",
      "\t Grad:   tensor([-0.1060,  0.6002])\n",
      "Epoch 944, loss 4.017509\n",
      "\t Params: tensor([  4.7456, -13.7833])\n",
      "\t Grad:   tensor([-0.1058,  0.5992])\n",
      "Epoch 945, loss 4.013810\n",
      "\t Params: tensor([  4.7467, -13.7893])\n",
      "\t Grad:   tensor([-0.1057,  0.5982])\n",
      "Epoch 946, loss 4.010122\n",
      "\t Params: tensor([  4.7478, -13.7953])\n",
      "\t Grad:   tensor([-0.1055,  0.5972])\n",
      "Epoch 947, loss 4.006450\n",
      "\t Params: tensor([  4.7488, -13.8012])\n",
      "\t Grad:   tensor([-0.1053,  0.5962])\n",
      "Epoch 948, loss 4.002785\n",
      "\t Params: tensor([  4.7499, -13.8072])\n",
      "\t Grad:   tensor([-0.1051,  0.5952])\n",
      "Epoch 949, loss 3.999137\n",
      "\t Params: tensor([  4.7509, -13.8131])\n",
      "\t Grad:   tensor([-0.1050,  0.5942])\n",
      "Epoch 950, loss 3.995498\n",
      "\t Params: tensor([  4.7520, -13.8191])\n",
      "\t Grad:   tensor([-0.1048,  0.5932])\n",
      "Epoch 951, loss 3.991874\n",
      "\t Params: tensor([  4.7530, -13.8250])\n",
      "\t Grad:   tensor([-0.1046,  0.5921])\n",
      "Epoch 952, loss 3.988262\n",
      "\t Params: tensor([  4.7540, -13.8309])\n",
      "\t Grad:   tensor([-0.1044,  0.5911])\n",
      "Epoch 953, loss 3.984661\n",
      "\t Params: tensor([  4.7551, -13.8368])\n",
      "\t Grad:   tensor([-0.1042,  0.5901])\n",
      "Epoch 954, loss 3.981072\n",
      "\t Params: tensor([  4.7561, -13.8427])\n",
      "\t Grad:   tensor([-0.1041,  0.5891])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955, loss 3.977496\n",
      "\t Params: tensor([  4.7572, -13.8486])\n",
      "\t Grad:   tensor([-0.1039,  0.5881])\n",
      "Epoch 956, loss 3.973933\n",
      "\t Params: tensor([  4.7582, -13.8544])\n",
      "\t Grad:   tensor([-0.1037,  0.5871])\n",
      "Epoch 957, loss 3.970380\n",
      "\t Params: tensor([  4.7592, -13.8603])\n",
      "\t Grad:   tensor([-0.1035,  0.5861])\n",
      "Epoch 958, loss 3.966843\n",
      "\t Params: tensor([  4.7603, -13.8661])\n",
      "\t Grad:   tensor([-0.1034,  0.5851])\n",
      "Epoch 959, loss 3.963314\n",
      "\t Params: tensor([  4.7613, -13.8720])\n",
      "\t Grad:   tensor([-0.1032,  0.5841])\n",
      "Epoch 960, loss 3.959798\n",
      "\t Params: tensor([  4.7623, -13.8778])\n",
      "\t Grad:   tensor([-0.1030,  0.5832])\n",
      "Epoch 961, loss 3.956294\n",
      "\t Params: tensor([  4.7634, -13.8836])\n",
      "\t Grad:   tensor([-0.1029,  0.5822])\n",
      "Epoch 962, loss 3.952804\n",
      "\t Params: tensor([  4.7644, -13.8895])\n",
      "\t Grad:   tensor([-0.1027,  0.5812])\n",
      "Epoch 963, loss 3.949322\n",
      "\t Params: tensor([  4.7654, -13.8953])\n",
      "\t Grad:   tensor([-0.1025,  0.5802])\n",
      "Epoch 964, loss 3.945856\n",
      "\t Params: tensor([  4.7664, -13.9010])\n",
      "\t Grad:   tensor([-0.1023,  0.5792])\n",
      "Epoch 965, loss 3.942399\n",
      "\t Params: tensor([  4.7675, -13.9068])\n",
      "\t Grad:   tensor([-0.1022,  0.5782])\n",
      "Epoch 966, loss 3.938953\n",
      "\t Params: tensor([  4.7685, -13.9126])\n",
      "\t Grad:   tensor([-0.1020,  0.5772])\n",
      "Epoch 967, loss 3.935520\n",
      "\t Params: tensor([  4.7695, -13.9184])\n",
      "\t Grad:   tensor([-0.1018,  0.5763])\n",
      "Epoch 968, loss 3.932097\n",
      "\t Params: tensor([  4.7705, -13.9241])\n",
      "\t Grad:   tensor([-0.1016,  0.5753])\n",
      "Epoch 969, loss 3.928689\n",
      "\t Params: tensor([  4.7715, -13.9299])\n",
      "\t Grad:   tensor([-0.1014,  0.5743])\n",
      "Epoch 970, loss 3.925292\n",
      "\t Params: tensor([  4.7725, -13.9356])\n",
      "\t Grad:   tensor([-0.1013,  0.5733])\n",
      "Epoch 971, loss 3.921905\n",
      "\t Params: tensor([  4.7736, -13.9413])\n",
      "\t Grad:   tensor([-0.1011,  0.5723])\n",
      "Epoch 972, loss 3.918529\n",
      "\t Params: tensor([  4.7746, -13.9470])\n",
      "\t Grad:   tensor([-0.1009,  0.5714])\n",
      "Epoch 973, loss 3.915166\n",
      "\t Params: tensor([  4.7756, -13.9527])\n",
      "\t Grad:   tensor([-0.1007,  0.5704])\n",
      "Epoch 974, loss 3.911817\n",
      "\t Params: tensor([  4.7766, -13.9584])\n",
      "\t Grad:   tensor([-0.1006,  0.5694])\n",
      "Epoch 975, loss 3.908473\n",
      "\t Params: tensor([  4.7776, -13.9641])\n",
      "\t Grad:   tensor([-0.1004,  0.5685])\n",
      "Epoch 976, loss 3.905145\n",
      "\t Params: tensor([  4.7786, -13.9698])\n",
      "\t Grad:   tensor([-0.1003,  0.5675])\n",
      "Epoch 977, loss 3.901826\n",
      "\t Params: tensor([  4.7796, -13.9755])\n",
      "\t Grad:   tensor([-0.1001,  0.5665])\n",
      "Epoch 978, loss 3.898518\n",
      "\t Params: tensor([  4.7806, -13.9811])\n",
      "\t Grad:   tensor([-0.0999,  0.5656])\n",
      "Epoch 979, loss 3.895221\n",
      "\t Params: tensor([  4.7816, -13.9868])\n",
      "\t Grad:   tensor([-0.0997,  0.5646])\n",
      "Epoch 980, loss 3.891936\n",
      "\t Params: tensor([  4.7826, -13.9924])\n",
      "\t Grad:   tensor([-0.0996,  0.5637])\n",
      "Epoch 981, loss 3.888664\n",
      "\t Params: tensor([  4.7836, -13.9980])\n",
      "\t Grad:   tensor([-0.0994,  0.5627])\n",
      "Epoch 982, loss 3.885402\n",
      "\t Params: tensor([  4.7846, -14.0036])\n",
      "\t Grad:   tensor([-0.0992,  0.5617])\n",
      "Epoch 983, loss 3.882150\n",
      "\t Params: tensor([  4.7856, -14.0092])\n",
      "\t Grad:   tensor([-0.0991,  0.5608])\n",
      "Epoch 984, loss 3.878911\n",
      "\t Params: tensor([  4.7865, -14.0148])\n",
      "\t Grad:   tensor([-0.0989,  0.5598])\n",
      "Epoch 985, loss 3.875682\n",
      "\t Params: tensor([  4.7875, -14.0204])\n",
      "\t Grad:   tensor([-0.0987,  0.5589])\n",
      "Epoch 986, loss 3.872465\n",
      "\t Params: tensor([  4.7885, -14.0260])\n",
      "\t Grad:   tensor([-0.0985,  0.5579])\n",
      "Epoch 987, loss 3.869256\n",
      "\t Params: tensor([  4.7895, -14.0316])\n",
      "\t Grad:   tensor([-0.0984,  0.5570])\n",
      "Epoch 988, loss 3.866060\n",
      "\t Params: tensor([  4.7905, -14.0371])\n",
      "\t Grad:   tensor([-0.0982,  0.5560])\n",
      "Epoch 989, loss 3.862874\n",
      "\t Params: tensor([  4.7915, -14.0427])\n",
      "\t Grad:   tensor([-0.0981,  0.5551])\n",
      "Epoch 990, loss 3.859699\n",
      "\t Params: tensor([  4.7924, -14.0482])\n",
      "\t Grad:   tensor([-0.0979,  0.5542])\n",
      "Epoch 991, loss 3.856537\n",
      "\t Params: tensor([  4.7934, -14.0538])\n",
      "\t Grad:   tensor([-0.0977,  0.5532])\n",
      "Epoch 992, loss 3.853381\n",
      "\t Params: tensor([  4.7944, -14.0593])\n",
      "\t Grad:   tensor([-0.0976,  0.5523])\n",
      "Epoch 993, loss 3.850239\n",
      "\t Params: tensor([  4.7954, -14.0648])\n",
      "\t Grad:   tensor([-0.0974,  0.5513])\n",
      "Epoch 994, loss 3.847108\n",
      "\t Params: tensor([  4.7963, -14.0703])\n",
      "\t Grad:   tensor([-0.0972,  0.5504])\n",
      "Epoch 995, loss 3.843986\n",
      "\t Params: tensor([  4.7973, -14.0758])\n",
      "\t Grad:   tensor([-0.0971,  0.5495])\n",
      "Epoch 996, loss 3.840876\n",
      "\t Params: tensor([  4.7983, -14.0813])\n",
      "\t Grad:   tensor([-0.0969,  0.5485])\n",
      "Epoch 997, loss 3.837775\n",
      "\t Params: tensor([  4.7992, -14.0868])\n",
      "\t Grad:   tensor([-0.0967,  0.5476])\n",
      "Epoch 998, loss 3.834686\n",
      "\t Params: tensor([  4.8002, -14.0922])\n",
      "\t Grad:   tensor([-0.0966,  0.5467])\n",
      "Epoch 999, loss 3.831606\n",
      "\t Params: tensor([  4.8012, -14.0977])\n",
      "\t Grad:   tensor([-0.0964,  0.5457])\n",
      "Epoch 1000, loss 3.828538\n",
      "\t Params: tensor([  4.8021, -14.1031])\n",
      "\t Grad:   tensor([-0.0962,  0.5448])\n"
     ]
    }
   ],
   "source": [
    "params = training_loop(\n",
    "    n_epochs = 1000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18371a6b080>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t_p = model(t_un, *params)\n",
    "fig = plt.figure(dpi = 80)\n",
    "plt.xlabel(\"Fahrenheit\")\n",
    "plt.ylabel('Celsius')\n",
    "\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
